---
title: "Creating Efficient and Reproducible Water Quality Workflows Using R"
output: slidy_presentation
date: "`r Sys.Date()`"
editor: visual
editor_options:
  wrap: 72
execute:
  echo: true
  eval: true
  output: true
  warning: false
  error: false
  include: true
  code_folding: true
authors: 
  - name: "Hillary Marler"
    affiliation: EPA
  - name: "Cristina Mullin"
    orcid: 0000-0002-0615-6087
    affiliation: EPA
  - name: "Marc Weber"
    affiliation: EPA
  - name: "Dave Blodgett"
    affiliation: USGS
  - name: "Michael Dumelle"
    affiliation: EPA
  - name: "Shelly Thawley"
    affiliation: EPA
  - name: "Kenny Wong"
    affiliation: ORISE at EPA
footer: "EPATADA, dataRetrieval, nhdplusTools, StreamCatTools, hydroloom, spsurvey, spmodel, SSN2, sf, prism, terra, leaflet and tmap"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# DRAFT WORKSHOP PRESENTATION

## (5 mins) Introduction

This workshop showcases how to integrate several R Packages developed by the U.S. Environmental Protection Agency (EPA) and the U.S. Geological Survey (USGS) to create efficient and reproducible workflows that support water quality programs and research. For example, performing watershed or waterbody level analyses such as Clean Water Act Assessments.

## Intended audience

Water Quality eXchange (WQX) and Water Quality Portal (WQP) community, Clean Water Act (CWA) Assessment community (EPA, States and Tribal Nations), water quality and geospatial data analysts/researchers, EPA/USGS and other federal agencies.

## Agenda

This workshop demonstrates potential uses (beyond their original collection purpose) for publicly available water quality data from Water Quality Portal (WQP). To start, participants will learn how to use EPA's Tools for Automated Data Analysis (TADA) R Package to retrieve, wrangle, harmonize, quality check, visualize and analyze WQP data from multiple organizations.

Next, we will showcase how to bring in other web services and libraries for easy integration of additional hydrologic data including USGS continuous sensor data (using the NLDI via DR?) and geospatial data (using StreamCat). We then plan to touch briefly on packages that can assist with building statistical models. Finally, we will demonstrate an example workflow for analyzing water quality by Assessment Units, which are state or tribal nation defined watershed or waterbody areas used for CWA assessments and reporting water quality conditions to EPA and the public.

## Packages

-   EPA: EPATADA, StreamCatTools, spsurvey, spmodel, SSN2

-   USGS: dataRetrieval/NLDI, nhdplusTools, hydroloom

-   Fundamental geospatial packages: sf, terra, leaflet and tmap

# (30 mins) Retrieving and Preparing Data for Analysis

# (15 mins) Leveraging the EPATADA R Package for WQP Discovery and Cleaning

Let's dive into Green Bay, WI!

## Install and load EPATADA

Install and load the remotes package.

```{r, eval = F}
if(!"remotes"%in%installed.packages()){
install.packages("remotes")
}

library(remotes)
```

Install and load the [EPATADA R Package](https://github.com/USEPA/EPATADA), StreamCatTools, and example data (NMC-Workshop-Data) for this workshop from GitHub.

```{r}
if(!"EPATADA"%in%installed.packages()){
  remotes::install_github(
    "USEPA/EPATADA",
    ref = "develop",
    dependencies = TRUE,
    force = TRUE
    )
}

if(!"StreamCatTools"%in%installed.packages()){
  remotes::install_github('USEPA/StreamCatTools')
}

if(!"NMCWorkshopData"%in%installed.packages()){
  remotes::install_github("mhweber/NMC-Workshop-Data")
}
if(!"nhdplusTools"%in%installed.packages()){
  remotes::install.packages("nhdplusTools")
}
library(EPATADA)
library(StreamCatTools)
library(NMCWorkshopData)
library(nhdplusTools)
```

It's go time! Let's time our process.

```{r}
# Record start time
start.time <- Sys.time()
```

## Intro to TADA Module 1: Water Quality Portal Data Discovery and Cleaning

This is an abbreviated introduction to key TADA Module 1 WQP Data Discovery and Cleaning functions. Additional functions and a more detailed example workflow is available [here](https://usepa.github.io/EPATADA/articles/TADAModule1.html).

## Retrieve data from the WQP

In this example, we will first use EPA's How's My Waterway (HMW) application to find an applicable Hydrologic Unit Code (HUC) for our area of interest - the [Fox River, Green Bay, WI](https://mywaterway.epa.gov/community/040302040405/monitoring). Next, let's query the WQP using the identified HUC, state abbreviation, and a date range. In this example, we'll start by pulling all data available in the WQP for this HUC 12 in Wisconsin for the last 5 years.

WATERSHED: City of Green Bay-Fox River (040302040405)

```{r}
# GreenBay_FoxRiver <- TADA_DataRetrieval(
#   statecode = "WI",
#   startDate = "2015-01-01",
#   endDate = "2024-12-30",
#   huc = c("040302040405"),
#   applyautoclean = TRUE
# )

GreenBay_FoxRiver <- NMCWorkshopData::GreenBay_FoxRiver
```

## Wrangle

Now, let's use EPATADA functions to review, visualize, and whittle the returned WQP data down to include only results that are applicable to our water quality analysis and area of interest.

![](images/Funnel.png)

## Flag and remove duplicate results from a single organization

```{r}
GreenBay_FoxRiver <- TADA_FindPotentialDuplicatesSingleOrg(GreenBay_FoxRiver)

GreenBay_FoxRiver <- dplyr::filter(GreenBay_FoxRiver, TADA.SingleOrgDup.Flag == "Unique")
```

## Autoclean

```{r}
GreenBay_FoxRiver <- TADA_AutoClean(GreenBay_FoxRiver)
```

## Handle censored results

```{r}
GreenBay_FoxRiver <- TADA_SimpleCensoredMethods(GreenBay_FoxRiver, nd_method = "multiplier", nd_multiplier = 0.5, od_method = "as-is", od_multiplier = "null")
```

## Flag and remove duplicates from multiple organizations

Two organizations sometimes submit the same exact data to WQP.

```{r}
GreenBay_FoxRiver <- TADA_FindPotentialDuplicatesMultipleOrgs(GreenBay_FoxRiver)

GreenBay_FoxRiver <- dplyr::filter(GreenBay_FoxRiver, TADA.ResultSelectedMultipleOrgs == "Y")
```

## Filter out any remaining irrelevant data, NA's and empty columns

```{r}
unique(GreenBay_FoxRiver$TADA.ResultMeasureValueDataTypes.Flag)

sum(is.na(GreenBay_FoxRiver$TADA.ResultMeasureValue))

GreenBay_FoxRiver <- TADA_AutoFilter(GreenBay_FoxRiver)
# CM note for TADA team discussion: Should results with NA units be dealt with here or in the TADA unit conversions function? These have not yet been addressed

unique(GreenBay_FoxRiver$TADA.ResultMeasureValueDataTypes.Flag)

sum(is.na(GreenBay_FoxRiver$TADA.ResultMeasureValue))
```

## Flag and remove QAQC samples and suspect results

```{r}
GreenBay_FoxRiver <- TADA_RunKeyFlagFunctions(GreenBay_FoxRiver, clean = TRUE)
```

## Flag results above and below threshold, but do not remove them

```{r}
GreenBay_FoxRiver <- TADA_FlagAboveThreshold(GreenBay_FoxRiver, clean = FALSE, flaggedonly = FALSE)

GreenBay_FoxRiver <- TADA_FlagBelowThreshold(GreenBay_FoxRiver, clean = FALSE, flaggedonly = FALSE)
```

## Harmonize synonyms across characteristic, fraction, and speciation

```{r}
GreenBay_FoxRiver <- TADA_HarmonizeSynonyms(GreenBay_FoxRiver)
```

## Calculate Total N and Total P from various species and fractions

```{r}
GreenBay_FoxRiver <- TADA_CalculateTotalNP(GreenBay_FoxRiver, daily_agg = "max")
```

## Review unique characteristic, fraction, and species combinations

```{r}
GreenBay_FoxRiver_Counts <- TADA_FieldValuesTable(GreenBay_FoxRiver, field = "TADA.ComparableDataIdentifier")

DT::datatable(GreenBay_FoxRiver_Counts, fillContainer = TRUE)
```

## Filter to focus on frequently monitored characteristics in example data

```{r}
GreenBay_FoxRiver_Subset <- GreenBay_FoxRiver %>%
  dplyr::filter(TADA.ComparableDataIdentifier %in%
      c("SPECIFIC CONDUCTANCE_NA_NA_US/CM", 
      "PH_NA_NA_NA", 
      "TOTAL NITROGEN, MIXED FORMS_UNFILTERED_AS N_MG/L",
      "TOTAL PHOSPHORUS, MIXED FORMS_UNFILTERED_AS P_UG/L",
      "DISSOLVED OXYGEN (DO)_NA_NA_MG/L"))
```

## Review organizations for subset

```{r}
# Create pie of results by organization
TADA_FieldValuesPie(GreenBay_FoxRiver_Subset, field = "OrganizationFormalName")
```

## EPATADA Visualizations

## Generate stats table

```{r}
GreenBay_FoxRiver_Subset_Stats <- TADA_Stats(GreenBay_FoxRiver_Subset)

DT::datatable(GreenBay_FoxRiver_Subset_Stats, fillContainer = TRUE)
```

## Generate scatterplot

```{r}
TADA_TwoCharacteristicScatterplot(GreenBay_FoxRiver_Subset, id_cols = "TADA.ComparableDataIdentifier",  groups = c("TOTAL PHOSPHORUS, MIXED FORMS_UNFILTERED_AS P_UG/L", "TOTAL NITROGEN, MIXED FORMS_UNFILTERED_AS N_MG/L"))
```

## Generate map

```{r}
TADA_OverviewMap(GreenBay_FoxRiver_Subset)

GreenBay_FoxRiver = TADA_FlagCoordinates(GreenBay_FoxRiver_Subset, clean_outsideUSA = "change sign", clean_imprecise = FALSE)

# CM note for TADA team discussion: Should results with NA lat/long be addressed within TADA_FlagCoordinates? For example, this df has NA lons from USGS that must be addressed before TADA_MakeSpatial can be run... 
# sum(is.na(GreenBay_FoxRiver$LongitudeMeasure))
GreenBay_FoxRiver_Subset <- GreenBay_FoxRiver_Subset[!is.na(GreenBay_FoxRiver_Subset$LongitudeMeasure),]
```

## (15-30 mins) Ingestion of additional hydrologic data using NLDI and Streamcat

## Make spatial

```{r}
GreenBay_FoxRiver_sf = TADA_MakeSpatial(GreenBay_FoxRiver_Subset)
```

We create a unique identifier based on shared lat long values and filter to just the 26 unique locations

```{r}
GreenBay_FoxRiver_sf$latlon <- paste0(GreenBay_FoxRiver_sf$TADA.LongitudeMeasure, GreenBay_FoxRiver_sf$TADA.LatitudeMeasure)

GreenBay_FoxRiver_sf <- GreenBay_FoxRiver_sf |> 
  dplyr::group_by(latlon) |> 
  dplyr::mutate(loc_id = dplyr::cur_group_id())

GreenBay_FoxRiver_sf_locs <- GreenBay_FoxRiver_sf |>
  dplyr::filter(!duplicated(loc_id))
```

## Access NHDPlus COMIDs for sites

We use `StreamCatTools` function `sc_get_comid` (which uses an `nhdplusTools` web service client) to get the comid for each location.

```{r}
library(StreamCatTools)

GreenBay_FoxRiver_sf_locs$COMID <- as.integer(strsplit(StreamCatTools::sc_get_comid(GreenBay_FoxRiver_sf_locs), split = ",")[[1]])

nhdplus_data <- nhdplusTools::subset_nhdplus(GreenBay_FoxRiver_sf_locs$COMID, nhdplus_data = "download")

outlet <- dplyr::filter(nhdplus_data$NHDFlowline_Network, hydroseq == min(hydroseq)) 

nhdplusTools::plot_nhdplus(bbox = sf::st_bbox(outlet))
plot(sf::st_transform(sf::st_geometry(GreenBay_FoxRiver_sf_locs), 3857), add = TRUE)
```

## dataRetrieval/NLDI, nhdplusTools, hydroloom (Dave Blodgett)

Do a network navigation and get NHDPlus for our data. Note that the network navigation only includes flowline geometry. `nhdplusTools` subsets all of the NHDPlus.

```{r}
all_network <- dataRetrieval::findNLDI(comid = outlet$comid, nav = "UT", distance_km = 500)

# we could select only comids on network
if(FALSE) # don't run this one
  nhdplus_data <- nhdplusTools::subset_nhdplus(comids = as.integer(all_network$UT_flowlines$nhdplus_comid), nhdplus_data = "download", flowline_only = FALSE)


# or we could just get everything in the bbox to be sure we get non-network stuff too!
nhdplus_data <- nhdplusTools::subset_nhdplus(
  bbox = sf::st_bbox(all_network$UT_flowlines), 
  nhdplus_data = "download", 
  flowline_only = FALSE)

# see ?nhdplusTools::subset_nhdplus for lots more options!

sapply(nhdplus_data, nrow)

sapply(nhdplus_data, names)
```

### Addressing sites to the network:

There are two forms of hydrographic addresses: catchment indexing and linear referencing. The former is established with a point in polygon analysis. The latter is more nuanced. The following block shows how to establish both with the data we just retrieved.

Note that hydroloom is compatible with nhdplus and other attribute systems. See [hydroloom documentation for more!](https://doi-usgs.github.io/hydroloom/articles/hydroloom.html)

```{r}
GreenBay_FoxRiver_sf_locs <- sf::st_join(
  GreenBay_FoxRiver_sf_locs, 
  hydroloom::st_compatibalize(dplyr::select(nhdplus_data$CatchmentSP, featureid),
                              GreenBay_FoxRiver_sf_locs))

# NOTE that featureid and comid are the same!!
all(GreenBay_FoxRiver_sf_locs$COMID == GreenBay_FoxRiver_sf_locs$featureid)

(linear_references <- hydroloom::index_points_to_lines(
  nhdplus_data$NHDFlowline_Network,
  GreenBay_FoxRiver_sf_locs))

GreenBay_FoxRiver_sf_locs <- dplyr::bind_cols(GreenBay_FoxRiver_sf_locs, linear_references)
```

We can take this one step further by indexing points to waterbodies! The return here tells us what waterbody our locations are near or within. For on-network waterbodies, it will also include the outlet flowling for each waterbody.

```{r}
all_wb <- dplyr::bind_rows(dplyr::select(nhdplus_data$NHDWaterbody, wbid = comid),
                           dplyr::select(nhdplus_data$NHDArea, wbid = comid))

(waterbody_indexes <- hydroloom::index_points_to_waterbodies(
  sf::st_transform(all_wb, 5070), 
  GreenBay_FoxRiver_sf_locs, 
  flines = nhdplus_data$NHDFlowline_Network, 
  search_radius = units::as_units(1000, "m")))
```

```{r}
par(mar=c(0,0,0,0))
nhdplusTools::plot_nhdplus(bbox = sf::st_bbox(GreenBay_FoxRiver_sf), 
                           cache_data = tempfile(fileext = ".rds"))
plot(sf::st_transform(all_wb[all_wb$wbid %in% waterbody_indexes$near_wbid,], 
                      3857),
     add = TRUE, 
     col = "darkblue", border = NA)
plot(sf::st_transform(sf::st_geometry(GreenBay_FoxRiver_sf_locs), 3857), add = TRUE, col = "white")
```

There's much much more where that came from. See the pkgdown sites for [nhdplusTools](https://doi-usgs.github.io/nhdplusTools/) and [hydroloom](https://doi-usgs.github.io/hydroloom/index.html) for more!

## Accessing watershed information for sites (Marc Weber)

### Discover what StreamCat metrics we might want to use

Will draft here

### Discover land cover of waterhsheds for sites

We'll pull in all the NLCD categories at the local catchment level for each location

```{r}
library(ggplot2)
GB_FR_NLCD <- sc_nlcd(year='2019', aoi='cat', comid=GreenBay_FoxRiver_sf_locs$COMID)


GB_FR_Urb <- GB_FR_NLCD |> 
  dplyr::mutate(Pct_Urbanized = pcturbop2019cat+pcturbmd2019cat+pcturblo2019cat+pcturbhi2019cat) |> 
  dplyr::select(comid,Pct_Urbanized)
GB_FR_Urb
```

### Visualize urbanization for local catchment for each location

```{r}
ggplot(GB_FR_Urb, aes(x=Pct_Urbanized)) + 
  geom_density()
```

### Pull in data for modeling using `StreamCatTools`

Now we'll just demonstrate pulling in watershed data that we might use in a modeling exercise as spatial covariates

```{r}
ws_data <- sc_get_data(metric='fert,nsurp,nani,manure,IWI', aoi='cat,ws', comid=GreenBay_FoxRiver_sf_locs$COMID)
```

# (5 mins) Example Use Case 1: Building Statistical Models

## Spatial Dependence

-   For spatial data, nearby observations tend to be more similar than distant observations

-   This phenomena is called *spatial dependence* and can be built into statistical models

-   The benefits of incorporating spatial dependence are *significant* and include:

    -   More realistic characterization of ecological drivers
    -   More precise predictions at unobserved locations

## The `spmodel` R package

-   The `spmodel` R package makes spatial models accessible via straightforward extensions to common modeling functions like `lm()` and `glm()`
-   Spatial dependence is based on Euclidean (straight-line) distance
-   Learn more at <https://usepa.github.io/spmodel/>

## The `SSN2` R package

-   Like `spmodel`, `SSN2` extends common modeling functions like `lm()` and `glm()`
-   Spatial dependence is based on stream network distance (flow-connected, flow-unconnected)
-   `SSN2` is an updated version of `SSN` (`SSN` has been archived)
-   Learn more at <https://usepa.github.io/SSN2/>

# (30 mins) Example Use Case 2: Clean Water Act (CWA) Section 303(d) Assessments Part A

TADA_MakeSpatial(), TADA_GetATTAINS(), TADA_ViewATTAINS()

## TADA Module 2: Geospatial Functions

Additional functions and a more detailed example workflow is available here: <https://usepa.github.io/EPATADA/articles/TADAModule2.html>

## CWA Assessment Process

We do not have time to cover the full process today. Let's focus on geospatial aspects!

[Integrated Reporting Memoranda under CWA Sections 303(d), 305(b) and 314](https://www.epa.gov/tmdl/Integrated%20Reporting%20Guidance%20under%20CWA%20Sections%20303%28d%29%2C%20305%28b%29%20and%20314).

## What are Assessment Units?

Geospatial areas for analysis. Let's assign data to those units!

CWA assessment determinations are made by assessment unit, meaning the entire assessment unit is assessed as either meeting or not meeting water quality standards (i.e., thresholds or criteria) for all designated uses.

## How are assessment units delineated?

Assessment units are typically delineated by using watershed-oriented collections of stream reaches, often broken down by physical features like waterfalls, bridge crossings, or changes in land use, to analyze water quality impairments within a specific area, ensuring data homogeneity and spatial clarity within the assessment unit.

-   Existing Assessment Units are available from ATTAINS geospatial services

## Associating ATTAINS Assessment Units with WQP Monitoring Locations

One of the first steps in the CWA assessment process is to define Assessment Units and associate data with them. A major source for water quality data is the WQP.

## Associating ATTAINS Assessment Units with WQP Monitoring Locations

-   Assessment Units: state or tribal waterbody geospatial features
    -   These may be lines, areas or points
-   Water Quality Portal Monitoring Locations
    -   These are points

## TADA_GetATTAINS()

-   Automates matching of WQP monitoring locations with ATTAINS assessment units that fall within (intersect) the same NHDPlus catchment ([details](https://usepa.github.io/EPATADA/articles/TADAModule2.html))
-   The function uses high resolution NHDPlus catchments by default because 80% of state submitted assessment units in ATTAINS were developed based on high res NHD; users can select med-res if applicable to their use case

```{r}
WQP_with_ATTAINSonly <- TADA_GetATTAINS(GreenBay_FoxRiver_Subset, fill_catchments = FALSE, return_sf = TRUE)
```

## TADA_ViewATTAINS()

-   Allows for viewing the

## Challenges with Automated Approach

-   Certain NHDPlus high res catchments overlap multiple ATTAINS assessment units (state submitted hydrography) which means the sites are assigned to both AUs in the current functions. Another challenge is that the WQP sites are not always accurate (imprecise coordinates). WQP location metadata may also be helpful for matching/QAQC'ing waterbody names with ATTAINS waterbody names instead of relying solely on the lat/long and geospatial/mapping information. Users must manually review associations for accuracy.

## Using all available data from the WQP

Finally, some waterbodies have data available in the WQP or from other sources, but there are no existing Assessment Units in ATTAINS for them. In the next section, we will share a way to create AU's using NHDPlus high resolution catchments.

# Example Use Case 2: Clean Water Act (CWA) Section 303(d) Assessments Part B

nhdplusTools, TADA::fetchNHD(), TADA_GetATTAINS(), TADA_ViewATTAINS()

## Creating new AUs to assess additional areas (leveraging USGS's nhdplusTools and TADA geospatial functions)

TADA has included a way to do this using TADA_GetATTAINS() fill_catchments function input. This is included for exploratory purposes only. In theory, states and tribal nations could use the high res catchments as new assessment unit polygons to assess additional areas where there is WQP data but no Assessment Unit yet in ATTAINS, but that process is outside of TADA.

## Creating new AUs to assess additional areas

For WQP monitoring sites that DO NOT overlap an existing ATTAINS feature (neither ATTAINS NHDPlus high res catchment snap shot or state submitted points/lines/polys), there is nothing to use from ATTAINS because these are areas where there is WQP data but no ATTAINS Assessment Unit yet.

## Creating new AUs to assess additional areas

For these, we implemented a solution using NHDPlusTools to pull in either NHDPlus high res or med res catchments (user can choose, but high res is the default) and match those with the WQP sites & create new IDs (essentially creating new AUs that are the catchments that intersect these WQP sites).

```{r}
WQP_withATTAINSandNHDPluscatchments <- TADA_GetATTAINS(GreenBay_FoxRiver_Subset, fill_catchments = TRUE, return_sf = TRUE)
```

# (15 mins) Visualizing Water Quality Issues

-   Placeholder: Now that we have data assigned to watershed/waterbodies (Assessment Units). Let's showcase how to visualize water quality issues for a few characteristics of interest on a map and in figures using available packages.

# (5 mins) Conclusion

```{r}
end.time <- Sys.time()

end.time - start.time
```

## Contribute

Note: TADA is still under development. New functionality is added weekly, and sometimes we need to make bug fixes in response to tester and user feedback. We appreciate your feedback, patience, and interest in these helpful tools.

If you are interested in contributing to TADA development, more information is available at:

<https://usepa.github.io/EPATADA/articles/CONTRIBUTING.html>

We welcome collaboration with external partners.

Contribute to EPATADA in a way that helps elevate work you have already done, broadens the user base of the package, or improves the resource for all!

## Thank you to our workshop contributors!

-   EPA: Cristina Mullin (mullin.cristina\@epa.gov), Marc Weber, Hillary Marler, Kenny Wong, Michael Dumelle, Shelly Thawley

-   USGS: Dave Blodgett

## Thank you for your attention!
