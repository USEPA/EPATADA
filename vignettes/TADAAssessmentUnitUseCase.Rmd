---
title: "TADA: Assessment Unit Use Case Demo"
format: html
editor: visual
author: "TADA Team"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{TADA: Assessment Unit Use Case Demo}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
description: An overview of a TADA use case.
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: 72
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  cache = TRUE,
  collapse = TRUE,
  comment = "#>",
  eval = FALSE
)
```

```{css, echo=FALSE}
pre {
  max-height: 300px;
  overflow-y: auto;
}

pre[class] {
  max-height: 100px;
}
```

## Overview

This vignette walks through the specific use case of query, downloading,
preparing, QA/QCing data from a single Assessment Unit with multiple
Monitoring Locations sampled by several organizations. Three
characteristics, pH, water temperature, and total nitrogen are used in
this example. Two of the characteristics, pH and water temperature, will
be compared to a state water quality standard from Illinois. The third
characteristic, total nitrogen, does not have an Illinois water quality
standard, but is used to demonstrate some helpful functions for data
exploration and visualization.

## Load Required Packages

The fist step is to load the TADA package and other packages used in our
workflow.

```{r library, results = 'hide', message = FALSE, warning = FALSE}
# Load required packages

library(TADA)
library(dplyr)
library(yaml)
library(lwgeom)
library(sf)
library(lubridate)
library(knitr)

start.time <- Sys.time()

```

## Data Retrieval - Water Chemistry

All water chemistry data used in this example are downloaded from the
Water Quality Portal (<https://www.waterqualitydata.us/>). The WQP
integrates publicly available water quality data from the USGS National
Water Information System (**NWIS**) and the EPA Water Quality Exchange
(**WQX**) Data Warehouse. The EPA water quality data originate from the
[Water Quality
Exchange](https://www.epa.gov/waterdata/water-quality-data), the EPA's
repository of water quality monitoring data collected by water resource
management groups across the country. Organizations, including states,
tribes, watershed groups, other federal agencies, volunteer groups, and
universities, submit data to the WQX in order to make their data
publicly accessible.

We can use TADA_DataRetrieval to retrieve WQP data. In this example, we
have specififed lists of HUCs and Characteristic Types to reduce the
size of the query since we have a general idea of the location of our
assessment unit of interest and know which characteristics we'd like to
explore.

```{r TADA_DataRetrieval}
# Import data from WQP

data <- TADA_DataRetrieval(statecode = "IL",
                           startDate = "2010-01-01", 
                           endDate = "2020-12-31", 
                           huc = c("0714010505", "0714010504", "0714010508", "0714010501", "0714010503"),
                           characteristicType = c("Nutrient", "Physical"),
                            applyautoclean = TRUE)
```

## AutoClean

TADA_AutoClean is performed automatically with TADA_DataRetrieval unless
specified otherwise by the user (by setting applyautoclean = FALSE).
When TADA_AutoClean is run, the following functions are performed on the
data retrieved from the WQP:

-   **TADA_ConvertSpecialChars** - converts result value columns to
    numeric and flags non-numeric values that could not be converted.

-   **TADA_ConvertResultUnits** - unifies result units for easier
    quality control and review

-   **TADA_ConvertDepthUnits** - converts depth units to a consistent
    unit (meters).

-   **TADA_IDCensoredData** - categorizes detection limit data and
    identifies mismatches in result detection condition and result
    detection limit type.

-   Other helpful actions - converts important text columns to all
    upper-case letters, removes exact duplicates, and uses WQX format
    rules to harmonize specific NWIS metadata conventions (e.g. move
    characteristic speciation from the
    TADA.ResultMeasure.MeasureUnitCode column to the
    TADA.MethodSpeciationName column)

As a general rule, TADA functions do not change any contents in the
WQP-served columns. Instead, they add new columns with the prefix
"TADA."

## Data Retrieval - Geospatial

All geospatial data used in this example are downloaded from the
Assessment Total Maximum Daily Load (TMDL) Tracking and Implementation
System (**ATTAINS**) (<https://www.epa.gov/waterdata/attains>).
**ATTAINS** is an online system for accessing information about the
conditions in the Nation's surface waters.

This information reported to EPA by states is available in ATTAINS. The
public information is made available via ATTAINS web services,
geospatial services, as well as through other EPA tools. New TADA
functions leverage the ATTAINS geospatial services to make geospatial
information including catchment and assessment unit geometry easily
accessible to R users.

We can use the function, TADA_GetATTAINS to obtain geospatial data from
ATTAINS relevant to the Monitoring Locations included in the WQP data
set.

```{r TADA_GetAttains}
# Import data from ATTAINS geospatial services

ATTAINS_data <- TADA_GetATTAINS(data)
```

## View Geospatial Features

The **TADA_ViewATTAINS** function allows us to see where the monitoring
locations from the WQP data set are relative to **ATTAINS-**indexed
catchments and assessment units. This can be helpful when deciding which
monitoring locationsshould be retained for additional analysis. For this
demo, we will select a single assessment unit, IL-84, with multiple
monitoring locations (*MonitoringLocationIdentifier*).

```{r TADA_ViewAttains}
# View catchments and assessment units on map

ATTAINS_map <- TADA_ViewATTAINS(ATTAINS_data)

ATTAINS_map
```

## Monitoring Location Filter and Review

Now that we've selected an assessment unit, we can filter the data set
to retain only results that were collected in the specified assessment
unit. We can also generate a new table to give us some information about
the individual monitoring locations within the assessment unit. Let's
remove the "ATTAINS." prefixed columns to reduce the size of the data
set, as we won't need them for the next steps. We can add them back
again later as needed.

We can also create a table with some basic information about the
Monitoring Locations in assessment unit IL-84 and a pie chart to display
the relative number of results contributed by each organization.

```{r Data Retrieval - Geospatial}

# Filter data for specified assessment unit

AUID_data <- ATTAINS_data$TADA_with_ATTAINS %>%
  dplyr::filter(ATTAINS.assessmentunitidentifier == "IL_I-84")

Analysis_data <- ATTAINS_data$TADA_with_ATTAINS %>%
  dplyr::filter(ATTAINS.assessmentunitidentifier == "IL_I-84") %>%
  dplyr::select(-contains("ATTAINS.")) %>%
  sf::st_drop_geometry() %>%
  TADA_RetainRequired()
  

# Create table of monitoring location indentifiers

MonitoringLocations <- Analysis_data %>%
  dplyr::select(MonitoringLocationName, MonitoringLocationIdentifier, OrganizationFormalName) %>%
  dplyr::distinct()


# Create pie of results by organization
Orgs_pie <- TADA_FieldValuesPie(Analysis_data, field = "OrganizationFormalName")

Orgs_pie
  
```


```{r Hidden Calcuations}

# Determine number of organizations

norgs <- length(unique(Analysis_data$OrganizationFormalName))

# Determine number of monitoring locations

nmls <- length(unique(Analysis_data$MonitoringLocationIdentifier))

# Determine N results
nres <- length(Analysis_data$TADA.ResultMeasureValue)

# Determine earliest sample date

earlydate <- min(Analysis_data$ActivityStartDate)

# Determine latest sample date

latedate <- max(Analysis_data$ActivityStartDate)

```

We can see that there are `nmls` monitoring locations from ` norgs` organizations with
results from `earlydate` to `latedate`. There are `nres`
water chemistry results in the data frame.

## Water Chemistry Data Preparation and QC

Before we can begin comparisons between the water chemistry results and
a water quality standard, there are some additional data preparation and
QC steps that can be performed using TADA functions.

First, we can check the data for additional conditions which might cause
us to exclude certain results from further analysis. For example, we can
use TADA_FlagMethod to check for invalid analytical
method-characteristic combinations; TADA_FlagSpeciation to check for
invalid characteristics-method speciation combinations,
TADA_FlagResultUnit to check the the validity of each characteristic-media-result unit combination. In this simple example, we will remove all in invalid combinations, but you will likely review each more carefully in order to more thoroughly understand your data set.

```{r remove invalid combinations}

# Flag and remove results

Analysis_data <- Analysis_data %>%
  TADA_FlagMethod(clean = TRUE) %>%
  TADA_FlagSpeciation(clean = "both") %>%
  TADA_FlagResultUnit(clean = "both") %>%
  TADA_FlagFraction(clean = TRUE)
```

Another set of TADA flagging functions can be used to check results aginst national lower and upper thresholds. As in the previous examples, we will set these functions to remove any results that fall outside the national thresholds.

```{r remove outside thresholds}

# Flag and remove results

Analysis_data <- Analysis_data %>%
  TADA_FlagAboveThreshold(clean = TRUE) %>%
  TADA_FlagBelowThreshold(clean = TRUE)
  
```

We can also review the data set to see if it contains potential duplicate results from within a single organization or potential duplicates from within multiple organizations (such as when two or more organizations monitor the same location and may submit duplicate results).

We will select to keep only unique samples from TADA_FindPotentialDuplicatesSingleOrg by filtering for TADA.SingleOrgDup.Flag equals "Unique". Then we will search for potential duplicates from multiple orgs with TADA_FindPotentialDuplicatesMultipleOrgs and filter only to retain only one value per potential duplicate by filtering for TADA.ResultSelectedMultipleOrgs equals "Y".


```{r remove potential dups}

# Flag and remove results

Analysis_data <- Analysis_data %>%
  TADA_FindPotentialDuplicatesSingleOrg() %>%
  dplyr::filter(TADA.SingleOrgDup.Flag == "Unique") %>%
  TADA_FindPotentialDuplicatesMultipleOrgs(dist_buffer = 100,
                                           org_hierarchy = "none") %>%
  dplyr::filter(TADA.ResultSelectedMultipleOrgs == "Y")

```

Next we can remove QC and qualified samples (with qualifiers identified as suspect).

```{r remove QC and qualified}

# Flag and remove results

Analysis_data <- Analysis_data %>%
  TADA_FindQCActivities(clean = TRUE) %>%
  TADA_FlagMeasureQualifierCode(clean = TRUE)

```

## Censored data

Censored data are measurements for which the true value is not known,
but we can estimate the value based on lower or upper detection
conditions and limit types. TADA fills missing *TADA.ResultMeasureValue*
and *TADA.ResultMeasure.MeasureUnitCode* values with values and units
from *TADA.DetectionQuantitationLimitMeasure.MeasureValue* and
*TADA.DetectionQuantitationLimitMeasure.MeasureUnitCode*, respectively,
using the TADA_AutoClean function. 

The TADA package currently has functions that summarize censored data
incidence in the dataset and perform simple substitutions of censored
data values, including x times the detection limit and random selection
of a value between 0 and the detection limit. The user may specify the
methods used for non-detects and over-detects separately in the input to
the **TADA_SimpleCensoredMethods** function.

All censored data functions depend first on the **TADA_IDCensoredData**
utility function, which assigns a *TADA.CensoredData.Flag* to all data
records and identifies over-detects from non-detects using the
*ResultDetectionConditionText* and *DetectionQuantitationLimitTypeName*.
This utility function is automatically run within the TADA_DataRetrieval
function and produces the *TADA.CensoredData.Flag* column. A
The next step we take in this example is to perform simple conversions
to the censored data in the dataset: we keep over-detects as is (no
conversion made) and convert non-detect values to 0.5 times the
detection limit (half the detection limit). 

```{r SummarizeCensoredData}

Analysis_data <- TADA_SimpleCensoredMethods(Analysis_data,
  nd_method = "multiplier",
  nd_multiplier = 0.5,
  od_method = "as-is",
  od_multiplier = "null"
)
```

## Harmonize Results

The **TADA_GetSynonymRef** function generates a synonym reference table
that is specific to the input dataframe. Users can review how their
input data relates to standard TADA values for the following elements: *TADA.CharacteristicName*, *TADA.ResultSampleFractionText*, *TADA.MethodSpeciationName*, and *TADA.ResultMeasure.MeasureUnitCode* and edit if desired.

Users can also edit the reference file to meet their needs if desired.
The download argument can be used to save the harmonization file to your
current working directory when download = TRUE, the default is download
= FALSE.

The **TADA_HarmonizeSynonyms** function then compares the input
dataframe to the TADA Synonym Reference Table and makes conversions
where target characteristics/fractions/speciations/units are provided.
This function also appends a column called TADA.Harmonized.Flag,
indicating which results had metadata changed/converted in this
function. The purpose of this function is to make similar data
consistent and therefore easier to compare and analyze.


```{r TADA_HarmonizeSynonyms}
UniqueHarmonizationRef <- TADA_GetSynonymRef(Analysis_data)

UniqueHarmonizationRef_edit <- UniqueHarmonizationRef %>%
  dplyr::mutate(Target.TADA.CharacteristicName = ifelse(TADA.CharacteristicName == "TEMPERATURE, WATER", "TEMPERATURE", TADA.CharacteristicName),
                Target.TADA.ResultSampleFractionText = ifelse(TADA.CharacteristicName == "PH", NA, Target.TADA.ResultSampleFractionText),
                HarmonizationGroup = ifelse(TADA.CharacteristicName == "PH", "PH", HarmonizationGroup),
                HarmonizationGroup = ifelse(Target.TADA.CharacteristicName == "TEMPERATURE", "TEMPERATURE",
                                            HarmonizationGroup))

Harmonized_data <- TADA_HarmonizeSynonyms(Analysis_data,
  ref = UniqueHarmonizationRef_edit
)
```

## Total Nitrogen and Total Phosphorus Calculations

This section covers summing nutrient subspecies to estimate total
nitrogen and phosphorus. This can be a challenging endeavor because some
subspecies/compounds overlap in total nutrient calculations. Thus,
**TADA_CalculateTotalNP** uses the [Nutrient Aggregation
logic](https://echo.epa.gov/trends/loading-tool/resources/nutrient-aggregation)
to add together specific subspecies to obtain a total. TADA adds one
more equation to the mix: total particulate nitrogen + total dissolved
nitrogen. The function uses as many subspecies as possible to calculate
a total for each given site, date, and depth group, but it will estimate
total nitrogen with whatever subspecies are present. This function
creates NEW total nutrient measurements (total nitrogen unfiltered as N
and total phosphorus unfiltered as P) and adds them to the dataframe.

Users can use the default summation worksheet (see
**TADA_GetNutrientSummationRef**) or customize it to suit their needs.
The function also requires a daily aggregation value, either minimum,
maximum, or mean. The default is 'max', which means that if multiple
measurements of the same subspecies-fraction-speciation-unit occur on
the same day at the same site and depth, the function will pick the
maximum value to use in summation calculations.

```{r, TADA_CalculateTotalNP}
Harmonized_data <- TADA_CalculateTotalNP(Harmonized_data, daily_agg = "max")
```

## Parameter Level Filtering

Now we can filter to our three parameters of interest and using *TADA_Stats* take a look at some basic statistics for each, including location count, measurement count, min, max, and more.

```{r parameter level filtering}
# review unique identifiers
unique(Harmonized_data$TADA.ComparableDataIdentifier)

# filter for three comparable data identifiers of interest
Filtered_data <- Harmonized_data %>%
  dplyr::filter(TADA.ComparableDataIdentifier %in% c("TEMPERATURE_NA_NA_DEG C", "PH_NA_NA_NA", "TOTAL NITROGEN, MIXED FORMS_TOTAL RECOVERABLE_NA_MG/L" ))

# generate stats table
Filtered_data_stats <- TADA_Stats(Filtered_data)
```

## Standard Comparisons With Scatterplot and Pie Chart

Next, we will create a two characteristic scatterplot of pH and temperature to begin visualizing the data, using *TADA_TwoCharacteristicScatterplot*.

```{r two param scatterplot}

# choose two and generate scatterplot
TADA_TwoCharacteristicScatterplot(Harmonized_data, id_cols = "TADA.ComparableDataIdentifier", groups = c("TEMPERATURE_NA_NA_DEG C", "PH_NA_NA_NA"))
```

Let's focus on just one characteristic, pH. We can filter the data frame to retain only pH samples. We can also add a column to indicate whether each result falls within the water quality standard range for pH (6.5 - 9). From this pH-only frame we can create a table with just a few columns for easier review, and a single characteristic scatterplot using *TADA_Scatterplot*. In this example, horizontal lines have been added to indicate the upper and lower ends of the water quality standard. These are not a default option in *TADA_Scatterplot* but can be added via the *plotly* package.

```{r ph analysis and visualization}
# comparison to standard for compid2

pH_Standard <- Filtered_data %>%
  dplyr::filter(TADA.ComparableDataIdentifier == "PH_NA_NA_NA") %>%
  dplyr::mutate(MeetsStandard = ifelse(TADA.ResultMeasureValue >= 6.5 & TADA.ResultMeasureValue <= 9, "Yes", "No")) 


pH_Table <- pH_Standard %>%
  dplyr::select(MonitoringLocationIdentifier, OrganizationFormalName, ActivityStartDate, TADA.ResultMeasureValue,
                MeetsStandard)

pH_Scatter <- TADA::TADA_Scatterplot(pH_Standard, id_cols = "TADA.ComparableDataIdentifier") %>%
  plotly::add_lines(
    y = 6.5,
    x = c(min(pH_Standard$ActivityStartDate), max(pH_Standard$ActivityStartDate)),
    inherit = FALSE,
    showlegend = FALSE,
    line = list(color = "red"),
    hoverinfo = "none"
  ) %>%
   plotly::add_lines(
    y = 9,
    x = c(min(pH_Standard$ActivityStartDate), max(pH_Standard$ActivityStartDate)),
    inherit = FALSE,
    showlegend = FALSE,
    line = list(color = "red"),
    hoverinfo = "none"
  )
```

Comparison of temperature to water quality standards is a little more complicated as the maximum temperature varies by season and there are multiple components of the temperature standard. For this example, we will focus on the "shall never exceed" seasonal temperature standards. 

These are: 

17.7 deg C for January, February, March, and December

33.7 deg C for April, May, June, July, August, September, October, and November.

We can use *lubridate* and *dplyr* functions to assign the appropriate standard to each result by using *lubridate::month* to identify the month in which each sample was collected and *dplyr::mutate* to create a new column for the temperature standard. Then the results can be compared to the standard.

We can use *TADA_Scatterplot* again to visualize the data. Due to the seasonal variation in the standard and the ten-year date range in our data set, we may want to consider other visualizations to visually review the number of results not meeting the standard. We can use *TADA_FieldValuesPie* on the MeetsStandard field we created to see how many samples met or did not meet the standard.

Creating a table also allows for easy filtering of results to identify the results that did not meet the standard and review during which years and seasons they occurred. 

```{r temp analysis and visualization}
Temp_Standard <- Filtered_data %>%
  dplyr::filter(TADA.ComparableDataIdentifier == "TEMPERATURE_NA_NA_DEG C") %>%
  dplyr::mutate(MonthForAnalysis = lubridate::month(ActivityStartDate),
                TempStandard = ifelse(MonthForAnalysis %in% c(1,2,3,12), 17.7, 33.7),
                MeetsStandard = ifelse(TADA.ResultMeasureValue < TempStandard,
                                       "Yes", "No"))

Temp_Scatter <- TADA_Scatterplot(Temp_Standard, id_cols = "TADA.ComparableDataIdentifier") 

Temp_Pie <- TADA_FieldValuesPie(Temp_Standard, field = "MeetsStandard")

Temp_Table <- Temp_Standard %>%
  dplyr::select(MonitoringLocationIdentifier, OrganizationFormalName, ActivityStartDate, TADA.ResultMeasureValue, TempStandard,
                MeetsStandard)
  
```

## Additional Data Exploration

We may also want to use TADA functions for exploration and visualization of characteristics without water quality standards. For this example, we will use "TOTAL NITROGEN, MIXED FORMS_TOTAL RECOVERABLE_NA_MG/L".

To better understand the distribution of results, we can use the TADA functions **TADA_Histogram** and
**TADA_Boxplot**. 

**TADA_Histogram** can be useful for identifying the overall shape of the datat.

```{r boxplot and histogram}

# filter dataframe to comparable data identifier of interest

Nitrogen_data <- dplyr::filter(Filtered_data, TADA.ComparableDataIdentifier == "TOTAL NITROGEN, MIXED FORMS_TOTAL RECOVERABLE_NA_MG/L")

# generate a histogram
Nitrogen_Histogram <- TADA_Histogram(Compid1_data, id_cols = "TOTAL NITROGEN, MIXED FORMS_TOTAL RECOVERABLE_NA_MG/L")

# view histogram
Nitrogen_Histogram
```

**TADA_Boxplot** can be useful for identifying skewness and percentiles.

```{r boxplot, fig.width=8, fig.height=6, fig.fullwidth=TRUE}
Nitrogen_Boxplot <- TADA::TADA_Boxplot(Nitrogen_data, id_cols = "TADA.ComparableDataIdentifier") 
  

Nitrogen_Boxplot
```

Filtering the results of **TADA_Stats** for only "TOTAL NITROGEN, MIXED FORMS_TOTAL RECOVERABLE_NA_MG/L" and selecting a smaller subset of columns or creating a single characteristic scatterplot may also provide useful information.

```{r stats and scatterplot}
Nitrogen_Scatterplot <- TADA::TADA_Scatterplot(Nitrogen_data, id_cols = "TADA.ComparableDataIdentifier")

Nitrogen_Scatterplot
```

## Reproducible and Documented

Some of major benefits of a workflow like this are that is is both reproducible and the decisions at each step as far as data querying, review, QC, filtering, and analysis are well documented. This means that it is easy to go back, make changes as necessary, and run it again.

For example, we could change the Assessment Unit of interest, modify the relevant code chunks (potentially including the WQP query if the new Assessment Unit is in a different HUC or state) and repeat the same analysis for the same characteristics at a different location.

Or we could change or add additional characteristics to our analysis. We could also write additional custom functions or use use functions from other packages as needed for more complex standards, evaluate trends, or answer other questions using a TADA data frame.

The code chunk below displays the elapsed time it took to run the code chunks and create this document, providing an example of how incorporating TADA in your workflow can increase efficiency.

```{r analysis time}
end.time <- Sys.time()

end.time - start.time
```
