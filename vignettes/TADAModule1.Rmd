---
title: "TADA Module 1: Water Quality Portal Data Discovery and Cleaning"
author: "TADA Team"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\usepackage[utf8]{inputenc}
  %\VignetteIndexEntry{TADA Module 1: Water Quality Portal Data Discovery and Cleaning}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: 72
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{css, echo=FALSE}
pre {
  max-height: 300px;
  overflow-y: auto;
}

pre[class] {
  max-height: 100px;
}
```

## Download this Article from GitHub

Go to:
<https://github.com/USEPA/TADA/blob/develop/vignettes/TADAModule1.Rmd>

[![Click the highlighted icon to download TADAModule1.Rmd from GitHub.
Open this file in R Studio to follow along. Alternatively, you can copy
and paste desired lines of code herein into your own
script.](images/DownloadModule1.jpg)](https://github.com/USEPA/TADA/blob/develop/vignettes/TADAModule1.Rmd)

## Overview

This vignette walks through how to use the TADA R Package to discover
and clean (i.e., wrangle, Quality Assure and Quality Control (QAQC), and
harmonize) [Water Quality Portal
(WQP)](https://www.waterqualitydata.us/) data from multiple
organizations.

## Install and load packages

To install TADA, currently you need to install from GitHub using remotes
(shown) or devtools.

First, install and load the "remotes" package specifying the repo. This
is needed before installing TADA because it is only available on GitHub
(not CRAN).

```{r install_remotes, results = 'hide', message = FALSE, warning = FALSE}
install.packages("remotes",
  repos = "http://cran.us.r-project.org"
)
library(remotes)
```

Next, install and load TADA. dataRetrieval and other TADA R Package
dependencies will also be downloaded from CRAN with the TADA install,
but the development version can be downloaded directly from GitHub if
desired (un-comment).

```{r install_TADA, results = 'hide', message = FALSE, warning = FALSE}
# remotes::install_github("USGS-R/dataRetrieval", dependencies=TRUE)

# if you experience any issues installing TADA, try un-commenting and running
# the line below before the install
# options(download.file.method = "wininet")

remotes::install_github("USEPA/TADA",
  ref = "develop",
  dependencies = TRUE
)

library(TADA)
```

## Retrieve WQP data

WQP data is retrieved and processed for compatibility with TADA. This
function, **TADA_DataRetrieval**, builds on the USGS dataRetrieval
package functions. It joins four WQP profiles (i.e., Site metadata,
Sample Results (narrow), Sample Results (physical/chemical metadata),
and Project metadata. In addition, it changes all data in the
Characteristic, Speciation, Fraction, and Unit fields to uppercase,
removes true duplicates, and addressed result values that include
special characters.

This function uses the same inputs as the dataRetrieval `readWQPdata`
function. `readWQPdata` does not restrict the characteristics pulled
from [Water Quality Portal (WQP)](https://www.waterqualitydata.us/). You
may specify the desired characteristics by using, for instance:
characteristicName = "pH".

Data retrieval filters include:

-   startDate

-   endDate

-   characteristicName

-   sampleMedia

-   siteType

-   statecode (review list of possible state and territory
    [abbreviations](https://www2.census.gov/geo/docs/reference/state.txt))

-   countycode

-   siteid

-   organization

-   project

-   huc

-   characteristicType

Please be aware that the default TADA_DataRetrieval function
automatically runs the TADA **TADA_AutoClean** and
**TADA_ConvertSpecialChars** functions. Both are both required for
subsequent functions within the TADA R package to run. As a general
rule, TADA functions do not change any contents in the WQP-served
columns (enter *?TADA_ConvertSpecialChars* and *?TADA_AutoClean* into
the console for more details). Instead, they add new columns with the
prefix "TADA." The following columns are numeric versions of their WQP
origins:

    -   TADA.ResultMeasureValue

    -   TADA.DetectionQuantitationLimitMeasure.MeasureValue

    -   TADA.LatitudeMeasure

    -   TADA.LongitudeMeasure

These functions also add the columns
TADA.ResultMeasureValueDataTypes.Flag and
TADA.DetectionQuantitationLimitMeasure.MeasureValueDataTypes.Flag, which
provide information about the result values that is needed to address
censored data later on (i.e., nondetections). Specifically, these new
columns flag if special characters are included in result values, and
specifies what the special characters are.

Downloads using TADA_DataRetrieval will have the same columns each time,
but be aware that data are uploaded to the Water Quality Portal by
individual organizations, which may or may not follow the same
conventions. Data and metadata quality are not guaranteed! Make sure to
carefully explore any data and make conservative quality assurance
decisions where information is limited.

Tips:

1.  All the query filters for the WQP work as an AND but within the
    fields there are ORs. For example:

    -   Characteristics: If you choose pH & DO - it's an OR. This means
        you will retrieve both pH OR DO data if available.

    -   States: Similarly, if you choose VA and IL, it's an OR. This
        means you will retrieve both VA OR IL data if available.

    -   Combinations of fields are ANDs, such as State/VA AND
        Characteristic/DO". This means you will receive all DO data
        available in VA.

    -   "Characteristic" and "Characteristic Type" also work as an AND.
        This means that the Characteristic must fall within the
        CharacteristicGroup if both filters are being used, if not you
        will get an error.

2.  The "siteid" is a general term WQP uses to describe both Site IDs
    from USGS databases and Monitoring Location Identifiers (from the
    Water Quality Portal). Each monitoring location in the Water Quality
    Portal (WQP) has a unique Monitoring Location Identifier, regardless
    of the database from which it derives. The Monitoring Location
    Identifier from the WQP is the concatenated Organization Identifier
    plus the Site ID number. Site IDs that only include a number are
    only unique identifiers for monitoring locations within USGS NWIS or
    EPA's WQX databases separately.

Additional resources:

-   Review function documentation by entering the following code into
    the console: ?TADA_DataRetrieval

-   [Introduction to the dataRetrieval
    package](https://CRAN.R-project.org/package=dataRetrieval)

-   [General Data Import from Water Quality
    Portal](https://rdrr.io/cran/dataRetrieval/man/readWQPdata.html)

-   [Water Quality Portal Web Services
    Guide](https://www.waterqualitydata.us/webservices_documentation/)

-   [dataRetrieval Tutorial](https://owi.usgs.gov/R/dataRetrieval.html)

## dataRetrieval

Uncomment below if you would like to review differences between the
profiles you would get using readWQPdata vs. TADA_DataRetrieval. The
profiles are different because TADA_DataRetrieval automatically joins in
data from multiple WQP profiles, and does some additional data cleaning
as part of the data retrieval process.

This example includes monitoring data collected from Jan 2018 to Jan
2019 by six organizations: 1) Red Lake Band of Chippewa Indians, 2) Sac
& Fox Nation, 3) Pueblo of Pojoaque, 4) Minnesota Chippewa Tribe (Fond
du Lac Band), 5) Pueblo of Tesuque, and 6) The Chickasaw Nation

We will move forward with this example in the remainder of the vignette.

```{r dataRetrieval_example}
# dataRetrieval_example <- dataRetrieval::readWQPdata(organization = c("REDLAKE_WQX", "SFNOES_WQX", "PUEBLO_POJOAQUE", "FONDULAC_WQX", "PUEBLOOFTESUQUE", "CNENVSER"), startDate = "2018-01-01", endDate = "2019-01-01", ignore_attributes = TRUE)
```

Use the code below to download data from the WQP using
TADA_DataRetrieval. Edit the code chuck below to define your own WQP
query inputs.

Note: TADA_DataRetrieval (by leveraging dataRetrieval), automatically
converts the date times to UTC. It also automatically converts the data
to dates, datetimes, and numerics based on a standard algorithm.

Enter ?TADA_DataRetrieval into the console to review more example queries
and additional information.

```{r TADA_DataRetrieval}
TADAProfile <- TADA_DataRetrieval(organization = c("REDLAKE_WQX", "SFNOES_WQX", "PUEBLO_POJOAQUE", "FONDULAC_WQX", "PUEBLOOFTESUQUE", "CNENVSER"), startDate = "2018-01-01", endDate = "2019-01-01")
```

If you need to download a large amount of data from across a large area,
and the TADA_DataRetrieval function is not working due to WQP timeout
issues, then the **TADA_BigDataRetrieval** function may work better.

This function does multiple synchronous data calls to the WQP
(waterqualitydata.us). It uses the WQP summary service to limit the
sites downloaded to only those with relevant data. It pulls back data
from set number of stations at a time and then joins the data back
together to produce a single TADA compatible dataframe as the output.

See ?TADA_BigDataRetrieval for more details. WARNING, some of the
examples below can take multiple HOURS to run. The total run time
depends on your query inputs.

```{r BigdataRetrieval}
# AK_AL_WaterTemp <- TADA_BigDataRetrieval(startDate = "2000-01-01", endDate = "2022-12-31", characteristicName = "Temperature, water", statecode = c("AK","AL"))

# AllWaterTemp <- TADA_BigDataRetrieval(characteristicName = "Temperature, water")

# AllPhosphorus <- TADA_BigDataRetrieval(characteristicName = "Phosphorus")

# AllCT <- TADA_BigDataRetrieval(statecode = "CT")
```

Review all column names in the TADA Profile. Remove results that are not
water samples or measurements (TADA is recommended for use with water
data only).

```{r TADA_SummarizeColumn}
colnames(TADAProfile)

TADAProfile_CharSummary <- TADA_SummarizeColumn(TADAProfile, "TADA.CharacteristicName")

TADAProfile_CharSummary

# Remove data for non-water media types
TADAProfile <- dplyr::filter(TADAProfile, TADA.ActivityMediaName == "WATER")
```

## Invalid coordinates

Review station locations and summary information using the
**TADA_OverviewMap** function. **TADA_OverviewMap** counts the number of
unique results, characteristics, and organizations at each monitoring
location in the dataset and creates a tidy map for reviewing summary
stats spatially. Larger point sizes indicate more results collected at a
given site, while darker blue colors indicate more unique
characteristics collected at the site. Users may click on a site to view
a pop-up with this summary information, including the number of
organizations that reported results at that site. This map may inform a
user's decision to remove/correct sites that are outside the US.

```{r Map, fig.width=6, fig.height=6, fig.fullwidth=TRUE}
TADA_OverviewMap(TADAProfile)
```

The TADA **TADA_FlagCoordinates** function identifies and flags
potentially invalid coordinate data. While its functionality is
showcased here, it is always important to review any invalid outputs
before cleaning to reduce the risk of leaving out usable data/sites.

Allowable values for clean_outsideUSA are "no", "remove", or "change
sign". The default is "no" which flags latitude and longitude
coordinates outside the USA. Assigning clean_ousideUSA = "remove" will
remove rows of data with coordinates outside the USA. And assigning
clean_outsideUSA = "change sign" will flip the sign of latitude or
longitude coordinates flagged as outside the USA. The "change sign"
option should only be used when it is known that coordinates were
entered with the wrong sign in WQX; additionally, the data owner should
fix these incorrect coordinates in the raw data through the WQX - for
assistance email the WQX help desk: WQX\@epa.gov

Allowable values for clean_imprecise are TRUE or FALSE. The default is
FALSE which flags rows of data with invalid or imprecise coordinates
without removing them. Assigning clean_imprecise = TRUE will remove rows
of data with invalid or imprecise coordinates.

Allowable values for errorsonly are TRUE or FALSE. The default is FALSE
which keeps all rows of data regardless of flag status. Assigning
errorsonly = TRUE filters the dataframe to show only rows of data which
are flagged.

When clean_outsideUSA = "no" and/or clean_imprecise = FALSE, a column
will be appended titled "TADA.InvalidCoordinates.Flag" with the
following flags (if relevant to dataframe):

-   If the latitude is less than zero, the row will be flagged with
    "LAT_OutsideUSA". (Exception for American Samoa)

-   If the longitude is greater than zero AND less than 145, the row
    will be flagged as "LONG_OutsideUSA". (Exceptions for Guam and the
    Northern Mariana Islands)

-   If the latitude or longitude contains the string, "999", the row
    will be flagged as invalid.

-   Finally, precision can be measured by the number of decimal places
    in the latitude and longitude provided. If either does not have any
    numbers to the right of the decimal point, the row will be flagged
    as "Imprecise".

```{r TADA_FlagCoordinates}
# flag only
TADAProfileClean1 <- TADA_FlagCoordinates(TADAProfile, clean_outsideUSA = "no", clean_imprecise = FALSE, errorsonly = FALSE)

# review unique flags in TADAProfileClean1
unique(TADAProfileClean1$TADA.InvalidCoordinates.Flag)

# review unique MonitoringLocationIdentifiers in your flag dataframe
unique(TADAProfileClean1$MonitoringLocationIdentifier)

Unique_InvalidCoordinateFlags <- TADAProfileClean1 %>%
  dplyr::select(
    "MonitoringLocationIdentifier",
    "MonitoringLocationName",
    "TADA.InvalidCoordinates.Flag",
    "OrganizationIdentifier",
    "TADA.LongitudeMeasure",
    "TADA.LatitudeMeasure",
    "MonitoringLocationTypeName",
    "CountryCode",
    "StateCode",
    "CountyCode",
    "HUCEightDigitCode",
    "MonitoringLocationDescriptionText",
    "ProjectName",
    "ProjectIdentifier",
    "OrganizationFormalName"
  ) %>%
  dplyr::distinct()

Unique_InvalidCoordinateFlags

# if needed, un-comment below to change the sign for all data for sites flagged as outside the USA. You can also change FALSE to TRUE if you want to remove sites outside of the US or sites with imprecise lat/longs

# TADAProfileClean1 <- TADA_FlagCoordinates(TADAProfile, clean_outsideUSA = "change sign", clean_imprecise = FALSE, errorsonly = FALSE)
```

## Depth unit conversions

The **TADA_ConvertDepthUnits** function converts depth units to a
consistent unit. Depth values and units are most commonly associated
with lake data, and are populated in the *ActivityDepthHeightMeasure*,
*ActivityTopDepthHeightMeasure*, *ActivityBottomDepthHeightMeasure*, and
*ResultDepthHeightMeasure* Result Value/Unit columns.

Allowable values for 'unit' are either 'm' (meter), 'ft' (feet), or 'in'
(inch). 'unit' accepts only one allowable value as an input. Default is
unit = "m".

Note that upon download using **TADA_DataRetrieval**, all depth columns
are converted to meters by default. However, the user may choose to run
the **TADA_ConvertDepthUnits** function on their dataset to convert to
another unit. See function documentation for additional input options by
entering the following code in the console: ?TADA_ConvertDepthUnits

```{r TADA_ConvertDepthUnits}
# converts all depth profile data to meters
TADAProfileClean1 <- TADA_ConvertDepthUnits(TADAProfileClean1,
  unit = "ft",
  transform = TRUE
)
```

## Statistically aggregated data

The **TADA_FindContinuousData** function checks for and removes
statistically aggregated high frequency (i.e., continuous) data, if
present.

The Water Quality Portal (WQP) is not currently designed to store
high-frequency sensor data (more than 1 value per day). However,
sometimes data providers choose to aggregate their continuous data to a
daily avg, max, or min value, and then submit that aggregated data to
the WQP through WQX. Alternatively, some organizations aggregate their
high frequency data (15 min or 1 hour data) to 2 or 4 hour interval
averages, and they also submit that data to the WQP through WQX. This
type of high frequency data may (or may not) be suitable for integration
with discrete water quality data for assessments. Therefore, this
function uses metadata submitted by data providers to flag rows with
aggregated continuous data. This is done by flagging results where the
ResultDetectionConditionText = "Reported in Raw Data (attached)".

-   When clean = FALSE, a column titled "TADA.AggregatedContinuousData"
    is added to the dataframe to indicate if the row includes aggregated
    continuous data, "Y", or not, "N".

-   When clean = TRUE, rows with aggregated continuous data are removed
    from the dataframe and no column will be appended. The default is
    clean = TRUE.

An additional input called errorsonly will allow the user to filter data
to show only rows of aggregated continuous data. Allowable values for
errorsonly are TRUE or FALSE. The default is FALSE which keeps all rows
of data regardless of flag status. Assigning errorsonly = TRUE filters
the dataframe to show only rows of data which are flagged "Y".

See function documentation for additional function options by entering
the following code in the console: ?TADA_FindContinuousData

```{r AggregatedContinuousData}
TADAProfileClean1 <- TADA_FindContinuousData(TADAProfileClean1, clean = FALSE)

# uncomment below to create a dataframe of only the aggregated continuous data

# TADAProfile_aggcont <- TADA_FindContinuousData(TADAProfileClean3, clean = FALSE, errorsonly = TRUE)
```

## WQX Quality Assurance and Quality Control (QAQC) Service Result Flags

Run the following result functions to address invalid method, fraction,
speciation, and unit metadata by characteristic. The default is clean =
TRUE, which will remove invalid results. You can change this to clean =
FALSE to flag results, but not remove them.

See documentation for more details:

-   ?**TADA_FlagMethod**

    -   When clean = FALSE, this function adds the following column to
        your dataframe: TADA.AnalyticalMethod.Flag. This column flags
        invalid TADA.CharacteristicName,
        ResultAnalyticalMethod/MethodIdentifier, and
        ResultAnalyticalMethod/MethodIdentifierContext combinations in
        your dataframe either "Nonstandardized", "Invalid", or "Valid".

    -   When clean = TRUE, "Invalid" rows are removed from the dataframe
        and no column will be appended.

    -   When errorsonly = TRUE, the dataframe is filtered to only the
        rows flagged as "Invalid"; default is errorsonly = FALSE.

-   ?**TADA_FlagSpeciation**

    -   When clean = "none", this function adds the following column to
        your dataframe: TADA.MethodSpeciation.Flag. This column flags
        each TADA.CharacteristicName and MethodSpecificationName
        combination in your dataframe as either "Nonstandardized",
        "Invalid", or "Valid".

    -   When clean = "invalid_only", only "Invalid" rows are removed
        from the dataframe. Default is clean = "invalid_only".

    -   When clean = "nonstandardized_only", only "Nonstandardized" rows
        are removed from the dataframe.

    -   When clean = "both", "Invalid" and "Nonstandardized" rows are
        removed from the dataframe.

    -   When clean = "none", no rows are removed from the dataframe.

    -   When errorsonly = TRUE, the dataframe is filtered to only the
        rows flagged as "Invalid" or "Nonstandardized"; default is
        errorsonly = FALSE.

-   ?**TADA_FlagResultUnit**

    -   When clean = FALSE, the following column will be added to your
        dataframe: TADA.ResultUnit.Flag. This column flags each
        TADA.CharacteristicName, TADA.ActivityMediaName, and
        TADA.ResultMeasure.MeasureUnitCode combination in your dataframe
        as either "Nonstandardized", "Invalid", or "Valid".

    -   When clean = TRUE, "Invalid" rows are removed from the dataframe
        and no column will be appended.

    -   When errorsonly = TRUE, the dataframe is filtered to only the
        rows flagged as "Invalid"; default is errorsonly = FALSE.

-   ?**TADA_FlagFraction**

    -   When clean = FALSE, this function adds the following column to
        your dataframe: TADA.SampleFraction.Flag. This column flags each
        TADA.CharacteristicName and TADA.ResultSampleFractionText
        combination in your dataframe as either "Nonstandardized",
        "Invalid", or "Valid".
    -   When clean = TRUE, "Invalid" rows are removed from the dataframe
        and no column will be appended.
    -   When errorsonly = TRUE, the dataframe is filtered to only the
        rows flagged as "Invalid"; default is errorsonly = FALSE.

```{r Invalid_Method_Fraction_Speciation_ResultUnit}
TADAProfileClean2 <- TADA_FlagMethod(TADAProfileClean1, clean = TRUE)

TADAProfileClean2 <- TADA_FlagFraction(TADAProfileClean2, clean = TRUE)

TADAProfileClean2 <- TADA_FlagSpeciation(TADAProfileClean2, clean = "invalid_only")

TADAProfileClean2 <- TADA_FlagResultUnit(TADAProfileClean2, clean = "invalid_only")
```

## WQX national upper and lower thresholds

Run the following code to flag or remove results that are above or below
the national upper and lower bound for each characteristic and unit
combination. See documentation for more details:

-   ?**TADA_FlagAboveThreshold**

    -   When clean = FALSE, the following column is added to your
        dataframe: TADA.ResultValueAboveUpperThreshold.Flag. This column
        flags rows with data that are above the upper WQX threshold.

    -   When clean = TRUE, data that is above the upper WQX threshold is
        removed from the dataframe. The default is clean = TRUE.

    -   When errorsonly = TRUE, the dataframe is filtered to only the
        rows flagged as above the upper WQX threshold; default is
        errorsonly = FALSE.

-   ?**TADA_FlagBelowThreshold**

    -   When clean = FALSE, the following column is added to your
        dataframe: TADA.ResultValueBelowLowerThreshold.Flag. This column
        flags rows with data that are below the lower WQX threshold.

    -   When clean = TRUE, data that is below the lower WQX threshold is
        removed from the dataframe. The default is clean = TRUE.

    -   When errorsonly = TRUE, the dataframe is filtered to only the
        rows flagged as below the lower WQX threshold; default is
        errorsonly = FALSE.

```{r WQX_Thresholds}
TADAProfileClean3 <- TADA_FlagAboveThreshold(TADAProfileClean2, clean = TRUE)

TADAProfileClean3 <- TADA_FlagBelowThreshold(TADAProfileClean3, clean = TRUE)
```

## Potential duplicates

Sometimes multiple organizations submit the exact same data to Water
Quality Portal (WQP), which can affect water quality analyses and
assessments. This function checks for and identifies data that may be duplicates based on date, time, characteristic, result value, and a distance buffer. Each pair or group of potential duplicate rows is flagged with a
unique ID. For more information, review the documentation by entering
the following into the console:

-   ?**TADA_FindPotentialDuplicates**

```{r PotentialDuplicateRowID}
TADAProfileClean3 <- TADA_FindPotentialDuplicates(TADAProfileClean3, dist_buffer = 100)
```

## Review QAPP information

The **TADA_FindQAPPApproval** function checks data for an approved QAPP.

This function checks to see if there is any information in the column
"QAPPApprovedIndicator". Some organizations submit data for this field
to indicate if the data produced has an approved Quality Assurance
Project Plan (QAPP) or not. In this field, Y indicates yes, N indicates
no.

This function has three default inputs: clean = TRUE, cleanNA = FALSE,
and errorsonly = FALSE. These defaults remove rows of data where the
QAPPApprovedIndicator equals "N".

Users could alternatively remove both N's and NA's using the inputs
clean = TRUE, cleanNA = TRUE, and errorsonly = FALSE.

Additionally, users could filter to show only N's and NA's by using the
inputs clean = FALSE, cleanNA = FALSE, and errorsonly = TRUE.

If clean = FALSE, cleanNA = FALSE, and errorsonly = FALSE, the function
will not do anything.

```{r TADA_FindQAPPApproval}
TADAProfileClean3 <- TADA_FindQAPPApproval(TADAProfileClean3, clean = FALSE, cleanNA = FALSE)
```

The **TADA_FindQAPPDoc** function checks to see if a QAPP Doc is
Available

This function checks data submitted under the "ProjectFileUrl" column to
determine if a QAPP document is available to review. When clean = FALSE,
a column will be appended to flag results that do have an associated
QAPP document URL provided. When clean = TRUE, rows that do not have an
associated QAPP document are removed from the dataframe and no column
will be appended. When errorsonly = TRUE, the dataframe is filtered to
show only rows that do not have an associated QAPP document. The
defaults are clean = FALSE and errorsonly = FALSE. This function should
only be used to remove data if an accompanying QAPP document is required
to use data in assessments.

```{r TADA_FindQAPPDoc}
TADAProfileClean3 <- TADA_FindQAPPDoc(TADAProfileClean3,
  clean = FALSE
)
```

## Full Dataframe Filtering

In this section a TADA user will want to review the unique values in
specific fields and may choose to remove data with particular values.

To start, review the list of common fields used for filtering, and the
number of unique values in each field using the **TADA_FieldCounts**
function.

This function returns counts for you entire data frame for each of the
following fields (if populated, columns that are populated only with
NA's are not included in the output):

-   "ActivityTypeCode"

-   "TADA.ActivityMediaName"

-   "ActivityMediaSubdivisionName"

-   "ActivityCommentText"

-   "MonitoringLocationTypeName"

-   "StateName"

-   "TribalLandName"

-   "OrganizationFormalName"

-   "TADA.CharacteristicName"

-   "HydrologicCondition"

-   "HydrologicEvent"

-   "BiologicalIntentName"

-   "MeasureQualifierCode"

-   "ActivityGroup"

-   "AssemblageSampledName"

-   "ProjectName"

-   "CharacteristicNameUserSupplied"

-   "DetectionQuantitationLimitTypeName"

-   "SampleTissueAnatomyName"

-   "LaboratoryName"

```{r TADA_FieldCounts_all}
# multiple options

# print table to console
TADA_FieldCounts(TADAProfileClean3)

# create object of table
fieldCounts_Table <- TADA_FieldCounts(TADAProfileClean3)
```

Next, choose a field from the list generated above to view a summary
table or pie chart of the counts of unique values in that field using
**TADA_FieldValuesTable** or **TADA_FieldValuesPie**. We'll start with
ActivityTypeCode.

```{r fieldValues_all, fig.width=6, fig.height=2, fig.fullwidth=TRUE}
TADA_FieldValuesTable(TADAProfileClean3, field = "ActivityTypeCode")
TADA_FieldValuesPie(TADAProfileClean3, field = "ActivityTypeCode")
```

The ActivityTypeCode field has multiple unique values. In this example
we remove Quality Control (QC) values using the
TADA_FindQCActivities function.

```{r TADA_FindQCActivities}
# Remove all QC samples using the TADA_FindQCActivities function:
# enter ?TADA_FindQCActivities into the console for more information
TADAProfileClean4 <- TADA_FindQCActivities(TADAProfileClean3, clean = TRUE)

# See WQX domain file to review all the ActivityTypeCode allowable values:
# https://cdx.epa.gov/wqx/download/DomainValues/ActivityType.CSV

# Access all WQX Domain Files
# https://www.epa.gov/waterdata/storage-and-retrieval-and-water-quality-exchange-domain-services-and-downloads

# regenerate table and pie chart
TADA_FieldValuesTable(TADAProfileClean4, "ActivityTypeCode")
TADA_FieldValuesPie(TADAProfileClean4, "ActivityTypeCode")
```

We've completed our review of the ActivityTypeCode.

Now, let's move on to a different field and see if there are any values
that we want to remove.

In this next example, there are multiple MeasureQualifierCode values to
review.

```{r MeasureQualifierCodeReview, fig.width=6, fig.height=2, fig.fullwidth=TRUE}
TADA_FieldValuesPie(TADAProfileClean4, "MeasureQualifierCode")
```

MeasureQualifierCode definitions are available
[here](https://cdx.epa.gov/wqx/download/DomainValues/ResultMeasureQualifier.CSV){style="font-size: 12pt;"}.
Values and definitions relevant to this example data frame are included
below:

-   D: Contract Required Quantitation Limit (CRQL) not met due to sample
    matrix interference, dilution required

-   H: Holding time exceeded

-   ICA: Incorrect Initial Calibration Associated with Sample

-   \*: Sample was warm when received

-   E: Concentration of analyte being analyzed exceeded calibration
    range of instrument.

-   J: Estimated: The analyte was positively identified and the
    associated numerical value is the approximate concentration of the
    analyte in the sample.

-   U: Not Detected: The analyte was analyzed for, but was not detected
    at a level greater than or equal to the level of the adjusted
    Contract Required Quantitation Limit (CRQL) for sample and method.

In this example, we show how to remove specific values and regenerate
the pie chart.

```{r FilterMeasureQualifierCodes}
TADAProfileClean4 <- dplyr::filter(TADAProfileClean4, !(MeasureQualifierCode %in% c("D", "H", "ICA", "*")))

# regenerate table and pie chart
TADA_FieldValuesPie(TADAProfileClean4, field = "MeasureQualifierCode")
```

## Censored data

Censored data are measurements for which the true value is not known,
but we can estimate the value based on lower or upper detection
conditions and limit types. TADA fills missing *TADA.ResultMeasureValue*
and *TADA.ResultMeasure.MeasureUnitCode* values with values and units
from *TADA.DetectionQuantitationLimitMeasure.MeasureValue* and
*TADA.DetectionQuantitationLimitMeasure.MeasureUnitCode*, respectively,
using the TADA_AutoClean function. In other words, detection limit
information is copied and pasted into the result value column when the
original value is NA and detection limit information is available. The
two columns TADA focuses on to define and flag censored data are
*ResultDetectionConditionText* and *DetectionQuantitationLimitTypeName*.

The TADA package currently has functions that summarize censored data
incidence in the dataset and perform simple substitutions of censored
data values, including x times the detection limit and random selection
of a value between 0 and the detection limit. The user may specify the
methods used for non-detects and over-detects separately in the input to
the **TADA_SimpleCensoredMethods** function.

All censored data functions depend first on the **TADA_IDCensoredData**
utility function, which assigns a *TADA.CensoredData.Flag* to all data
records and identifies over-detects from non-detects using the
*ResultDetectionConditionText* and *DetectionQuantitationLimitTypeName*.
This utility function is automatically run within the TADA_DataRetrieval
function and produces the *TADA.CensoredData.Flag* column. All records
receive one of the following classifications: - Uncensored - Not filled
with detection limit value; a detection. - Non-Detect - Left-censored -
Over-Detect - Right-censored - Other Condition/Limit Populated -
detection condition or limit type are ambiguous or not associated with a
lower/upper detection limit. - Conflict between Condition and Limit -
detection condition and limit type for a single record do not agree,
e.g. one suggests over-detect and the other suggests non-detect. -
Detection condition or detection limit is not documented in TADA
reference tables. - detection condition or limit type is not
characterized in the TADA reference tables, which are based on WQX
domain tables. - Detection condition is missing and required for
censored data ID. - Result needs more information before being
categorized.

In the example below, we first summarize the censored data in the
dataset using the default grouping variables *TADA.CharacteristicName*,
*TADA.ResultMeasure.MeasureUnitCode*,*TADA.ResultSampleFractionText*,
and *TADA.MethodSpecificationName*. The user can specify any columns in
the TADA dataframe they'd like to use to aggregate their censored data
counts. For example, some may want to aggregate both by characteristic
and HUC or characteristic and monitoring location.

The next step we take in this example is to perform simple conversions
to the censored data in the dataset: we keep over-detects as is (no
conversion made) and convert non-detect values to 0.5 times the
detection limit (half the detection limit). Please review
**?TADA_SummarizeCensoredData** and **?TADA_SimpleCensoredMethods** for more
information.

```{r SummarizeCensoredData}
TADAProfileClean_censoredSummary <- TADA_SummarizeCensoredData(TADAProfileClean4, spec_cols = c("TADA.CharacteristicName", "TADA.ResultMeasure.MeasureUnitCode", "TADA.ResultSampleFractionText", "TADA.MethodSpecificationName"))

TADAProfileClean_censoredSummary

TADAProfileClean4 <- TADA_SimpleCensoredMethods(TADAProfileClean4,
  nd_method = "multiplier",
  nd_multiplier = 0.5,
  od_method = "as-is",
  od_multiplier = "null"
)
```

Next, review unique values within the TADA.CensoredData.Flag,
DetectionQuantitationLimitTypeName, and ResultDetectionConditionText
columns.

```{r uniquevalues}
# review unique values
unique(TADAProfileClean4$TADA.CensoredData.Flag)
unique(TADAProfileClean4$DetectionQuantitationLimitTypeName)
unique(TADAProfileClean4$ResultDetectionConditionText)
```

Also, review the TADA.ResultMeasureValueDataTypes.Flag to see if any
NA's or ND's (non-detects) remain.

```{r ResultMeasureValueDataTypes.Flag_uniquevalues}
unique(TADAProfileClean4$TADA.ResultMeasureValueDataTypes.Flag)
```

Count how many NA's remain in the TADA.ResultMeasureValue.

```{r Review_NA_MeasureValues}
sum(is.na(TADAProfileClean4$TADA.ResultMeasureValue))
```

Filter down to only numeric data. Remove data where the
TADA.ResultMeasureValueDataTypes.Flag = "Text","Coerced to NA","ND or
NA".

```{r filter_out_NAs}
# Filter down to only numeric data. Remove "Text","Coerced to NA","ND or NA"
TADAProfileClean5 <- dplyr::filter(
  TADAProfileClean4,
  TADA.ResultMeasureValueDataTypes.Flag != "ND or NA" &
    TADA.ResultMeasureValueDataTypes.Flag != "Text" &
    TADA.ResultMeasureValueDataTypes.Flag != "Coerced to NA"
)
```

Double check to make sure no NA's or ND's remain.

```{r check_for_NAs_again}
unique(TADAProfileClean5$TADA.ResultMeasureValueDataTypes.Flag)
```

## Transform Characteristic, Speciation, and Unit values to TADA Standards

The **TADA_HarmonizeRefTable** function generates a harmonization reference
table that is specific to the input dataframe. Users can review how
their input data relates to standard TADA values for the following
elements:

-   TADA.CharacteristicName

-   TADA.ResultSampleFractionText

-   TADA.MethodSpecificationName

-   TADA.ResultMeasure.MeasureUnitCode

The **TADA_HarmonizeSynonyms** function then compares the input dataframe to the
TADA Harmonization Reference Table. The purpose of the function is to
make similar data consistent and therefore easier to compare and
analyze.

Users can also edit the reference file to meet their needs if desired.
The download argument can be used to save the harmonization file to your
current working directory when download = TRUE, the default is download
= FALSE.

Optional outputs include:

1.  the dataframe with Harmonization columns appended,

2.  the dataframe with TADA.CharacteristicName,
    TADA.ResultSampleFractionText, TADA.MethodSpecificationName, and
    TADA.ResultMeasure.MeasureUnitCode converted to TADA standards or

3.  the four fields converted with most Harmonization Reference Table
    columns appended. Default is transform = TRUE and flag = TRUE.

Here are some examples of how the TADA_HarmonizeSynonyms function can be used:

1.  TADA.ResultSampleFractionText specifies forms of constituents. In
    some cases, a single \*TADA.CharacteristicName\*\* will have both
    "Total" and "Dissolved" forms specified, which should not be
    combined. In these cases, each TADA.CharacteristicName and
    TADA.ResultSampleFractionText combination is given a different
    identifier. This identifier can be used later on to identify
    comparable data groups for calculating statistics and creating
    figures for each combination.

2.  Some variables have different names but represent the same
    constituent (e.g., "Total Kjeldahl nitrogen (Organic N & NH3)" and
    "Kjeldahl nitrogen"). The TADA_HarmonizeSynonyms function gives a consistent
    name (and identifier) to synonyms.

```{r TADA_HarmonizeSynonyms}
UniqueHarmonizationRef <- TADA_GetSynonymRef(TADAProfileClean5,
  download = FALSE
)

TADAProfileClean5 <- TADA_HarmonizeSynonyms(TADAProfileClean5,
  ref = UniqueHarmonizationRef,
  transform = TRUE,
  flag = TRUE
)
```

## Parameter Level Filtering

In this section, you can select a single parameter, and review the
unique values in specified fields. You may then choose to remove
particular values by filtering.

To start, review the list of parameters in the dataframe using the
**TADA_FieldValuesTable** function.

Enter ?TADA_FieldValuesTable into the console for more information.

```{r TADA_FieldValuesTable_chars}
TADA_FieldValuesTable(TADAProfileClean5, field = "TADA.CharacteristicName")
```

Next, we can revisit the **TADA_FieldCounts** function at the characteristic
level to review how many unique allowable values are included within
each of the following fields:

-   "ActivityCommentText"

-   "ActivityTypeCode"

-   "TADA.ActivityMediaName"

-   "ActivityMediaSubdivisionName"

-   "MeasureQualifierCode"

-   "MonitoringLocationTypeName"

-   "HydrologicCondition"

-   "HydrologicEvent"

-   "ResultStatusIdentifier"

-   "MethodQualifierTypeName"

-   "ResultCommentText"

-   "ResultLaboratoryCommentText"

-   "TADA.ResultMeasure.MeasureUnitCode"

-   "TADA.ResultSampleFractionText"

-   "ResultTemperatureBasisText"

-   "ResultValueTypeName"

-   "ResultWeightBasisText"

-   "SampleCollectionEquipmentName"

-   "LaboratoryName"

-   "MethodDescriptionText"

-   "ResultParticleSizeBasisText"

-   "SampleCollectionMethod.MethodIdentifier"

-   "SampleCollectionMethod.MethodIdentifierContext"

-   "SampleCollectionMethod.MethodName"

-   "DataQuality.BiasValue"

-   "MethodSpeciationName"

-   "ResultAnalyticalMethod.MethodName"

-   "ResultAnalyticalMethod.MethodIdentifier"

-   "ResultAnalyticalMethod.MethodIdentifierContext"

-   "AssemblageSampledName"

-   "DetectionQuantitationLimitTypeName"

```{r TADA_FieldCounts_char}
TADA_FieldCounts(TADAProfileClean5, display = "most", characteristicName = "TOTAL PHOSPHORUS, MIXED FORMS")
```

Selecting a parameter generates the list above, which is subset by the
selected parameter. The list includes fields you may want to review, and
the number of unique values in each field.

Next, choose a field from the list.

Review the WQX domain files for definitions:
<https://www.epa.gov/waterdata/storage-and-retrieval-and-water-quality-exchange-domain-services-and-downloads>

Now, we'll use **TADA_FieldValuesTable** and **TADA_FieldValuesPie** at the
characteristic-level to review a column of interest.

```{r TADA_FieldValuesTable_Pie_char, fig.width=6, fig.height=2, fig.fullwidth=TRUE}
# In this example we review values from the SampleCollectionMethod.MethodName field
TADA_FieldValuesTable(TADAProfileClean5, field = "SampleCollectionMethod.MethodName", characteristicName = "TOTAL PHOSPHORUS, MIXED FORMS")
TADA_FieldValuesPie(TADAProfileClean5, field = "SampleCollectionMethod.MethodName", characteristicName = "TOTAL PHOSPHORUS, MIXED FORMS")
```

Summarize results for a single comparable data group using the
TADA.ComparableDataIdentifier (i.e., comparable characteristic, unit,
speciation, and fraction combination)

```{r ComparableDataIdentifier_stats_and_histogram, fig.width=6, fig.height=6, fig.fullwidth=TRUE}
# review TADA.ComparableDataIdentifier
unique(TADAProfileClean5$TADA.ComparableDataIdentifier)

# filter dataframe to only "TOTAL PHOSPHORUS, MIXED FORMS"
TADAProfileCleanTP <- dplyr::filter(TADAProfileClean5, TADA.ComparableDataIdentifier == "Total Phosphorus_as P_ug/L")

# generate stats table
TADAProfileCleanTP_stats <- TADA::TADA_Stats(TADAProfileCleanTP)

TADAProfileCleanTP_stats

# generate a histogram
TADA_Histogram(TADAProfileCleanTP, id_col = "TADA.ComparableDataIdentifier")
```

Generate interactive box plot.

```{r boxplot, fig.width=6, fig.height=6, fig.fullwidth=TRUE}
TADA::TADA_Boxplot(TADAProfileCleanTP, id_col = "TADA.ComparableDataIdentifier")
```

## TADA Shiny Application

Finally, take a look at an alternative workflow, TADA Shiny Module 1:
Data Discovery and Cleaning. This is a Shiny application that runs many
of the TADA functions covered in this document behind a graphical user
interface. The shiny application queries the WQP, contains maps and data
visualizations, flags suspect data results, handles censored data, and
more. You can launch it using the code below.

```{r, eval = F}
# download TADA Shiny repository
remotes::install_github("USEPA/TADAShiny",
  ref = "develop",
  dependencies = TRUE
)

# launch the app locally.
TADAShiny::run_app()
```

DRAFT [Module 1](https://owshiny-dev.app.cloud.gov/tada-dev/) is also
currently hosted on the web with minimal server memory/storage
allocated.
