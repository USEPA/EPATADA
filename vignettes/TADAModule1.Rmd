---
title: "TADA Module 1: Water Quality Portal Data Discovery and Cleaning"
author: "TADA Team"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\usepackage[utf8]{inputenc}
  %\VignetteIndexEntry{TADA Module 1: Water Quality Portal Data Discovery and Cleaning}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: 72
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{css, echo=FALSE}
pre {
  max-height: 300px;
  overflow-y: auto;
}

pre[class] {
  max-height: 100px;
}
```

## Overview

This vignette walks through how to use the TADA R Package to discover
and clean (i.e., wrangle, Quality Assure and Quality Control (QAQC), and
harmonize) [Water Quality Portal
(WQP)](https://www.waterqualitydata.us/) data from multiple
organizations.

## Install and load packages

First, install and load the remotes package specifying the repo. This is
needed before installing TADA because it is only available on GitHub
(not CRAN).

```{r install_remotes, eval = F, results = 'hide', message = FALSE, warning = FALSE}
install.packages("remotes",
  repos = "http://cran.us.r-project.org"
)
library(remotes)
```

Next, install and load TADA using the remotes package. USGS's
dataRetrieval and other TADA R Package dependencies will also be
downloaded automatically from CRAN with the TADA install. If desired,
the development version of dataRetrieval can be downloaded directly from
GitHub (un-comment).

```{r install_TADA, eval = F, results = 'hide', message = FALSE, warning = FALSE}
remotes::install_github("USEPA/TADA",
  ref = "develop",
  dependencies = TRUE
)

# remotes::install_github("USGS-R/dataRetrieval", dependencies=TRUE)

# if you experience any issues installing TADA, try un-commenting and running
# the line below before the install
# options(download.file.method = "wininet")
```

```{r for-development-only, echo = F, results = 'hide', message = FALSE, warning = FALSE}
# IF YOU ARE NOT DEVELOPING TADA, SKIP THIS CODE CHUNK
# when developing the package, update this chunk to the current repository branch, so it runs with all of the new features prior to a PR to develop
remotes::install_github("USEPA/TADA",
  ref = "334-flag-duplicates-for-multiple-orgs-weird-behavior-to-check",
  dependencies = TRUE
)
```

Finally, use the **library()** function to load the TADA R Package into
your R session.

```{r library, results = 'hide', message = FALSE, warning = FALSE}
library(TADA)
```

## Retrieve WQP data

WQP data is retrieved and processed for compatibility with TADA. This
function, **TADA_DataRetrieval**, builds on USGS's dataRetrieval R
package functions. It joins three WQP profiles: Site, Sample Results
(physical/chemical metadata), and Project. In addition, it changes all
data in the Characteristic, Speciation, Fraction, and Unit fields to
uppercase, removes exact duplicates, and addresses result values that
include special characters.

This function uses the same inputs as the dataRetrieval `readWQPdata`
function. `readWQPdata` does not restrict the characteristics pulled
from [Water Quality Portal (WQP)](https://www.waterqualitydata.us/).

Data retrieval filters include:

-   startDate

-   endDate

-   characteristicName

-   sampleMedia

-   siteType

-   statecode (review list of possible state and territory
    [abbreviations](https://www2.census.gov/geo/docs/reference/state.txt))

-   countycode

-   siteid

-   organization

-   project

-   huc

-   characteristicType

The default TADA_DataRetrieval function automatically runs the
**TADA_AutoClean** function. In this example, we will set
**TADA_AutoClean = FALSE** and run it as a separate step in the work
flow.

Tips:

1.  All the query filters for the WQP work as an AND but within the
    fields there are ORs. For example:

    -   Characteristics: If you choose pH & DO - it's an OR. This means
        you will retrieve both pH OR DO data if available.

    -   States: Similarly, if you choose VA and IL, it's an OR. This
        means you will retrieve both VA OR IL data if available.

    -   Combinations of fields are ANDs, such as State/VA AND
        Characteristic/DO". This means you will receive all DO data
        available in VA.

    -   "Characteristic" and "Characteristic Type" also work as an AND.
        This means that the Characteristic must fall within the
        CharacteristicGroup if both filters are being used, if not you
        will get an error.

2.  The "siteid" is a general term WQP uses to describe both Site IDs
    from USGS databases and Monitoring Location Identifiers (from WQX).
    Each monitoring location in the Water Quality Portal (WQP) has a
    unique Monitoring Location Identifier, regardless of the database
    from which it derives. The Monitoring Location Identifier from the
    WQP is the concatenated Organization Identifier plus the Site ID
    number. Site IDs that only include a number are only unique
    identifiers for monitoring locations within USGS NWIS or EPA's WQX
    databases separately.

Additional resources:

-   Review function documentation by entering the following code into
    the console: ?TADA_DataRetrieval

-   [Introduction to the dataRetrieval
    package](https://CRAN.R-project.org/package=dataRetrieval)

-   [General Data Import from Water Quality
    Portal](https://rdrr.io/cran/dataRetrieval/man/readWQPdata.html)

-   [Water Quality Portal Web Services
    Guide](https://www.waterqualitydata.us/webservices_documentation/)

-   [dataRetrieval Tutorial](https://owi.usgs.gov/R/dataRetrieval.html)

## dataRetrieval

Uncomment below if you would like to review differences between the
profiles you would get using readWQPdata vs. TADA_DataRetrieval. The
profiles are different because TADA_DataRetrieval automatically joins in
data from multiple WQP profiles, and does some additional data cleaning
as part of the data retrieval process.

This example includes monitoring data collected from Jan 2018 to Jan
2019 by six organizations: 1) Red Lake Band of Chippewa Indians, 2) Sac
& Fox Nation, 3) Pueblo of Pojoaque, 4) Minnesota Chippewa Tribe (Fond
du Lac Band), 5) Pueblo of Tesuque, and 6) The Chickasaw Nation

We will move forward with this example in the remainder of the vignette.

```{r dataRetrieval_example}
# dataRetrieval_example <- dataRetrieval::readWQPdata(organization = c("REDLAKE_WQX", "SFNOES_WQX", "PUEBLO_POJOAQUE", "FONDULAC_WQX", "PUEBLOOFTESUQUE", "CNENVSER"), startDate = "2018-01-01", endDate = "2019-01-01", ignore_attributes = TRUE)
```

Use the code below to download data from the WQP using
TADA_DataRetrieval. Edit the code chuck below to define your own WQP
query inputs.

Downloads using TADA_DataRetrieval will have the same columns each time,
but be aware that data are uploaded to the Water Quality Portal by
individual organizations, which may or may not follow the same
conventions. Data and metadata quality are not guaranteed! Make sure to
carefully explore any data and make conservative quality assurance
decisions where information is limited.

Note: TADA_DataRetrieval (by leveraging dataRetrieval), automatically
converts the date times to UTC. It also automatically converts the data
to dates, datetimes, and numerics based on a standard algorithm.

Enter ?TADA_DataRetrieval into the console to review more example
queries and additional information.

```{r TADA_DataRetrieval}
TADAProfile <- TADA_DataRetrieval(organization = c("REDLAKE_WQX", "SFNOES_WQX", "PUEBLO_POJOAQUE", "FONDULAC_WQX", "PUEBLOOFTESUQUE", "CNENVSER"), startDate = "2018-01-01", endDate = "2019-01-01", applyautoclean = FALSE)
```

If you need to download a large amount of data from across a large area,
and the TADA_DataRetrieval function is not working due to WQP timeout
issues, then the **TADA_BigDataRetrieval** function may work better.

This function does multiple synchronous data calls to the WQP
(waterqualitydata.us). It uses the WQP summary service to limit the
sites downloaded to only those with relevant data. It pulls back data
from set number of stations at a time and then joins the data back
together to produce a single TADA compatible dataframe as the output.

See ?TADA_BigDataRetrieval for more details. WARNING, some of the
examples below can take multiple HOURS to run. The total run time
depends on your query inputs.

```{r BigdataRetrieval}
# AK_AL_WaterTemp <- TADA_BigDataRetrieval(startDate = "2000-01-01", endDate = "2022-12-31", characteristicName = "Temperature, water", statecode = c("AK","AL"))

# AllWaterTemp <- TADA_BigDataRetrieval(characteristicName = "Temperature, water")

# AllPhosphorus <- TADA_BigDataRetrieval(characteristicName = "Phosphorus")

# AllCT <- TADA_BigDataRetrieval(statecode = "CT")
```

Some TADA users are interested in using WQP data for surface water only
or for analysis of some non-water data. The **TADA_AnalysisDataFilter**
function can assist in identifying results of interest. Multiple columns
are used to identify groundwater results as different organizations may
populate different combinations of fields in order to identify a result
as groundwater.

This function identifies surface water, groundwater, and sediment
results. Users can specify whether all results should be returned with a
new column, *TADA.UseForAnalysis.Flag*,identifying if the result should
be included in further analysis or if only results that should be in
included are returned.

The defaults are to include surface water, exclude groundwater and
sediment, and to return only the results that should be used for
analysis (clean = TRUE). This is shown in the active example below. If
you would like to see all results with the *TADA.UseForAnalysis.Flag*
column, you can uncomment the example where clean = FALSE.

If you are not interested in using **TADA_AnalysisDataFilter**, but
would like to filter by activity media, uncomment the example to filter
for water data only by using dplyr::filter() with
TADA.ActivityMediaName.

```{r AnalysisDataFilter}
# Filter to retain only results for use in analysis
TADAProfile <- TADA_AnalysisDataFilter(TADAProfile,
  clean = TRUE,
  surface_water = TRUE,
  ground_water = FALSE,
  sediment = FALSE
)

# Add TADA.UseForAnalysis.Flag column to identify which results should be used for analysis
# TADAProfile <- TADA_AnalysisDataFilter(TADAProfile, clean = FALSE)

# Remove data for non-water media types, alternate workflow without using TADA_AnalysisDataFilter()
# TADAProfile <- dplyr::filter(TADAProfile, TADA.ActivityMediaName == "WATER")
```

## AutoClean

Now **TADA_AutoClean** can be run on a smaller dataset after unnecessary
results have been removed. It performs the following functions on the
data retrieved from the WQP:

-   **TADA_ConvertSpecialChars** - converts result value columns to
    numeric and flags non-numeric values that could not be converted.

-   **TADA_ConvertResultUnits** - unifies result units for easier
    quality control and review

-   **TADA_ConvertDepthUnits** - converts depth units to a consistent
    unit (meters).

-   **TADA_IDCensoredData** - categorizes detection limit data and
    identifies mismatches in result detection condition and result
    detection limit type.

-   Other helpful actions - converts important text columns to all
    upper-case letters, removes exact duplicates, and uses WQX format
    rules to harmonize specific NWIS metadata conventions (e.g. move
    characteristic speciation from the
    TADA.ResultMeasure.MeasureUnitCode column to the
    TADA.MethodSpeciationName column)

As a general rule, TADA functions do not change any contents in the
WQP-served columns. Instead, they add new columns with the prefix
"TADA." The following columns are numeric versions of their WQP origins:

```         
-   TADA.ResultMeasureValue

-   TADA.DetectionQuantitationLimitMeasure.MeasureValue

-   TADA.LatitudeMeasure

-   TADA.LongitudeMeasure
```

These functions also add the columns
TADA.ResultMeasureValueDataTypes.Flag and
TADA.DetectionQuantitationLimitMeasure.MeasureValueDataTypes.Flag, which
provide information about the result values that is needed to address
censored data later on (i.e., nondetections). Specifically, these new
columns flag if special characters are included in result values, and
specifies what the special characters are.

```{r TADA_AutoClean}
# run TADA_AutoClean on filtered dataset to convert special characters, result units, and depth units and identify censored data.

TADAProfile <- TADA_AutoClean(TADAProfile)
```

Review all column names in the TADA Profile to familiarize yourself with
the dataset after TADA_AutoClean has added additional TADA prefixed
columns. **TADA_SummarizeColumn** summarizes the data set based on the
user specified column and returns a dataframe displaying the number of
sites and number of records for each unique value in the specified
column. The example below uses TADA.CharacteristicName.

```{r TADA_SummarizeColumn}
# View column names for TADAProfile
colnames(TADAProfile)

# Review the number of sites and number of records for each CharacteristicName in TADAProfile
TADAProfile_CharSummary <- TADA_SummarizeColumn(TADAProfile, "TADA.CharacteristicName")

# View TADAProfile_CharSummary
TADAProfile_CharSummary
```

## Invalid coordinates

Review station locations and summary information using the
**TADA_OverviewMap** function. **TADA_OverviewMap** counts the number of
unique results, characteristics, and organizations at each monitoring
location in the dataset and creates a tidy map for reviewing summary
stats spatially. Larger point sizes indicate more results collected at a
given site, while darker blue colors indicate more unique
characteristics collected at the site. Users may click on a site to view
a pop-up with this summary information, including the number of
organizations that reported results at that site. This map may inform a
user's decision to remove/correct sites that are outside the US.

```{r Map, fig.width=8, fig.height=6, fig.fullwidth=TRUE, eval = F, message = FALSE, warning = FALSE}
TADA_OverviewMap(TADAProfile)
```

The TADA **TADA_FlagCoordinates** function identifies and flags
potentially invalid coordinate data. While its functionality is
showcased here, it is always important to review any invalid outputs
before cleaning to reduce the risk of leaving out usable data/sites.

Allowable values for clean_outsideUSA are "no", "remove", or "change
sign". The default is "no" which flags latitude and longitude
coordinates outside the USA. Assigning clean_ousideUSA = "remove" will
remove rows of data with coordinates outside the USA. And assigning
clean_outsideUSA = "change sign" will flip the sign of latitude or
longitude coordinates flagged as outside the USA. The "change sign"
option should only be used when it is known that coordinates were
entered with the wrong sign in WQX; additionally, the data owner should
fix these incorrect coordinates in the raw data through the WQX - for
assistance email the WQX help desk: WQX\@epa.gov

Allowable values for clean_imprecise are TRUE or FALSE. The default is
FALSE which flags rows of data with invalid or imprecise coordinates
without removing them. Assigning clean_imprecise = TRUE will remove rows
of data with invalid or imprecise coordinates.

Allowable values for flaggedonly are TRUE or FALSE. The default is FALSE
which keeps all rows of data regardless of flag status. Assigning
flaggedonly = TRUE filters the dataframe to show only rows of data which
are flagged.

When clean_outsideUSA = "no" and/or clean_imprecise = FALSE, a column
will be appended titled "TADA.InvalidCoordinates.Flag" with the
following flags (if relevant to dataframe):

-   If the latitude is less than zero, the row will be flagged with
    "LAT_OutsideUSA". (Exception for American Samoa)

-   If the longitude is greater than zero AND less than 145, the row
    will be flagged as "LONG_OutsideUSA". (Exceptions for Guam and the
    Northern Mariana Islands)

-   If the latitude or longitude contains the string, "999", the row
    will be flagged as invalid.

-   Finally, precision can be measured by the number of decimal places
    in the latitude and longitude provided. If either does not have any
    numbers to the right of the decimal point, the row will be flagged
    as "Imprecise".

```{r TADA_FlagCoordinates}
# flag only
TADAProfileClean1 <- TADA_FlagCoordinates(TADAProfile, clean_outsideUSA = "no", clean_imprecise = FALSE, flaggedonly = FALSE)

# review unique flags in TADAProfileClean1
unique(TADAProfileClean1$TADA.InvalidCoordinates.Flag)

# review unique MonitoringLocationIdentifiers in your flag dataframe
unique(TADAProfileClean1$MonitoringLocationIdentifier)

Unique_InvalidCoordinateFlags <- TADAProfileClean1 %>%
  dplyr::select(
    "MonitoringLocationIdentifier",
    "MonitoringLocationName",
    "TADA.InvalidCoordinates.Flag",
    "OrganizationIdentifier",
    "TADA.LongitudeMeasure",
    "TADA.LatitudeMeasure",
    "MonitoringLocationTypeName",
    "CountryCode",
    "StateCode",
    "CountyCode",
    "HUCEightDigitCode",
    "MonitoringLocationDescriptionText",
    "ProjectName",
    "ProjectIdentifier",
    "OrganizationFormalName"
  ) %>%
  dplyr::distinct()

Unique_InvalidCoordinateFlags

# if needed, un-comment below to change the sign for all data for sites flagged as outside the USA. You can also change FALSE to TRUE if you want to remove sites outside of the US or sites with imprecise lat/longs

# TADAProfileClean1 <- TADA_FlagCoordinates(TADAProfile, clean_outsideUSA = "change sign", clean_imprecise = FALSE, flaggedonly = FALSE)
```

## Depth unit conversions

The **TADA_ConvertDepthUnits** function converts depth units to a
consistent unit. Depth values and units are most commonly associated
with lake data, and are populated in the *ActivityDepthHeightMeasure*,
*ActivityTopDepthHeightMeasure*, *ActivityBottomDepthHeightMeasure*, and
*ResultDepthHeightMeasure* Result Value/Unit columns.

Allowable values for 'unit' are either 'm' (meter), 'ft' (feet), or 'in'
(inch). 'unit' accepts only one allowable value as an input. Default is
unit = "m".

Note that upon download using **TADA_DataRetrieval**, all depth columns
are converted to meters by default. However, the user may choose to run
the **TADA_ConvertDepthUnits** function on their dataset to convert to
another unit. See function documentation for additional input options by
entering the following code in the console: ?TADA_ConvertDepthUnits

```{r TADA_ConvertDepthUnits}
# converts all depth profile data to meters
TADAProfileClean1 <- TADA_ConvertDepthUnits(TADAProfileClean1,
  unit = "ft",
  transform = TRUE
)
```

## Statistically aggregated data

The **TADA_FindContinuousData** function checks for and removes
statistically aggregated high frequency (i.e., continuous) data, if
present.

The Water Quality Portal (WQP) is not currently designed to store
high-frequency sensor data (more than 1 value per day). However,
sometimes data providers choose to aggregate their continuous data to a
daily avg, max, or min value, and then submit that aggregated data to
the WQP through WQX. Alternatively, some organizations aggregate their
high frequency data (15 min or 1 hour data) to 2 or 4 hour interval
averages, and they also submit that data to the WQP through WQX. This
type of high frequency data may (or may not) be suitable for integration
with discrete water quality data for assessments. Therefore, this
function uses metadata submitted by data providers to flag rows with
aggregated continuous data. This is done by flagging results where the
ResultDetectionConditionText = "Reported in Raw Data (attached)".

-   When clean = FALSE, a column titled "TADA.AggregatedContinuousData"
    is added to the dataframe to indicate if the row includes aggregated
    continuous data, "Y", or not, "N".

-   When clean = TRUE, rows with aggregated continuous data are removed
    from the dataframe and no column will be appended. The default is
    clean = TRUE.

An additional input called flaggedonly will allow the user to filter
data to show only rows of aggregated continuous data. Allowable values
for flaggedonly are TRUE or FALSE. The default is FALSE which keeps all
rows of data regardless of flag status. Assigning flaggedonly = TRUE
filters the dataframe to show only rows of data which are flagged "Y".

See function documentation for additional function options by entering
the following code in the console: ?TADA_FindContinuousData

```{r AggregatedContinuousData}
TADAProfileClean1 <- TADA_FindContinuousData(TADAProfileClean1,
  clean = FALSE
)

# uncomment below to create a dataframe of only the aggregated continuous data

# TADAProfile_aggcont <- TADA_FindContinuousData(TADAProfileClean3, clean = FALSE, flaggedonly = TRUE)
```

## WQX Quality Assurance and Quality Control (QAQC) Service Result Flags

Run the following result functions to address invalid method, fraction,
speciation, and unit metadata by characteristic. The default is clean =
TRUE, which will remove invalid results. You can change this to clean =
FALSE to flag results, but not remove them.

See documentation for more details:

-   ?**TADA_FlagMethod**

    -   When clean = FALSE, this function adds the following column to
        your dataframe: TADA.AnalyticalMethod.Flag. This column flags
        invalid TADA.CharacteristicName,
        ResultAnalyticalMethod/MethodIdentifier, and
        ResultAnalyticalMethod/MethodIdentifierContext combinations in
        your dataframe either "NonStandardized", "Invalid", or "Valid".

    -   When clean = TRUE, "Invalid" rows are removed from the dataframe
        and no column will be appended.

    -   When flaggedonly = TRUE, the dataframe is filtered to only the
        rows flagged as "Invalid"; default is flaggedonly = FALSE.

-   ?**TADA_FlagSpeciation**

    -   When clean = "none", this function adds the following column to
        your dataframe: TADA.MethodSpeciation.Flag. This column flags
        each TADA.CharacteristicName and MethodSpeciationName
        combination in your dataframe as either "NonStandardized",

        "Invalid", or "Valid".

    -   When clean = "invalid_only", only "Invalid" rows are removed
        from the dataframe. Default is clean = "invalid_only".

    -   When clean = "nonstandardized_only", only "NonStandardized" rows
        are removed from the dataframe.

    -   When clean = "both", "Invalid" and "NonStandardized" rows are
        removed from the dataframe.

    -   When clean = "none", no rows are removed from the dataframe.

    -   When flaggedonly = TRUE, the dataframe is filtered to only the
        rows flagged as "Invalid" or "NonStandardized"; default is
        flaggedonly = FALSE.

-   ?**TADA_FlagResultUnit**

    -   When clean = FALSE, the following column will be added to your
        dataframe: TADA.ResultUnit.Flag. This column flags each
        TADA.CharacteristicName, TADA.ActivityMediaName, and
        TADA.ResultMeasure.MeasureUnitCode combination in your dataframe
        as either "NonStandardized", "Invalid", or "Valid".

    -   When clean = TRUE, "Invalid" rows are removed from the dataframe
        and no column will be appended.

    -   When flaggedonly = TRUE, the dataframe is filtered to only the
        rows flagged as "Invalid"; default is flaggedonly = FALSE.

-   ?**TADA_FlagFraction**

    -   When clean = FALSE, this function adds the following column to
        your dataframe: TADA.SampleFraction.Flag. This column flags each
        TADA.CharacteristicName and TADA.ResultSampleFractionText
        combination in your dataframe as either "NonStandardized",
        "Invalid", or "Valid".
    -   When clean = TRUE, "Invalid" rows are removed from the dataframe
        and no column will be appended.
    -   When flaggedonly = TRUE, the dataframe is filtered to only the
        rows flagged as "Invalid"; default is flaggedonly = FALSE.

```{r Invalid_Method_Fraction_Speciation_ResultUnit}
TADAProfileClean2 <- TADA_FlagMethod(TADAProfileClean1, clean = TRUE)

TADAProfileClean2 <- TADA_FlagFraction(TADAProfileClean2, clean = TRUE)

TADAProfileClean2 <- TADA_FlagSpeciation(TADAProfileClean2, clean = "invalid_only")

TADAProfileClean2 <- TADA_FlagResultUnit(TADAProfileClean2, clean = "invalid_only")
```

## WQX national upper and lower thresholds

Run the following code to flag or remove results that are above or below
the national upper and lower bound for each characteristic and unit
combination. See documentation for more details:

-   ?**TADA_FlagAboveThreshold**

    -   When clean = FALSE, the following column is added to your
        dataframe: TADA.ResultValueAboveUpperThreshold.Flag. This column
        flags rows with data that are above the upper WQX threshold. The
        default is clean = FALSE.

    -   When clean = TRUE, data that is above the upper WQX threshold is
        removed from the dataframe.

    -   When flaggedonly = TRUE, the dataframe is filtered to only the
        rows flagged as above the upper WQX threshold; default is
        flaggedonly = FALSE.

-   ?**TADA_FlagBelowThreshold**

    -   When clean = FALSE, the following column is added to your
        dataframe: TADA.ResultValueBelowLowerThreshold.Flag. This column
        flags rows with data that are below the lower WQX threshold. The
        default is clean = FALSE.

    -   When clean = TRUE, data that is below the lower WQX threshold is
        removed from the dataframe.

    -   When flaggedonly = TRUE, the dataframe is filtered to only the
        rows flagged as below the lower WQX threshold; default is
        flaggedonly = FALSE.

```{r WQX_Thresholds}
TADAProfileClean3 <- TADA_FlagAboveThreshold(TADAProfileClean2, clean = TRUE)

TADAProfileClean3 <- TADA_FlagBelowThreshold(TADAProfileClean3, clean = TRUE)
```

## Potential duplicates

Sometimes multiple organizations submit the exact same data to Water
Quality Portal (WQP), which can affect water quality analyses and
assessments. Similarly, organizations occasionally submit the same data
multiple times to the Portal. The following functions check for and
identify data that may be duplicates based on date, time,
characteristic, result value, and a distance buffer. Each pair or group
of potential duplicate rows is flagged with a unique ID. For more
information, review the documentation by entering the following into the
console:

-   ?**TADA_FindPotentialDuplicatesMultipleOrgs**
-   ?**TADA_FindPotentialDuplicatesSingleOrg**

```{r FindPotentialDuplicates}
TADAProfileClean3 <- TADA_FindPotentialDuplicatesSingleOrg(TADAProfileClean3)

TADAProfileClean3 <- TADA_FindPotentialDuplicatesMultipleOrgs(TADAProfileClean3,
  dist_buffer = 100,
  org_hierarchy = "none"
)
```

## Review QAPP information

The **TADA_FindQAPPApproval** function checks data for an approved QAPP.

This function checks to see if there is any information in the column
"QAPPApprovedIndicator". Some organizations submit data for this field
to indicate if the data produced has an approved Quality Assurance
Project Plan (QAPP) or not. In this field, Y indicates yes, N indicates
no.

This function has three default inputs: clean = TRUE, cleanNA = FALSE,
and flaggedonly = FALSE. These defaults remove rows of data where the
QAPPApprovedIndicator equals "N".

Users could alternatively remove both N's and NA's using the inputs
clean = TRUE, cleanNA = TRUE, and flaggedonly = FALSE.

Additionally, users could filter to show only N's and NA's by using the
inputs clean = FALSE, cleanNA = FALSE, and flaggedonly = TRUE.

If clean = FALSE, cleanNA = FALSE, and flaggedonly = FALSE, the function
will not do anything.

```{r TADA_FindQAPPApproval}
TADAProfileClean3 <- TADA_FindQAPPApproval(TADAProfileClean3, clean = FALSE, cleanNA = FALSE)
```

The **TADA_FindQAPPDoc** function checks to see if a QAPP Doc is
Available

This function checks data submitted under the "ProjectFileUrl" column to
determine if a QAPP document is available to review. When clean = FALSE,
a column will be appended to flag results that do have an associated
QAPP document URL provided. When clean = TRUE, rows that do not have an
associated QAPP document are removed from the dataframe and no column
will be appended. When flaggedonly = TRUE, the dataframe is filtered to
show only rows that do not have an associated QAPP document. The
defaults are clean = FALSE and flaggedonly = FALSE. This function should
only be used to remove data if an accompanying QAPP document is required
to use data in assessments.

```{r TADA_FindQAPPDoc}
TADAProfileClean3 <- TADA_FindQAPPDoc(TADAProfileClean3,
  clean = FALSE
)
```

## Full Dataframe Filtering

In this section a TADA user will want to review the unique values in
specific fields and may choose to remove data with particular values.

To start, review the list of common fields used for filtering, and the
number of unique values in each field using the **TADA_FieldCounts**
function.

This function returns counts for you entire data frame for each of the
following fields (if populated, columns that are populated only with
NA's are not included in the output):

-   *ActivityTypeCode*

-   *TADA.ActivityMediaName*

-   *ActivityMediaSubdivisionName*

-   *ActivityCommentText*

-   *MonitoringLocationTypeName*

-   *StateCode*

-   *OrganizationFormalName*

-   *TADA.CharacteristicName*

-   *HydrologicCondition*

-   *HydrologicEvent*

-   *BiologicalIntentName*

-   *MeasureQualifierCode*

-   *ActivityGroup*

-   *AssemblageSampledName*

-   *ProjectName*

-   *CharacteristicNameUserSupplied*

-   *DetectionQuantitationLimitTypeName*

-   *SampleTissueAnatomyName*

-   *LaboratoryName*

```{r TADA_FieldCounts_all}
# multiple options

# print table to console
TADA_FieldCounts(TADAProfileClean3)

# create object of table
fieldCounts_Table <- TADA_FieldCounts(TADAProfileClean3)
```

Next, choose a field from the list generated above to view a summary
table or pie chart of the counts of unique values in that field using
**TADA_FieldValuesTable** or **TADA_FieldValuesPie**. We'll start with
*ActivityTypeCode*.

```{r fieldValues_all, fig.width=8, fig.height=6, fig.fullwidth=TRUE}
TADA_FieldValuesTable(TADAProfileClean3, field = "ActivityTypeCode")
TADA_FieldValuesPie(TADAProfileClean3, field = "ActivityTypeCode")
```

The *ActivityTypeCode* field has multiple unique values. Before we
remove the QC samples/measurements from this dataset to prepare for
analyses, lets review flagged Quality Control (QC) values using the
**TADA_FindQCActivities** function, which adds a new TADA
*TADA.ActivityType.Flag* column.

For example, the new *QC_replicate* flag in **TADA.ActivityType.Flag**
column indicates that the flagged rows include any of the following
replicate values: - *Quality Control Field Replicate Habitat
Assessment* - *Quality Control Field Replicate Msr/Obs* - *Quality
Control Field Replicate Portable Data Logger* - *Quality Control Field
Replicate Sample-Composite* - *Quality Control Sample-Field Replicate*

See WQX domain file to review all the **ActivityTypeCode** allowable
values: <https://cdx.epa.gov/wqx/download/DomainValues/ActivityType.CSV>

```{r Run TADA_FindQCActivities to review replicates}
# Review flagged QC samples using the TADA_FindQCActivities function:
# enter ?TADA_FindQCActivities into the console for more information
TADAProfileClean3a <- TADA_FindQCActivities(TADAProfileClean3,
  clean = FALSE,
  flaggedonly = TRUE
)

# Filter to review only data where the TADA.ActivityType.Flag = "QC_replicate"
TADAProfileClean3a <- dplyr::filter(TADAProfileClean3a, TADA.ActivityType.Flag == "QC_replicate")
```

Now, let's run **TADA_PairReplicates** to see if any replicates in this
dataframe can be paired with their original (parent)
samples/measurements.

We found over 100 replicates in this dataframe that have a paired parent
sample/measurement (based on a 10-minute time window, which can be
adjusted if desired). Enter ?TADA_PairReplicates into the console for
more details.

What are replicate samples and how are they used in water analyses?

Replicate field samples are samples taken to assess the reproducibility
of the sampling technique or analytical method. They are independently
carried through all the steps of the sampling and measurement process in
an identical manner to their associated routine field sample and used to
measure the precision of the total sampling method.

Theoretically, the analysis of a replicate field sample should yield a
very similar result as its associated routine field sample. If the
results are not the same or acceptably similar, it could signal possible
contamination or other issues in the sampling chain. However, water
quality can vary at very small scales. So, the field replicate can mix
up analytical precision with small scale variability. Field replicates
tell you the potential for your method to yield the same results at a
single time and place, to the extent that you are actually in exactly
the same place, and the few seconds (or any defined time window) from
one sample to the next does not matter, and the water isn't moving. Be
careful about labeling data as imprecise or bad based on this alone.

Users of TADA have noted that it would be useful to incorporate
replicate field samples into water quality data analysis by (a) flagging
routine field sample measurements whose associated replicate field
sample measurements are outside of a user-defined window of precision
(relative percent difference or absolute difference) and/or (b)
averaging or randomly replacing routine field sample measurements with
their associated replicate field sample measurements.

For now, users can perform these subsequent analyses outside of TADA. A
two-stage data-quality-indicator, where low values should be within the
absolute difference limit and high values within the Relative Percent
Difference (RPD) limit, may be appropriate. RPD is the calculated
difference (RPD) between the routine sample result and its associated
replicate sample result. For example, if the RPD/CV exceeds 20% some
water quality, analysts consider that to be a potentially concerning
lack of precision, especially for non-particulate analytes. However,
depending on the characteristic being analyzed and the sampling method,
acceptable RPDs can vary widely. Therefore, it is best for the user to
define their own level of RPD acceptability. In addition, a tiered
approach may be more appropriate, where the widely used 20% RPD for
measurements can be used for results above XX-times the detection limit,
but also an absolute difference approach can be used for those
result-values near the detection limit, or lower than the detection
limit (e.g., phosphorus). An absolute difference approach is more
appropriate when implementing RPD for samples close to the detection
limit, as even small absolute differences might show up as large
relative percent differences that "fail" the 20% RPD test.

For example, when nutrient concentrations are close to detection limit,
it becomes impossible to have a low RPD. In this scenario, high RPD's
are acceptable because if you stand back and look at ALL the data, and
not just the replicates, these data may be agreeing perfectly well that
nutrients are very low. DO NOT throw out data if RPD is \>20%, unless
you have good reason, or you will potentially bias your data toward high
concentrations. QA procedures should not bias statistical analyses of
the data. Note that a modest error in a measurement will have a much
smaller effect than implementing a QA process that builds in bias.

```{r Run TADA_PairReplicates}
# Run TADA_PairReplicates to add new TADA.ReplicateSampleID column
TADAProfileClean3b <- TADA_PairReplicates(TADAProfileClean3)

# Review unique values in TADA.ReplicateSampleID
unique(TADAProfileClean3b$TADA.ReplicateSampleID)

# Filter df to include only unique values that are paired replicate samples (parent-result and child-replicate).

# Exclude NA's
TADAProfileClean3b <- TADAProfileClean3b[!is.na(TADAProfileClean3b$TADA.ReplicateSampleID), ]
# Exclude orphans
TADAProfileClean3b <- dplyr::filter(TADAProfileClean3b, TADA.ReplicateSampleID != "Orphan")

# Review unique values in TADA.ReplicateSampleID
unique(TADAProfileClean3b$TADA.ReplicateSampleID)
```

Now, let's remove QC samples/measurements from the dataframe.

```{r TADA_FindQCActivities, fig.width=6, fig.height=6, fig.fullwidth=TRUE}
# Remove flagged QC samples using the TADA_FindQCActivities function:
TADAProfileClean4 <- TADA_FindQCActivities(TADAProfileClean3,
  clean = TRUE
)

# regenerate table and pie chart
TADA_FieldValuesTable(TADAProfileClean4, "ActivityTypeCode")
TADA_FieldValuesPie(TADAProfileClean4, "ActivityTypeCode")
```

We've completed our review of the ActivityTypeCode.

Now, let's move on to a different field and see if there are any values
that we want to remove.

In this next example, there are multiple MeasureQualifierCode values to
review.

```{r MeasureQualifierCodeReview, fig.width=8, fig.height=6, fig.fullwidth=TRUE}
TADA_FieldValuesPie(TADAProfileClean4, "MeasureQualifierCode")
```

MeasureQualifierCode definitions are available
[here](https://cdx.epa.gov/wqx/download/DomainValues/ResultMeasureQualifier.CSV){style="font-size: 12pt;"}.

In this example, we show how to use the function
**TADA_FlagMeasureQualifierCode** to add MeasureQualifierCode
definitions and flag and/or remove rows with specific codes under
MeasureQualifierCode that are categorized as "SUSPECT".

See ?TADA_FlagMeasureQualifierCode for more information.

```{r FilterMeasureQualifierCodes}
# flag only
Review_TADAProfileClean4 <- TADA_FlagMeasureQualifierCode(TADAProfileClean4,
  clean = FALSE,
  flaggedonly = TRUE,
  define = TRUE
)
# Review_TADAProfileClean4 is empty because we did not find any Suspect samples

TADAProfileClean4 <- TADA_FlagMeasureQualifierCode(TADAProfileClean4,
  clean = TRUE
)

# regenerate table and pie chart
TADA_FieldValuesPie(TADAProfileClean4, field = "MeasureQualifierCode")
```

## Censored data

Censored data are measurements for which the true value is not known,
but we can estimate the value based on lower or upper detection
conditions and limit types. TADA fills missing *TADA.ResultMeasureValue*
and *TADA.ResultMeasure.MeasureUnitCode* values with values and units
from *TADA.DetectionQuantitationLimitMeasure.MeasureValue* and
*TADA.DetectionQuantitationLimitMeasure.MeasureUnitCode*, respectively,
using the TADA_AutoClean function. In other words, detection limit
information is copied and pasted into the result value column when the
original value is NA and detection limit information is available. The
two columns TADA focuses on to define and flag censored data are
*ResultDetectionConditionText* and *DetectionQuantitationLimitTypeName*.

The TADA package currently has functions that summarize censored data
incidence in the dataset and perform simple substitutions of censored
data values, including x times the detection limit and random selection
of a value between 0 and the detection limit. The user may specify the
methods used for non-detects and over-detects separately in the input to
the **TADA_SimpleCensoredMethods** function.

All censored data functions depend first on the **TADA_IDCensoredData**
utility function, which assigns a *TADA.CensoredData.Flag* to all data
records and identifies over-detects from non-detects using the
*ResultDetectionConditionText* and *DetectionQuantitationLimitTypeName*.
This utility function is automatically run within the TADA_DataRetrieval
function and produces the *TADA.CensoredData.Flag* column. All records
receive one of the following classifications: - Uncensored - Not filled
with detection limit value; a detection. - Non-Detect - Left-censored -
Over-Detect - Right-censored - Other Condition/Limit Populated -
detection condition or limit type are ambiguous or not associated with a
lower/upper detection limit. - Conflict between Condition and Limit -
detection condition and limit type for a single record do not agree,
e.g. one suggests over-detect and the other suggests non-detect. -
Detection condition or detection limit is not documented in TADA
reference tables. - detection condition or limit type is not
characterized in the TADA reference tables, which are based on WQX
domain tables. - Detection condition is missing and required for
censored data ID. - Result needs more information before being
categorized.

The **TADA_SimpleCensoredMethods** function also adds a
*TADA.MeasureQualifierCode.Def* column which contains the
*MeasureQualiferCode* concatenated with the WQX definition for each
qualifier code. This provides additional information to the user which
may assist in deciding which records to retain for analysis.

The next step we take in this example is to perform simple conversions
to the censored data in the dataset: we keep over-detects as is (no
conversion made) and convert non-detect values to 0.5 times the
detection limit (half the detection limit). Please review
**?TADA_Stats** and **?TADA_SimpleCensoredMethods** for more
information.

```{r SummarizeCensoredData}
TADAProfileClean4 <- TADA_SimpleCensoredMethods(TADAProfileClean4,
  nd_method = "multiplier",
  nd_multiplier = 0.5,
  od_method = "as-is",
  od_multiplier = "null"
)
```

Next, review unique values within the *TADA.CensoredData.Flag*,
*DetectionQuantitationLimitTypeName*, and *ResultDetectionConditionText*
columns.

```{r uniquevalues}
# review unique values
unique(TADAProfileClean4$TADA.CensoredData.Flag)
unique(TADAProfileClean4$DetectionQuantitationLimitTypeName)
unique(TADAProfileClean4$ResultDetectionConditionText)
```

Also, review the *TADA.ResultMeasureValueDataTypes.Flag* to see if any
NA's or ND's (non-detects) remain.

```{r ResultMeasureValueDataTypes.Flag_uniquevalues}
unique(TADAProfileClean4$TADA.ResultMeasureValueDataTypes.Flag)
```

Count how many NA's remain in the TADA.ResultMeasureValue.

```{r Review_NA_MeasureValues}
sum(is.na(TADAProfileClean4$TADA.ResultMeasureValue))
```

Filter down to only numeric data. Remove data where the
TADA.ResultMeasureValueDataTypes.Flag = "Text" or "NA - Not Available".
You can also remove any columns not required for the TADA workflow that
contain only NAs. The **TADA_AutoFilter()** function removes non-numeric
data and optional columns containing only NAs.

```{r filter_out_NAs}
# Removes rows where the result value is not numeric. Specifically, removes rows with "Text" or "NA - Not Available" in the TADA.ResultMeasureValueDataTypes.Flag column, or NA in the TADA.ResultMeasureValue column. Removes optional columns containing only NAs.
TADAProfileClean5 <- TADA_AutoFilter(TADAProfileClean4)
```

Double check to make sure no NA's or ND's remain.

```{r check_for_NAs_again}
unique(TADAProfileClean5$TADA.ResultMeasureValueDataTypes.Flag)

sum(is.na(TADAProfileClean5$TADA.ResultMeasureValue))
```

## Convert synonymous characteristic, fraction, speciation, and unit values to a consistent convention based on user-defined/TADA standards

The **TADA_GetSynonymRef** function generates a synonym reference table
that is specific to the input dataframe. Users can review how their
input data relates to standard TADA values for the following elements:

-   *TADA.CharacteristicName*

-   *TADA.ResultSampleFractionText*

-   *TADA.MethodSpeciationName*

-   *TADA.ResultMeasure.MeasureUnitCode*

Users can also edit the reference file to meet their needs if desired.
The download argument can be used to save the harmonization file to your
current working directory when download = TRUE, the default is download
= FALSE.

The **TADA_HarmonizeSynonyms** function then compares the input
dataframe to the TADA Synonym Reference Table and makes conversions
where target characteristics/fractions/speciations/units are provided.
This function also appends a column called TADA.Harmonized.Flag,
indicating which results had metadata changed/converted in this
function. The purpose of this function is to make similar data
consistent and therefore easier to compare and analyze.

Here are some examples of how the TADA_HarmonizeSynonyms function can be
used:

1.  *TADA.ResultSampleFractionText* specifies forms of constituents. In
    some cases, a single *TADA.CharacteristicName* will have both
    "Total" and "Dissolved" forms specified, which should not be
    combined. In these cases, each *TADA.CharacteristicName* and
    *TADA.ResultSampleFractionText* combination is given a different
    identifier. This identifier can be used later on to identify
    comparable data groups for calculating statistics and creating
    figures for each combination.

2.  Some variables have different names but represent the same
    constituent (e.g., "Total Kjeldahl nitrogen (Organic N & NH3)" and
    "Kjeldahl nitrogen"). The **TADA_HarmonizeSynonyms** function gives
    a consistent name (and identifier) to synonyms.

```{r TADA_HarmonizeSynonyms}
UniqueHarmonizationRef <- TADA_GetSynonymRef(TADAProfileClean5)

TADAProfileClean5 <- TADA_HarmonizeSynonyms(TADAProfileClean5,
  ref = UniqueHarmonizationRef
)
```

## Total Nitrogen and Total Phosphorus Calculations

This section covers summing nutrient subspecies to estimate total
nitrogen and phosphorus. This can be a challenging endeavor because some
subspecies/compounds overlap in total nutrient calculations. Thus,
**TADA_CalculateTotalNP** uses the [Nutrient Aggregation
logic](https://echo.epa.gov/trends/loading-tool/resources/nutrient-aggregation)
to add together specific subspecies to obtain a total. TADA adds one
more equation to the mix: total particulate nitrogen + total dissolved
nitrogen. The function uses as many subspecies as possible to calculate
a total for each given site, date, and depth group, but it will estimate
total nitrogen with whatever subspecies are present. This function
creates NEW total nutrient measurements (total nitrogen unfiltered as N
and total phosphorus unfiltered as P) and adds them to the dataframe.

Users can use the default summation worksheet (see
**TADA_GetNutrientSummationRef**) or customize it to suit their needs.
The function also requires a daily aggregation value, either minimum,
maximum, or mean. The default is 'max', which means that if multiple
measurements of the same subspecies-fraction-speciation-unit occur on
the same day at the same site and depth, the function will pick the
maximum value to use in summation calculations.

```{r, TADA_CalculateTotalNP}
TADAProfileClean6 <- TADA_CalculateTotalNP(TADAProfileClean5, daily_agg = "max")
```

## Parameter Level Filtering

In this section, you can select a single parameter, and review the
unique values in specified fields. You may then choose to remove
particular values by filtering.

To start, review the list of parameters in the dataframe using the
**TADA_FieldValuesTable** function.

Enter ?TADA_FieldValuesTable into the console for more information.

```{r TADA_FieldValuesTable_chars}
TADA_FieldValuesTable(TADAProfileClean6, field = "TADA.CharacteristicName")
```

Next, we can revisit the **TADA_FieldCounts** function at the
characteristic level to review how many unique allowable values are
included within each of the following fields:

-   *ActivityCommentText*

-   *ActivityTypeCode*

-   *TADA.ActivityMediaName*

-   *ActivityMediaSubdivisionName*

-   *MeasureQualifierCode*

-   *MonitoringLocationTypeName*

-   *HydrologicCondition*

-   *HydrologicEvent*

-   *ResultStatusIdentifier*

-   *MethodQualifierTypeName*

-   *ResultCommentText*

-   *ResultLaboratoryCommentText*

-   *TADA.ResultMeasure.MeasureUnitCode*

-   *TADA.ResultSampleFractionText*

-   *ResultTemperatureBasisText*

-   *ResultValueTypeName*

-   *ResultWeightBasisText*

-   *SampleCollectionEquipmentName*

-   *LaboratoryName*

-   *MethodDescriptionText*

-   *ResultParticleSizeBasisText*

-   *SampleCollectionMethod.MethodIdentifier*

-   *SampleCollectionMethod.MethodIdentifierContext*

-   *SampleCollectionMethod.MethodName*

-   *DataQuality.BiasValue*

-   *MethodSpeciationName*

-   *ResultAnalyticalMethod.MethodName*

-   *ResultAnalyticalMethod.MethodIdentifier*

-   *ResultAnalyticalMethod.MethodIdentifierContext*

-   *AssemblageSampledName*

-   *DetectionQuantitationLimitTypeName*

```{r TADA_FieldCounts_char}
TADA_FieldCounts(TADAProfileClean6, display = "most", characteristicName = "TOTAL PHOSPHORUS, MIXED FORMS")
```

Selecting a parameter generates the list above, which is subset by the
selected parameter. The list includes fields you may want to review, and
the number of unique values in each field.

Next, choose a field from the list.

Review the WQX domain files for definitions:
<https://www.epa.gov/waterdata/storage-and-retrieval-and-water-quality-exchange-domain-services-and-downloads>

Now, we'll use **TADA_FieldValuesTable** and **TADA_FieldValuesPie** at
the characteristic-level to review a column of interest.

```{r TADA_FieldValuesTable_Pie_char, fig.width=8, fig.height=6, fig.fullwidth=TRUE}
# In this example we review values from the SampleCollectionMethod.MethodName field
TADA_FieldValuesTable(TADAProfileClean6, field = "SampleCollectionMethod.MethodName", characteristicName = "TOTAL PHOSPHORUS, MIXED FORMS")
TADA_FieldValuesPie(TADAProfileClean6, field = "SampleCollectionMethod.MethodName", characteristicName = "TOTAL PHOSPHORUS, MIXED FORMS")
```

Generate a scatterplot with two

```{r TADA_TwoCharacteristicScatterplot, fig.width=8, fig.height=6, fig.fullwidth=TRUE}
# review unique identifiers
unique(TADAProfileClean6$TADA.ComparableDataIdentifier)

# choose two and generate scatterplot
TADA_TwoCharacteristicScatterplot(TADAProfileClean6, id_cols = "TADA.ComparableDataIdentifier", groups = c("TOTAL NITROGEN, MIXED FORMS_UNFILTERED_AS N_MG/L", "TOTAL PHOSPHORUS, MIXED FORMS_UNFILTERED_AS P_UG/L"))
```

Now we will summarize results for a single comparable data group using
the TADA.ComparableDataIdentifier (i.e., comparable characteristic,
unit, speciation, and fraction combination) using **TADA_Histogram** and
**TADA_Boxplot**. Note that users may generate a list output of multiple
plots if their input dataset has more than one unique comparable data
group.

```{r ComparableDataIdentifier_stats_and_histogram, fig.width=8, fig.height=6, fig.fullwidth=TRUE}
# review TADA.ComparableDataIdentifier
unique(TADAProfileClean5$TADA.ComparableDataIdentifier)

# filter dataframe to only "TOTAL PHOSPHORUS, MIXED FORMS"
TADAProfileCleanTP <- dplyr::filter(TADAProfileClean6, TADA.ComparableDataIdentifier == "TOTAL PHOSPHORUS, MIXED FORMS_UNFILTERED_AS P_UG/L")

# generate stats table
TADAProfileCleanTP_stats <- TADA::TADA_Stats(TADAProfileCleanTP)

TADAProfileCleanTP_stats

# generate a histogram
TP_Histogram <- TADA_Histogram(TADAProfileCleanTP, id_cols = "TADA.ComparableDataIdentifier")

# view histogram
TP_Histogram
```

Generate interactive box plot.

```{r boxplot, fig.width=8, fig.height=6, fig.fullwidth=TRUE}
TP_Boxplot <- TADA::TADA_Boxplot(TADAProfileCleanTP, id_cols = "TADA.ComparableDataIdentifier")

TP_Boxplot
```

Generate interactive scatterplot.

```{r scatterplot, fig.width=8, fig.height=6, fig.fullwidth=TRUE}
TADAProfileCleanTP_dailymax <- TADA_AggregateMeasurements(TADAProfileCleanTP,
  agg_fun = c("max"),
  clean = TRUE
)

TP_Scatterplot <- TADA::TADA_Scatterplot(TADAProfileCleanTP_dailymax, id_cols = "TADA.ComparableDataIdentifier")

TP_Scatterplot
```

## Retain TADA Required Columns

Now we can review the "TADA" prefixed columns we have added to the data
set. If we are satisfied with the conversions, filtering, flagging, etc.
and the resulting "TADA" columns, we can use the **TADA_RetainRequired**
function to remove any columns that are not required or used as filters
in the TADA workflow. This reduces the size of the data frame.

```{r retainrequired}
TADAProfileClean7 <- TADA_RetainRequired(TADAProfileClean6)
```

## TADA Shiny Application

Finally, take a look at an alternative workflow, TADA Shiny Module 1:
Data Discovery and Cleaning. This is a Shiny application that runs many
of the TADA functions covered in this document behind a graphical user
interface. The shiny application queries the WQP, contains maps and data
visualizations, flags suspect data results, handles censored data, and
more. You can launch it using the code below.

DRAFT [Module 1](https://owshiny-dev.app.cloud.gov/tada-dev/) is also
currently hosted on the web with minimal server memory/storage
allocated.

```{r, eval = F}
# download TADA Shiny repository
remotes::install_github("USEPA/TADAShiny",
  ref = "develop",
  dependencies = TRUE
)

# launch the app locally.
TADAShiny::run_app()
```

## Download this Article from GitHub

Go to:
<https://github.com/USEPA/TADA/blob/develop/vignettes/TADAModule1.Rmd>

[![Click the highlighted icon to download TADAModule1.Rmd from GitHub.
Open this file in R Studio to follow along. Alternatively, you can copy
and paste desired lines of code from here into your own script. Note:
You must have a GitHub account to download TADAModule1.Rmd from
GitHub](images/DownloadModule1.jpg)](https://github.com/USEPA/TADA/blob/develop/vignettes/TADAModule1.Rmd)
