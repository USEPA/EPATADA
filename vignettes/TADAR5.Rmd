---
title: "TADA Package Training: A Markdown For Region 5 R Users Network"
author: "TADA Team"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\usepackage[utf8]{inputenc}
  %\VignetteIndexEntry{TADA Package Training: A Markdown For Region 5 R Users Network}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: 72
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Welcome

Thank you for your interest in Tools for Automated Data Analysis (TADA). TADA is an open-source tool set built in the R programming language. This [RMarkdown](https://bookdown.org/yihui/rmarkdown/) document walks users through how to download the TADA R package from GitHub, access and parameterize several important functions with a sample dataset and create basic visualizations. The sample data set contains data from one week from
all EPA Region 5 states.

This example workflow demonstrates how to use TADA package functions to  query and download Water Quality Portal data, filter it for records of interest, and run various QC checks. At the end of the QC checks, the user should be confident that their data are properly documented and applicable to the analysis at hand.

**Note: TADA is still under development. New functionality is added weekly, and sometimes we need to make bug fixes in response to tester and user feedback. We appreciate your feedback, patience, and interest in these helpful tools.**

**If you are interested in contributing to TADA development, more information is available at [Contributing] (https://usepa.github.io/TADA/articles/CONTRIBUTING.html). We welcome collaboration with external partners.**

## Install and load packages

First, install and load the remotes package specifying the repo. This
is needed before installing TADA because it is only available on GitHub.

```{r install_remotes, eval = F, results = 'hide', message = FALSE, warning = FALSE}
install.packages("remotes",
  repos = "http://cran.us.r-project.org"
)
library(remotes)
```

Next, install and load TADA using the remotes package. TADA R Package dependencies will also be downloaded automatically from CRAN
with the TADA install. You may be prompted in the console to update dependency packages that have more recent versions available. If you see this prompt, it is recommended to update all of them (enter 1 into the console).

```{r install_TADA, eval = F, results = 'hide', message = FALSE, warning = FALSE}
remotes::install_github("USEPA/TADA",
  ref = "develop",
  dependencies = TRUE
)

```

Finally, use the **library()** function to load the TADA R Package into your R session.

```{r library, results = 'hide', message = FALSE, warning = FALSE}
library(TADA)
```

## Help pages

All TADA R package functions have their own individual help pages, listed on the [Function reference](https://usepa.github.io/TADA/reference/index.html) page on the GitHub site. Users can also access the help page for a given function in R or RStudio using the following format (example below): `?TADA::[name of TADA function]`

```{r}
?TADA::TADA_DataRetrieval
```

## Retrieve WQP data

WQP data is retrieved and processed for compatibility with TADA. This
function, **TADA_DataRetrieval**, builds on USGS's dataRetrieval R
package functions. It joins three WQP profiles: Site,
Sample Results (physical/chemical metadata),
and Project. In addition, it changes all data in the
Characteristic, Speciation, Fraction, and Unit fields to uppercase,
removes exact duplicates, and addresses result values that include
special characters.

The characteristics pulled
from [Water Quality Portal (WQP)](https://www.waterqualitydata.us/) are not restricted and can include: 

-   startDate

-   endDate

-   characteristicName

-   sampleMedia

-   siteType

-   statecode (review list of possible state and territory
    [abbreviations](https://www2.census.gov/geo/docs/reference/state.txt))

-   countycode

-   siteid

-   organization

-   project

-   huc

-   characteristicType

The default TADA_DataRetrieval function
automatically runs the **TADA_AutoClean** function. In this example, we will set **TADA_AutoClean = FALSE** and run it as a separate step in the work flow. 

Tips:

1.  All the query filters for the WQP work as an AND but within the
    fields there are ORs. For example:

    -   Characteristics: If you choose pH & DO - it's an OR. This means
        you will retrieve both pH OR DO data if available.

    -   States: Similarly, if you choose MI and IL, it's an OR. This
        means you will retrieve both MI OR IL data if available.

    -   Combinations of fields are ANDs, such as State/MI AND
        Characteristic/DO". This means you will receive all DO data
        available in MI.

    -   "Characteristic" and "Characteristic Type" also work as an AND.
        This means that the Characteristic must fall within the
        CharacteristicGroup if both filters are being used, if not you
        will get an error.

2.  The "siteid" is a general term WQP uses to describe both Site IDs
    from USGS databases and Monitoring Location Identifiers (from WQX).
    Each monitoring location in the Water Quality
    Portal (WQP) has a unique Monitoring Location Identifier, regardless
    of the database from which it derives. 
    
Additional resources:

-   Review function documentation by entering the following code into
    the console: ?TADA_DataRetrieval

-   [Water Quality Portal Web Services
    Guide](https://www.waterqualitydata.us/webservices_documentation/)

-   TADA Module 1 (TADA Package Training: A Markdown For Region 5 R Users Network)


The example dataset in this demo includes monitoring data from multiple organizations collected during one week (May 1, 2019 - May, 7 2019) in Region 5 states (Illinois, Indiana, Michigan, Minnesota, Ohio, and Wisconsin). 

For demonstration purposes, the R5 example data set has already been downloaded. If you're following along you can run the code chunk below to access the pre-downloaded data set. The original query has also been included and can be accessed by uncommenting and running the TADA_DataRetrieval function below.

Downloads using TADA_DataRetrieval will have the same columns each time,
but be aware that data are uploaded to the Water Quality Portal by
individual organizations, which may or may not follow the same
conventions. Data and metadata quality are not guaranteed! Make sure to
carefully explore any data and make conservative quality assurance
decisions where information is limited.

Keep in mind that any columns with a "TADA" prefix were added during data retrieval.

Note: TADA_DataRetrieval  automatically
converts the date times to UTC and data
to dates, datetimes, and numerics based on a standard algorithm. 

**Note:** USGS and EPA are working together to create WQP 3.0 data profiles. Once released, one data profile will contain the columns critical to TADA, removing the need to combine profiles in this first step. TADA package users likely will not notice a difference in their usage of the `TADA_DataRetrieval` function, but it will simplify the steps needed to upload a custom or WQP GUI-downloaded data set into the R package.


```{r TADA_DataRetrieval}
# Uncomment query below to download data set from WQP
# TADAProfile <- TADA_DataRetrieval(statecode = c("IL", "IN", "MI", "MN", "OH", "WI"), startDate = "2019-05-01", endDate = "2019-05-07", applyautoclean = FALSE)

# For demo purposes, import pre-downloaded R5 data set

R5Profile <- TADA::Data_R5_TADAPackageDemo

# 
```

**Question 1: How many results did TADA_DataRetrieval return?**

```{r q1}

R5_nresults <- nrow(R5Profile) # returns x and of x (as the numbers of rows and columns respectively)

```

**Answer: **
There are `r R5_nresults` in the data set.

If you need to download a large amount of data from across a large area,
and the TADA_DataRetrieval function is not working due to WQP timeout
issues, then the **TADA_BigDataRetrieval** function may work better. See ?TADA_BigDataRetrieval for more details or the TADA Module 1 vignette for more details. 

## Review and Filter By Media Type

TADA is primarily designed to accommodate water data from the WQP. Let's see what activity media types are represented in the data set.

To help answer this question, we can use TADA functions to create a 
table or pie chart of the counts of unique values in a user-specified field with
**TADA_FieldValuesTable** or **TADA_FieldValuesPie**. We'll start with
*TADA.ActivityMediaName*.

```{r fieldValues_all, fig.width=8, fig.height=6, fig.fullwidth=TRUE}

FieldValues_ActMedia <- TADA_FieldValuesTable(R5Profile, field = "ActivityMediaName")

TADA_FieldValuesPie(R5Profile, field = "ActivityMediaName")
```


**Question 2: How many unique 'ActivityMediaName' values exist in your dataset? Are there any media types that are not water?**

```{r fieldvales_actmedia, echo = FALSE}

n_media <- length(unique(FieldValues_ActMedia$Value))

unique_media <- FieldValues_ActMedia %>%
  dplyr::select(Value) %>%
  dplyr::mutate(media = paste(Value, collapse = ", ")) %>%
  dplyr::select(media) %>%
  unique() %>%
  stringi::stri_replace_last(fixed = ",", " and") 

n_not_water <- FieldValues_ActMedia %>% 
  dplyr::filter(Value != "Water")%>% 
  dplyr::summarize(n_not_water = length(Value))

```


**Answer:**
There are `r n_media` unique ActivityMediaNames in the data set. They are: `r unique_media`. `r n_not_water` of these are not water.

Some TADA users are interested in using WQP data for surface water only or including some non-water data. The **TADA_AnalysisDataFilter** function can assist in identifying results of interest. Multiple columns are used to identify groundwater results as organizations may populate different combinations of fields in order to identify groundwater results.

This function identifies surface water, groundwater, and sediment results. Users can  specify whether all results should be returned with a new column, *TADA.UseForAnalysis.Flag*, providing information about the result's media type of and identifying if the result should be included in further analysis or if only results that should be included are returned. 

The defaults are to include surface water, exclude groundwater and sediment, and to return all results with the added *TADA.UseForAnalysis.Flag* column (clean = FALSE). This is shown in the active example below. 

We can use TADA_FieldValuesTable and TADA_FieldValuesPie again to review this more specific breakdown of results by media type.

**Note:** When WQX 3.0 data profiles are released, this function will be modified to include fish tissue an option.

```{r AnalysisDataFilter}

# Filter to flag only surface water results for use in analysis 

R5Profile <- TADA_AnalysisDataFilter(R5Profile, clean = FALSE)

FieldValues_AnalysisFlag <- TADA_FieldValuesTable(R5Profile, field = "TADA.UseForAnalysis.Flag")

TADA_FieldValuesPie(R5Profile, field = "TADA.UseForAnalysis.Flag")
```

```{r q3, echo = FALSE}

# Filter to flag only surface water results for use in analysis 

n_sur_water <- FieldValues_AnalysisFlag %>%
  dplyr::filter(Value == "Yes - SURFACE WATER") %>%
  dplyr::select(Count)
  
```

**Question 3: How many SURFACE WATER results can we retain for further analysis**

**Answer:**
There are `r n_sur_water` surface water results in the R5 data set. Let's filter out any other results flagged "No" to reduce the size of the data set before continuing.

```{r AnalysisDataFilter2}

# Filter to retain only surface water results for use in analysis 

R5Profile <- R5Profile %>%
  dplyr::filter(TADA.UseForAnalysis.Flag == "Yes - SURFACE WATER")
```

## AutoClean

Now **TADA_AutoClean** can be run on the reduced data set. It performs the following functions on the data retrieved from the WQP:

-   **TADA_ConvertSpecialChars** - converts result value columns to numeric and flags non-numeric values that could not be converted.

-   **TADA_ConvertResultUnits** - unifies result units for easier quality control and review

-   **TADA_ConvertDepthUnits** - converts depth units to a consistent unit (meters). This function can also be run on its own, for example if you would like to convert depths from meters to feet later in the workflow.

-   **TADA_IDCensoredData** - categorizes detection limit data and identifies mismatches in result detection condition and result detection limit type. 

-   Other helpful actions - converts important text columns to all upper-case letters, removes exact duplicates, and uses WQX format rules to harmonize specific NWIS metadata conventions (e.g. move characteristic speciation from the TADA.ResultMeasure.MeasureUnitCode column to the TADA.MethodSpeciationName column)

As a general rule, TADA functions do not change any contents in the WQP-served
columns. Instead, they add new columns with the prefix "TADA." The following
columns are numeric versions of their WQP origins:

    -   *TADA.ResultMeasureValue*

    -   *TADA.DetectionQuantitationLimitMeasure.MeasureValue*

    -   *TADA.LatitudeMeasure*

    -   *TADA.LongitudeMeasure*

These functions also add the columns
*TADA.ResultMeasureValueDataTypes.Flag* and
*TADA.DetectionQuantitationLimitMeasure.MeasureValueDataTypes.Flag*, which
provide information about the result values that is needed to address
censored data later on (i.e., nondetections). Specifically, these new
columns flag if special characters are included in result values, and
specifies what the special characters are.

``` {r TADA_AutoClean}

# run TADA_AutoClean on filtered dataset to convert special characters, result units, and depth units and identify censored data.

R5Profile <- TADA_AutoClean(R5Profile)

```

Review all column names in the TADA Profile to familiarize yourself with the dataset after TADA_AutoClean has added additional TADA prefixed columns. **TADA_SummarizeColumn** summarizes the data set based on the user specified column and returns a dataframe displaying the number of sites and number of records for each unique value in the specified column. The example below uses TADA.CharacteristicName. 

```{r TADA_SummarizeColumn}

# View column names for TADAProfile
colnames(R5Profile)

# Review the number of sites and number of records for each CharacteristicName in TADAProfile
R5Profile_CharSummary <- TADA_SummarizeColumn(R5Profile, "TADA.CharacteristicName")

# View TADAProfile_CharSummary
R5Profile_CharSummary
```

```{r q4, echo = FALSE}

# Number of unique values of TADA.CharacteristicName

n_char_name <- length(unique(R5Profile_CharSummary$TADA.CharacteristicName))

identify_max_sites <- R5Profile_CharSummary %>%
  dplyr::slice_max(n_sites) 

char_max_sites <- identify_max_sites %>%
  dplyr::select(TADA.CharacteristicName)

max_sites <- identify_max_sites %>%
  dplyr::select(n_sites)
  
identify_max_results <-R5Profile_CharSummary %>%
  dplyr::slice_max(n_records)

char_max_results <- identify_max_results %>%
  dplyr::select(TADA.CharacteristicName)

max_sites <- identify_max_results %>%
  dplyr::select(n_records)
```

**Question 4: How many unique values of TADA.CharacteristicName are included in the data set? Which TADA.CharactersticName was collected at the greatest number of sites? Which TADA.CharactersticName has the most results?**

**Answer:**
There are `r n_char_name` unique values of TADA.CharacteristicName in the R5 data set. `r char_max_sites` was collected at the greatest number of sites (n = `r max_sites`). `r char_max_results` has the most results (n = `r max_results`).

## Invalid coordinates

Review station locations and summary information using the
**TADA_OverviewMap** function. **TADA_OverviewMap** counts the number of
unique results, characteristics, and organizations at each monitoring
location in the dataset and creates a tidy map for reviewing summary
stats spatially. Larger point sizes indicate more results collected at a
given site, while darker blue colors indicate more unique
characteristics collected at the site. Users may click on a site to view
a pop-up with this summary information. This map may inform a
user's decision to remove/correct sites that are outside the US.

```{r Map, fig.width=8, fig.height=6, fig.fullwidth=TRUE}
TADA_OverviewMap(R5Profile)
```

The TADA **TADA_FlagCoordinates** function identifies and flags
potentially invalid coordinate data. While its functionality is
showcased here, it is always important to review any invalid outputs
before cleaning to reduce the risk of leaving out usable data/sites.

Allowable values for clean_outsideUSA are "no", "remove", or "change
sign". The default is "no" which flags latitude and longitude
coordinates outside the USA. Assigning clean_ousideUSA = "remove" will
remove rows of data with coordinates outside the USA. And assigning
clean_outsideUSA = "change sign" will flip the sign of latitude or
longitude coordinates flagged as outside the USA. The "change sign"
option should only be used when it is known that coordinates were
entered with the wrong sign in WQX; additionally, the data owner should
fix these incorrect coordinates in the raw data through the WQX - for
assistance email the WQX help desk: WQX\@epa.gov

Allowable values for clean_imprecise are TRUE or FALSE. The default is
FALSE which flags rows of data with invalid or imprecise coordinates
without removing them. Assigning clean_imprecise = TRUE will remove rows
of data with invalid or imprecise coordinates.

Allowable values for flaggedonly are TRUE or FALSE. The default is FALSE
which keeps all rows of data regardless of flag status. Assigning
flaggedonly = TRUE filters the dataframe to show only rows of data which
are flagged.

When clean_outsideUSA = "no" and/or clean_imprecise = FALSE, a column
will be appended titled "TADA.InvalidCoordinates.Flag" with the
following flags (if relevant to dataframe):

-   If the latitude is less than zero, the row will be flagged with
    "LAT_OutsideUSA". (Exception for American Samoa)

-   If the longitude is greater than zero AND less than 145, the row
    will be flagged as "LONG_OutsideUSA". (Exceptions for Guam and the
    Northern Mariana Islands)

-   If the latitude or longitude contains the string, "999", the row
    will be flagged as invalid.

-   Finally, precision can be measured by the number of decimal places
    in the latitude and longitude provided. If either does not have any
    numbers to the right of the decimal point, the row will be flagged
    as "Imprecise".

```{r TADA_FlagCoordinates}
# flag only
R5ProfileClean1 <- TADA_FlagCoordinates(R5Profile, clean_outsideUSA = "no", clean_imprecise = FALSE, flaggedonly = FALSE)

# review unique flags in R5ProfileClean1
unique(R5ProfileClean1$TADA.InvalidCoordinates.Flag)

# review unique MonitoringLocationIdentifiers in your flag dataframe
unique(R5ProfileClean1$MonitoringLocationIdentifier)

Unique_CoordinateFlags <- R5ProfileClean1 %>%
  dplyr::select(
    "MonitoringLocationIdentifier",
    "MonitoringLocationName",
    "TADA.InvalidCoordinates.Flag",
    "OrganizationIdentifier",
    "TADA.LongitudeMeasure",
    "TADA.LatitudeMeasure",
    "MonitoringLocationTypeName",
    "CountryCode",
    "StateCode",
    "CountyCode",
    "HUCEightDigitCode",
    "MonitoringLocationDescriptionText",
    "ProjectName",
    "ProjectIdentifier",
    "OrganizationFormalName"
  ) %>%
  dplyr::distinct() %>%
  dplyr::filter(TADA.InvalidCoordinates.Flag != "OK")

Unique_CoordinateFlags

# if needed, un-comment below to change the sign for all data for sites flagged as outside the USA. You can also change FALSE to TRUE if you want to remove sites outside of the US or sites with imprecise lat/longs

# R5ProfileClean1 <- TADA_FlagCoordinates(R5Profile, clean_outsideUSA = "change sign", clean_imprecise = FALSE, flaggedonly = FALSE)


```

```{r qcoord, echo = FALSE}

# review unique flags in R5ProfileClean1
n_unique_coord_flag <- length(unique(R5ProfileClean1$TADA.InvalidCoordinates.Flag))

unique_coord_flag <- paste(unique(R5ProfileClean1$TADA.InvalidCoordinates.Flag), collapse = ", ") %>%
stringi::stri_replace_last(fixed = ", ", " and ")

n_outside_US <- Unique_CoordinateFlags %>%
  dplyr::filter(TADA.InvalidCoordinates.Flag %in%
                  c("LONG_OutsideUSA", "LAT_OutsideUSA")) %>%
  nrow()

n_imprecise <- Unique_CoordinateFlags %>%
  dplyr::filter(TADA.InvalidCoordinates.Flag == "Imprecise_lessthan3decimaldigits") %>%
  nrow()
  


```

**Question 4: How many unique coordinates flags were identified? How many Monitoring Locations in the data set had coordinates outside the US? How many Monitoring Locations were flagged with imprecise coordinates?**

**Answer:**
There are `r n_unique_coord_flag` unique coordinates flags (`r unique_coord_flag`). There are `r n_outside_US` Monitoring Locations with coordinates flagged outside the US. There are `r n_imprecise` Monitoring Locations with imprecise coordinates flagged

## Statistically aggregated data

The **TADA_FindContinuousData** function checks for and removes
statistically aggregated high frequency (i.e., continuous) data, if
present.

The Water Quality Portal (WQP) is not currently designed to store
high-frequency sensor data (more than 1 value per day). However,
sometimes data providers choose to aggregate their continuous data to avg, max, or min value over daily or other intervals, and then submit that aggregated data to
the WQP through WQX. This
type of high frequency data may (or may not) be usable for your analyses. Therefore, this
function uses metadata submitted by data providers to flag rows with
aggregated continuous data. This is done by flagging results where the
ResultDetectionConditionText = "Reported in Raw Data (attached)".

-   When clean = FALSE, a column titled "TADA.AggregatedContinuousData"
    is added to the dataframe to indicate if the row includes aggregated
    continuous data, "Y", or not, "N".

-   When clean = TRUE, rows with aggregated continuous data are removed
    from the dataframe and no column will be appended. The default is
    clean = TRUE.

An additional input called flaggedonly will allow the user to filter data
to show only rows of aggregated continuous data. Allowable values for
flaggedonly are TRUE or FALSE. The default is FALSE which keeps all rows
of data regardless of flag status. Assigning flaggedonly = TRUE filters
the dataframe to show only rows of data which are flagged "Y".

See function documentation for additional function options by entering
the following code in the console: ?TADA_FindContinuousData

```{r AggregatedContinuousData}
R5ProfileClean1 <- TADA_FindContinuousData(R5ProfileClean1,
  clean = FALSE
)
```

```{r q5, echo = FALSE}

n_cont_agg <- R5ProfileClean1 %>%
  dplyr::filter(TADA.AggregatedContinuousData.Flag == "Y") %>%
  nrow()
```

**Question 5: How many results are aggregated and associated with continuous data?**

**Answer:**
There are `r n_cont_aggS` results associated with aggregated continuous data.

## WQX Quality Assurance and Quality Control (QAQC) Service Result Flags

Run the following result functions to address invalid method, fraction,
speciation, and unit metadata by characteristic. The default is clean =
TRUE, which will remove invalid results. You can change this to clean =
FALSE to flag results, but not remove them.

See documentation for more details:

-   ?**TADA_FlagMethod**

    -   When clean = FALSE, this function adds the following column to
        your dataframe: TADA.AnalyticalMethod.Flag. This column flags
        invalid TADA.CharacteristicName,
        ResultAnalyticalMethod/MethodIdentifier, and
        ResultAnalyticalMethod/MethodIdentifierContext combinations in
        your dataframe either "NonStandardized", "Invalid", or "Valid".

    -   When clean = TRUE, "Invalid" rows are removed from the dataframe
        and no column will be appended.

    -   When flaggedonly = TRUE, the dataframe is filtered to only the
        rows flagged as "Invalid"; default is flaggedonly = FALSE.

-   ?**TADA_FlagSpeciation**

    -   When clean = "none", this function adds the following column to
        your dataframe: TADA.MethodSpeciation.Flag. This column flags
        each TADA.CharacteristicName and MethodSpeciationName
        combination in your dataframe as either "NonStandardized",

        "Invalid", or "Valid".

    -   When clean = "invalid_only", only "Invalid" rows are removed
        from the dataframe. Default is clean = "invalid_only".

    -   When clean = "nonstandardized_only", only "NonStandardized" rows
        are removed from the dataframe.

    -   When clean = "both", "Invalid" and "NonStandardized" rows are
        removed from the dataframe.

    -   When clean = "none", no rows are removed from the dataframe.

    -   When flaggedonly = TRUE, the dataframe is filtered to only the
        rows flagged as "Invalid" or "NonStandardized"; default is
        flaggedonly = FALSE.

-   ?**TADA_FlagResultUnit**

    -   When clean = FALSE, the following column will be added to your
        dataframe: TADA.ResultUnit.Flag. This column flags each
        TADA.CharacteristicName, TADA.ActivityMediaName, and
        TADA.ResultMeasure.MeasureUnitCode combination in your dataframe
        as either "NonStandardized", "Invalid", or "Valid".

    -   When clean = TRUE, "Invalid" rows are removed from the dataframe
        and no column will be appended.

    -   When flaggedonly = TRUE, the dataframe is filtered to only the
        rows flagged as "Invalid"; default is flaggedonly = FALSE.

-   ?**TADA_FlagFraction**

    -   When clean = FALSE, this function adds the following column to
        your dataframe: TADA.SampleFraction.Flag. This column flags each
        TADA.CharacteristicName and TADA.ResultSampleFractionText
        combination in your dataframe as either "NonStandardized",
        "Invalid", or "Valid".
    -   When clean = TRUE, "Invalid" rows are removed from the dataframe
        and no column will be appended.
    -   When flaggedonly = TRUE, the dataframe is filtered to only the
        rows flagged as "Invalid"; default is flaggedonly = FALSE.

```{r Invalid_Method_Fraction_Speciation_ResultUnit}
R5ProfileClean2 <- TADA_FlagMethod(R5ProfileClean1, clean = TRUE)

R5ProfileClean2 <- TADA_FlagFraction(R5ProfileClean2, clean = TRUE)

R5ProfileClean2 <- TADA_FlagSpeciation(R5ProfileClean2, clean = "invalid_only")

R5ProfileClean2 <- TADA_FlagResultUnit(R5ProfileClean2, clean = "invalid_only")

# Determine number of rows removed

R5ProfileClean1_n <- nrow(R5ProfileClean1)

R5ProfileClean2_n <- nrow(R5ProfileClean2)

rows_removed_n <- R5ProfileClean1_n - R5ProfileClean2_n


```

**Question 6: How many results were removed due to the WQX QAQC service functions? What might be a helpful first step in investigating why these removals occurred?**

**Answer:**
`r rows_removed_n` were removed from the data set as a result of TADA_FlagMethod, TADA_FlagFraction, TADA_FlagSpeciation, and TADA_FlagResultUnit. To learn more about specific methods, fractions, speciation, or result units that were flagged for removal, you could re-run the flag functions with clean = FALSE and filter by flag types.

## WQX national upper and lower thresholds

Run the following code to flag or remove results that are above or below
the national upper and lower bound for each characteristic and unit
combination. See documentation for more details:

-   ?**TADA_FlagAboveThreshold**

    -   When clean = FALSE, the following column is added to your
        dataframe: TADA.ResultValueAboveUpperThreshold.Flag. This column
        flags rows with data that are above the upper WQX threshold.
        The default is clean = FALSE.

    -   When clean = TRUE, data that is above the upper WQX threshold is
        removed from the dataframe. 

    -   When flaggedonly = TRUE, the dataframe is filtered to only the
        rows flagged as above the upper WQX threshold; default is
        flaggedonly = FALSE.

-   ?**TADA_FlagBelowThreshold**

    -   When clean = FALSE, the following column is added to your
        dataframe: TADA.ResultValueBelowLowerThreshold.Flag. This column
        flags rows with data that are below the lower WQX threshold.
        The default is clean = FALSE.

    -   When clean = TRUE, data that is below the lower WQX threshold is
        removed from the dataframe. 

    -   When flaggedonly = TRUE, the dataframe is filtered to only the
        rows flagged as below the lower WQX threshold; default is
        flaggedonly = FALSE.

```{r WQX_Thresholds}
R5ProfileClean3 <- TADA_FlagAboveThreshold(R5ProfileClean2, clean = TRUE)

R5ProfileClean3 <- TADA_FlagBelowThreshold(R5ProfileClean3, clean = TRUE)

R5ProfileClean2_n <- nrow(R5ProfileClean2)

R5ProfileClean3_n <- nrow(R5ProfileClean3)

threshold_removed_n <- R5ProfileClean2_n - R5ProfileClean3_n
```

**Question 6: How many results were removed due to the WQX upper and lower thresholds?**

**Answer:**
`r threshold_removed_n` results were removed due to falling outside the WQX upper or lower thresholds.


## Potential duplicates

Sometimes multiple organizations submit the exact same data to Water
Quality Portal (WQP), which can affect water quality analyses and
assessments. Let;s start by looking at the submitting organizations for this data set and their relative contributions.

```{r Organizations}
FieldValues_Orgs <- TADA_FieldValuesTable(R5ProfileClean3, field = "OrganizationFormalName")

TADA_FieldValuesPie(R5ProfileClean3, field = "OrganizationFormalName")
```

```{r q7, echo = FALSE}

orgs_n <- length(unique(FieldValues_Orgs$Value))

org_max <- dplyr::slice_max(FieldValues_Orgs, Count) 
  
org_min <- dplyr::slice_min(FieldValues_Orgs, Count) 
```
**Question 7: How many organizations submitted data? Which organization submitted the most results? Which organization submitted the fewest results?**

**Answer:**
`r orgs_n` unique organizations submitted data. `r org_max$Value` submitted the most results (n = `r org_max$Count`). `r org_min$Value` submitted the most results (n = `r org_min$Count`).


Organizations occasionally submit the same data multiple times to the Portal. The following functions check for and identify data that may be duplicates based on date, time, characteristic, result value, and a distance buffer. Each pair or group of potential duplicate rows is flagged with a
unique ID. For more information, review the documentation by entering
the following into the console:

-   ?**TADA_FindPotentialDuplicatesMultipleOrgs**
-   ?**TADA_FindPotentialDuplicatesSingleOrg**


```{r FindPotentialDuplicates}
R5ProfileClean3 <- TADA_FindPotentialDuplicatesMultipleOrgs(R5ProfileClean3,
  dist_buffer = 100,
  org_hierarchy = "none"
)

R5ProfileClean3 <- TADA_FindPotentialDuplicatesSingleOrg(R5ProfileClean3)

# Remove multiple and single org duplicates (random selection of single result)

R5ProfileClean4 <- R5ProfileClean3 %>%
  dplyr::filter(TADA.ResultSelectedMultipleOrgs == "Y",
                TADA.SingleOrgDup.Flag == "Unique")

# Determine how many duplicate results were removed

R5ProfileClean3_n <- nrow(R5ProfileClean3)

R5ProfileClean4_n <- nrow(R5ProfileClean4)

duplicate_removed_n <- R5ProfileClean3_n - R5ProfileClean4_n
  
```

**Question 8: How many total duplicate results were removed? How could you prioritize retaining results from your organization when duplicate results are identified?**

**Answer:**
`r duplicate_removed_n` duplicates were identified by TADA_FindPotentialDuplicatesMultipleOrgs and TADA_FindPotentialDuplicatesSingleOrg. To priorize results from a particular agency or agencies see documentation for ?TADA_FindDuplicatesMultipleOrgs for information on using the org_hierarchy argument.

## Full Dataframe Filtering

In this section a TADA user will want to review the unique values in
specific fields and may choose to remove data with particular values.

To start, review the list of common fields used for filtering, and the
number of unique values in each field using the **TADA_FieldCounts**
function.

This function returns counts for you entire data frame for each of the
following fields (if populated, columns that are populated only with
NA's are not included in the output):

-   *ActivityTypeCode*

-   *TADA.ActivityMediaName*

-   *ActivityMediaSubdivisionName*

-   *ActivityCommentText*

-   *MonitoringLocationTypeName*

-   *StateCode*

-   *OrganizationFormalName*

-   *TADA.CharacteristicName*

-   *HydrologicCondition*

-   *HydrologicEvent*

-   *BiologicalIntentName*

-   *MeasureQualifierCode*

-   *ActivityGroup*

-   *AssemblageSampledName*

-   *ProjectName*

-   *CharacteristicNameUserSupplied*

-   *DetectionQuantitationLimitTypeName*

-   *SampleTissueAnatomyName*

-   *LaboratoryName*

```{r TADA_FieldCounts_all}
# multiple options

# print table to console
TADA_FieldCounts(R5ProfileClean4)

# create object of table
R5_fieldCounts_Table <- TADA_FieldCounts(R5ProfileClean4)
```


The *ActivityTypeCode* field has multiple unique values. Before we remove the 
QC samples/measurements from this dataset to prepare for analyses, lets review 
flagged Quality Control (QC) values using the
**TADA_FindQCActivities** function, which adds a new TADA *TADA.ActivityType.Flag*
column.

For example, the new *QC_replicate* flag in *TADA.ActivityType.Flag* column 
indicates that the flagged rows include any of the following replicate values:
-   *Quality Control Field Replicate Habitat Assessment*
-   *Quality Control Field Replicate Msr/Obs*
-   *Quality Control Field Replicate Portable Data Logger*
-   *Quality Control Field Replicate Sample-Composite*
-   *Quality Control Sample-Field Replicate*

See WQX domain file to review all the **ActivityTypeCode** allowable values:
https://cdx.epa.gov/wqx/download/DomainValues/ActivityType.CSV

```{r Run TADA_FindQCActivities to review replicates}
# Review flagged QC samples using the TADA_FindQCActivities function:
# enter ?TADA_FindQCActivities into the console for more information
R5ProfileClean4a <- TADA_FindQCActivities(R5ProfileClean4,
  clean = FALSE,
  flaggedonly = TRUE
)

# Filter to review only data where the TADA.ActivityType.Flag = "QC_replicate"
R5ProfileClean4a <- dplyr::filter(R5ProfileClean4a, TADA.ActivityType.Flag == "QC_replicate")
```

Now, let's run **TADA_PairReplicates** to see if any replicates in this 
dataframe can be paired with their original (parent) samples/measurements.

```{r Run TADA_PairReplicates}
# Run TADA_PairReplicates to add new TADA.ReplicateSampleID column
R5ProfileClean4b <- TADA_PairReplicates(R5ProfileClean4)

# Review unique values in TADA.ReplicateSampleID
unique(R5ProfileClean4b$TADA.ReplicateSampleID)

# Filter df to include only unique values that are paired replicate samples (parent-result and child-replicate).

# Exclude NA's
R5ProfileClean4b <- R5ProfileClean4b[!is.na(R5ProfileClean4b$TADA.ReplicateSampleID), ]
# Exclude orphans
R5ProfileClean4b <- dplyr::filter(R5ProfileClean4b, TADA.ReplicateSampleID != "Orphan")

# Number of paired replicates

paired_reps_n <- nrow(R5ProfileClean4b)

# Review unique values in TADA.ReplicateSampleID
unique(R5ProfileClean4b$TADA.ReplicateSampleID)
```

**Question 9: How many replicates in this data set have a paired parent sample/measurement?**

**Answer:**
There are `r paired_reps_n` replicates in this data set with a paired parent sample/measurement based on the default 10-minute time window (this value can be adujsted, enter ?TADA_PairReplicates into the console for more information).

Users of TADA have noted that it would be useful to incorporate replicate field samples into water quality data analysis. For now, users can perform these subsequent analyses outside of TADA. See TADA Module 1 for more information about replicate field samples and additional analyses you may want to perform outside of TADA.

For now, let's remove QC samples/measurements from the dataframe.

```{r TADA_FindQCActivities, fig.width=6, fig.height=6, fig.fullwidth=TRUE}
# Remove flagged QC samples using the TADA_FindQCActivities function:
R5ProfileClean5 <- TADA_FindQCActivities(R5ProfileClean4,
  clean = TRUE
)

# regenerate table and pie chart
TADA_FieldValuesTable(R5ProfileClean5, "ActivityTypeCode")

TADA_FieldValuesPie(R5ProfileClean5, "ActivityTypeCode")
```

```{r q10, fig.width=6, fig.height=6, fig.fullwidth=TRUE}
# Number of ActivityTypeCodes

activity_type_code_n <- length(unique(R5ProfileClean5$ActivityTypeCode))

# List ActivityTypeCodes

activity_type_list <- paste(unique(R5ProfileClean5$ActivityTypeCode), collapse = ", ") %>%
  stringi::stri_replace_last(fixed = ", " , ", and ")

# Most common Activity Type Code
most_common_activity <- TADA_FieldValuesTable(R5ProfileClean5, "ActivityTypeCode") %>%
  dplyr::slice_max(Count)
```

**Question 10: How many ActivityTypeCodes are present after removing QC samples? Which ActivityTypeCode is the most common?**

**Answer:**
There are `r` unique ActivityTypeCodes present after removing QC samples. `r most_common_activity$Value` is the most common ActivityTypeCode (n = `r most_common_activity$Count`)

We've completed our review of the ActivityTypeCode.


Now, let's move on to a different field and see if there are any values
that we want to remove.

In this next example, there are multiple MeasureQualifierCode values to
review.

```{r MeasureQualifierCodeReview, fig.width=8, fig.height=6, fig.fullwidth=TRUE}
TADA_FieldValuesPie(R5ProfileClean5, "MeasureQualifierCode")
```

MeasureQualifierCode definitions are available
[here](https://cdx.epa.gov/wqx/download/DomainValues/ResultMeasureQualifier.CSV){style="font-size: 12pt;"}.

In this example, we show how to use the function **TADA_FlagMeasureQualifierCode** to add MeasureQualifierCode definitions and flag and/or remove rows with specific codes under MeasureQualifierCode that are categorized as "SUSPECT". 

See ?TADA_FlagMeasureQualifierCode for more information. 

```{r FilterMeasureQualifierCodes}
# flag only
Review_R5ProfileClean5 <- TADA_FlagMeasureQualifierCode(R5ProfileClean5,
  clean = FALSE,
  flaggedonly = TRUE,
  define = TRUE
)
# Review number of suspect results

suspect_n <- Review_R5ProfileClean5 %>%
  dplyr::filter(TADA.MeasureQualifierCode.Flag == "SUSPECT") %>%
  nrow()

# Run function with clean = TRUE
R5ProfileClean5 <- TADA_FlagMeasureQualifierCode(R5ProfileClean5,
  clean = TRUE)
```

**Question 11: How many results were identified as "SUSPECT" based on the MeasureQualifierCode?**

**Answer:**
`r suspect_n` results were identified as suspect based on the MeasureQualifierCode.

## Censored data

Censored data are measurements for which the true value is not known,
but we can estimate the value based on lower or upper detection
conditions and limit types. TADA fills missing *TADA.ResultMeasureValue*
and *TADA.ResultMeasure.MeasureUnitCode* values with values and units
from *TADA.DetectionQuantitationLimitMeasure.MeasureValue* and
*TADA.DetectionQuantitationLimitMeasure.MeasureUnitCode*, respectively,
using the TADA_AutoClean function. In other words, detection limit
information is copied and pasted into the result value column when the
original value is NA and detection limit information is available. The
two columns TADA focuses on to define and flag censored data are
*ResultDetectionConditionText* and *DetectionQuantitationLimitTypeName*.

The TADA package currently has functions that summarize censored data
incidence in the dataset and perform simple substitutions of censored
data values, including x times the detection limit and random selection
of a value between 0 and the detection limit. The user may specify the
methods used for non-detects and over-detects separately in the input to
the **TADA_SimpleCensoredMethods** function.

All censored data functions depend first on the **TADA_IDCensoredData**
utility function, which assigns a *TADA.CensoredData.Flag* to all data
records and identifies over-detects from non-detects using the
*ResultDetectionConditionText* and *DetectionQuantitationLimitTypeName*.
This utility function is automatically run within the TADA_AutoClean
function and produces the *TADA.CensoredData.Flag* column. All records
receive one of the following classifications: - Uncensored - Not filled
with detection limit value; a detection. - Non-Detect - Left-censored -
Over-Detect - Right-censored - Other Condition/Limit Populated -
detection condition or limit type are ambiguous or not associated with a
lower/upper detection limit. - Conflict between Condition and Limit -
detection condition and limit type for a single record do not agree,
e.g. one suggests over-detect and the other suggests non-detect. -
Detection condition or detection limit is not documented in TADA
reference tables. - detection condition or limit type is not
characterized in the TADA reference tables, which are based on WQX
domain tables. - Detection condition is missing and required for
censored data ID. - Result needs more information before being
categorized.

The **TADA_SimpleCensoredMethods** function also adds a *TADA.MeasureQualifierCode.Def* column which contains the *MeasureQualiferCode* concatenated with the WQX definition for each qualifier code. This provides additional information to the user which may assist in deciding which records to retain for analysis.

The next step we take in this example is to perform simple conversions
to the censored data in the dataset: we keep over-detects as is (no
conversion made) and convert non-detect values to 0.5 times the
detection limit (half the detection limit). Please review
**?TADA_Stats** and **?TADA_SimpleCensoredMethods** for more
information.

```{r SummarizeCensoredData}
R5ProfileClean5 <- TADA_SimpleCensoredMethods(R5ProfileClean5,
  nd_method = "multiplier",
  nd_multiplier = 0.5,
  od_method = "as-is",
  od_multiplier = "null"
)
```

**Question 12: How many NAs remain in the data set after running TADA_SimpleCensoredMethods?**

```{r Review_NA_MeasureValues}
result_na_n <- sum(is.na(R5ProfileClean5$TADA.ResultMeasureValue))
```

**Answer:**
There are `r result_na_n` TADA.ResultMeasureValue NAs remaining in the data set.

Filter down to only numeric data. Remove data where the
TADA.ResultMeasureValueDataTypes.Flag = "Text" or "NA - Not Available". You can also remove any columns not required for the TADA workflow that contain only NAs. The **TADA_AutoFilter()** function removes non-numeric data and optional columns containing only NAs.

```{r filter_out_NAs}
# Removes rows where the result value is not numeric. Specifically, removes rows with "Text" or "NA - Not Available" in the TADA.ResultMeasureValueDataTypes.Flag column, or NA in the TADA.ResultMeasureValue column. Removes optional columns containing only NAs.
R5ProfileClean6 <- TADA_AutoFilter(R5ProfileClean5)
```

**Question 13: How many NAs remain in the data set for TADA.ResultMeasureValue after running TADA_Autofilter? How many non-numeric values in TADA.ResultMeasureValueDataTypes.Flag remain in the data set? How many rows were removed from the data set?**

```{r check_for_NAs_again}

scm_result_nas_n <- sum(is.na(R5ProfileClean6$TADA.ResultMeasureValue))

non_numeric_n <- sum(!R5ProfileClean6$TADA.ResultMeasureValueDataTypes.Flag %in% c("Numeric", "Result Value/Unit Estimated from Detection Limit","Result Value/Unit Copied from Detection Limit"))

R5ProfileClean5_n <- nrow(R5ProfileClean5)

R5ProfileClean6_n <- nrow(R5ProfileClean6)

autofilter_removed_n <- R5ProfileClean5_n - R5ProfileClean6_n
```

**Answer:**
There are `r scm_result_nas_n`results remaining where TADA.ResultMeasureValue is equal to NA after running TADA_AutoFilter. There are `r non-numeric_n` results remaining where TADA.ResultMeasureValueDataTypes is non-numeric. `r autofilter_removed_n` results where removed from the data set to ensure that only numeric results are retained.


## Convert synonymous characteristic, fraction, speciation, and unit values to a consistent convention based on user-defined/TADA standards

The **TADA_GetSynonymRef** function generates a synonym reference
table that is specific to the input dataframe. Users can review how
their input data relates to standard TADA values for the following
elements:

-   *TADA.CharacteristicName*

-   *TADA.ResultSampleFractionText*

-   *TADA.MethodSpeciationName*

-   *TADA.ResultMeasure.MeasureUnitCode*

Users can also edit the reference file to meet their needs if desired.
The download argument can be used to save the harmonization file to your
current working directory when download = TRUE, the default is download
= FALSE.

The **TADA_HarmonizeSynonyms** function then compares the input dataframe to the
TADA Synonym Reference Table and makes conversions where target
characteristics/fractions/speciations/units are provided. This function also
appends a column called TADA.Harmonized.Flag, indicating which results had
metadata changed/converted in this function. The purpose of this function is to
make similar data consistent and therefore easier to compare and analyze.

Here are some examples of how the TADA_HarmonizeSynonyms function can be used:

1.  *TADA.ResultSampleFractionText* specifies forms of constituents. In
    some cases, a single *TADA.CharacteristicName* will have both
    "Total" and "Dissolved" forms specified, which should not be
    combined. In these cases, each *TADA.CharacteristicName* and
    *TADA.ResultSampleFractionText* combination is given a different
    identifier. This identifier can be used later on to identify
    comparable data groups for calculating statistics and creating
    figures for each combination.

2.  Some variables have different names but represent the same
    constituent (e.g., "Total Kjeldahl nitrogen (Organic N & NH3)" and
    "Kjeldahl nitrogen"). The **TADA_HarmonizeSynonyms** function gives a consistent
    name (and identifier) to synonyms.

```{r TADA_HarmonizeSynonyms}
UniqueHarmonizationRef <- TADA_GetSynonymRef(R5ProfileClean6)

R5ProfileClean7 <- TADA_HarmonizeSynonyms(R5ProfileClean6,
  ref = UniqueHarmonizationRef
)
```

## Total Nitrogen and Total Phosphorus Calculations

This section covers summing nutrient subspecies to estimate total nitrogen and phosphorus. This can be a challenging endeavor because some subspecies/compounds overlap in total nutrient calculations. Thus, **TADA_CalculateTotalNP** uses the [Nutrient Aggregation logic](https://echo.epa.gov/trends/loading-tool/resources/nutrient-aggregation) to add together specific subspecies to obtain a total. TADA adds one more equation to the mix: total particulate nitrogen + total dissolved nitrogen. The function uses as many subspecies as possible to calculate a total for each given site, date, and depth group, but it will estimate total nitrogen with whatever subspecies are present. This function creates NEW total nutrient measurements (total nitrogen unfiltered as N and total phosphorus unfiltered as P) and adds them to the dataframe. 

Users can use the default summation worksheet (see **TADA_GetNutrientSummationRef**) or customize it to suit their needs. The function also requires a daily aggregation value, either minimum, maximum, or mean. The default is 'max', which means that if multiple measurements of the same subspecies-fraction-speciation-unit occur on the same day at the same site and depth, the function will pick the maximum value to use in summation calculations.

```{r, TADA_CalculateTotalNP}
R5ProfileClean8 <- TADA_CalculateTotalNP(R5ProfileClean7, daily_agg = "max")
```


## Parameter Level Filtering

In this section, you can select a single parameter, and review the
unique values in specified fields. You may then choose to remove
particular values by filtering.

To start, review the list of parameters in the dataframe using the
**TADA_FieldValuesTable** function.


```{r TADA_FieldValuesTable_chars}
FieldValuesTable_Chars <- TADA_FieldValuesTable(R5ProfileClean8, field = "TADA.CharacteristicName")
```

Next, we can revisit the **TADA_FieldCounts** function at the characteristic
level to review how many unique allowable values are included within
each of the following fields:

-   *ActivityCommentText*

-   *ActivityTypeCode*

-   *TADA.ActivityMediaName*

-   *ActivityMediaSubdivisionName*

-   *MeasureQualifierCode*

-   *MonitoringLocationTypeName*

-   *HydrologicCondition*

-   *HydrologicEvent*

-   *ResultStatusIdentifier*

-   *MethodQualifierTypeName*

-   *ResultCommentText*

-   *ResultLaboratoryCommentText*

-   *TADA.ResultMeasure.MeasureUnitCode*

-   *TADA.ResultSampleFractionText*

-   *ResultTemperatureBasisText*

-   *ResultValueTypeName*

-   *ResultWeightBasisText*

-   *SampleCollectionEquipmentName*

-   *LaboratoryName*

-   *MethodDescriptionText*

-   *ResultParticleSizeBasisText*

-   *SampleCollectionMethod.MethodIdentifier*

-   *SampleCollectionMethod.MethodIdentifierContext*

-   *SampleCollectionMethod.MethodName*

-   *DataQuality.BiasValue*

-   *MethodSpeciationName*

-   *ResultAnalyticalMethod.MethodName*

-   *ResultAnalyticalMethod.MethodIdentifier*

-   *ResultAnalyticalMethod.MethodIdentifierContext*

-   *AssemblageSampledName*

-   *DetectionQuantitationLimitTypeName*

```{r TADA_FieldCounts_char}
R5_FieldCounts_Chars <- TADA_FieldCounts(R5ProfileClean8, display = "most", characteristicName = "TOTAL PHOSPHORUS, MIXED FORMS")
```

Selecting a parameter generates the list above, which is subset by the
selected parameter. The list includes fields you may want to review, and
the number of unique values in each field.

Next, choose a field from the list.

Review the WQX domain files for definitions:
<https://www.epa.gov/waterdata/storage-and-retrieval-and-water-quality-exchange-domain-services-and-downloads>

Now, we'll use **TADA_FieldValuesTable** and **TADA_FieldValuesPie** at the
characteristic-level to review a column of interest.

```{r TADA_FieldValuesTable_Pie_char, fig.width=8, fig.height=6, fig.fullwidth=TRUE}
# In this example we review values from the SampleCollectionMethod.MethodName field
TADA_FieldValuesTable(R5ProfileClean8, field = "SampleCollectionMethod.MethodName", characteristicName = "TOTAL PHOSPHORUS, MIXED FORMS")
```

Generate a scatterplot with two 
```{r TADA_TwoCharacteristicScatterplot, fig.width=8, fig.height=6, fig.fullwidth=TRUE}
# review unique identifiers
unique(R5ProfileClean8$TADA.ComparableDataIdentifier)

# choose two and generate scatterplot
TADA_TwoCharacteristicScatterplot(R5ProfileClean8, id_cols = "TADA.ComparableDataIdentifier", groups = c("TEMPERATURE_NA_NA_DEG C", "PH_NA_NA_STD UNITS"))
```


Now we will summarize results for a single comparable data group using the
TADA.ComparableDataIdentifier (i.e., comparable characteristic, unit,
speciation, and fraction combination) using **TADA_Histogram** and **TADA_Boxplot**. Note that users may generate a list output of multiple plots if their input dataset has more than one unique comparable data group.

```{r ComparableDataIdentifier_stats_and_histogram, fig.width=8, fig.height=6, fig.fullwidth=TRUE}
# review TADA.ComparableDataIdentifier
unique(R5ProfileClean8$TADA.ComparableDataIdentifier)

# filter dataframe to only "TOTAL PHOSPHORUS, MIXED FORMS"
R5ProfileCleanPH <- dplyr::filter(R5ProfileClean8, TADA.ComparableDataIdentifier == "PH_NA_NA_STD UNITS")

# generate stats table
R5ProfileCleanPH_stats <- TADA::TADA_Stats(R5ProfileCleanPH)

R5ProfileCleanPH_stats

# generate a histogram
PH_Histogram <- TADA_Histogram(R5ProfileCleanPH, id_cols = "TADA.ComparableDataIdentifier")

# view histogram
PH_Histogram
```

Generate interactive box plot.

```{r boxplot, fig.width=8, fig.height=6, fig.fullwidth=TRUE}
TP_Boxplot <- TADA::TADA_Boxplot(R5ProfileCleanPH, id_cols = "TADA.ComparableDataIdentifier")

TP_Boxplot
```

Generate interactive scatterplot.

```{r scatterplot, fig.width=8, fig.height=6, fig.fullwidth=TRUE}
R5ProfileCleanPH_dailymax <- TADA_AggregateMeasurements(R5ProfileCleanPH,
  agg_fun = c("max"),
  clean = TRUE
)

PH_Scatterplot <- TADA::TADA_Scatterplot(R5ProfileCleanPH_dailymax, id_cols = "TADA.ComparableDataIdentifier")

PH_Scatterplot
```

## Retain TADA Required Columns
Now we can review the "TADA" prefixed columns we have added to the data set. If we are satisfied with the conversions, filtering, flagging, etc. and the resulting "TADA" columns, we can use the **TADA_RetainRequired** function to remove any columns that are not required or used as filters in the TADA workflow. This reduces the size of the data frame.

```{r retainrequired}
R5ProfileClean9 <- TADA_RetainRequired(R5ProfileClean9)
```

## TADA Shiny Application

Finally, take a look at an alternative workflow, TADA Shiny Module 1:
Data Discovery and Cleaning. This is a Shiny application that runs many
of the TADA functions covered in this document behind a graphical user
interface. The shiny application queries the WQP, contains maps and data
visualizations, flags suspect data results, handles censored data, and
more. You can launch it using the code below.

DRAFT [Module 1](https://owshiny-dev.app.cloud.gov/tada-dev/) is also
currently hosted on the web with minimal server memory/storage
allocated.

```{r, eval = F}
# download TADA Shiny repository
remotes::install_github("USEPA/TADAShiny",
  ref = "develop",
  dependencies = TRUE
)

# launch the app locally.
TADAShiny::run_app()
```

## Download this Article from GitHub

Go to:
<https://github.com/USEPA/TADA/blob/develop/vignettes/TADAR5.Rmd>

[![Click the highlighted icon to download TADAR5.Rmd from GitHub.
Open this file in R Studio to follow along. Alternatively, you can copy
and paste desired lines of code from here into your own
script. Note: You must have a GitHub account to download TADAModule1.Rmd from GitHub ](images/DownloadModule1.jpg)](https://github.com/USEPA/TADA/blob/develop/vignettes/TADAModule1.Rmd)
