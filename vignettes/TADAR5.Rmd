---
title: "TADA Package Training: A Markdown For Region 5 R Users Network"
author: "TADA Team"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\usepackage[utf8]{inputenc}
  %\VignetteIndexEntry{TADA Package Training: A Markdown For Region 5 R Users Network}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: 72
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{css, echo=FALSE}
pre {
  max-height: 300px;
  overflow-y: auto;
}

pre[class] {
  max-height: 100px;
}
```

## Welcome

Thank you for your interest in Tools for Automated Data Analysis (TADA). TADA is an open-source tool set built in the R programming language. This [RMarkdown](https://bookdown.org/yihui/rmarkdown/) document walks users through how to download the TADA R package from GitHub, access and parameterize several important functions with a sample dataset and create basic visualizations. The sample data set contains data from one week from
all EPA Region 5 states.

This example workflow is similar to a funnel: at each decision point, data that fail QC checks are removed from the core dataset and placed in a separate dataframe, while data that pass are carried into the next step. At the end of the QC checks, the user should be confident that their data are properly documented and applicable to the analysis at hand.

**Note: TADA is still under development. New functionality is added weekly, and sometimes we need to make bug fixes in response to tester and user feedback. We appreciate your feedback, patience, and interest in these helpful tools.**

**If you are interested in contributing to TADA development, more information is available at [Contributing] (https://usepa.github.io/TADA/articles/CONTRIBUTING.html). We welcome collaboration with external partners.**

## Install and load packages

First, install and load the remotes package specifying the repo. This
is needed before installing TADA because it is only available on GitHub.

```{r install_remotes, eval = F, results = 'hide', message = FALSE, warning = FALSE}
install.packages("remotes",
  repos = "http://cran.us.r-project.org"
)
library(remotes)
```

Next, install and load TADA using the remotes package. TADA R Package dependencies will also be downloaded automatically from CRAN
with the TADA install. You may be prompted in the console to update dependency packages that have more recent versions available. If you see this prompt, it is recommended to update all of them (enter 1 into the console).

```{r install_TADA, eval = F, results = 'hide', message = FALSE, warning = FALSE}
remotes::install_github("USEPA/TADA",
  ref = "develop",
  dependencies = TRUE
)

```

Finally, use the **library()** function to load the TADA R Package into your R session.

```{r library, results = 'hide', message = FALSE, warning = FALSE}
library(TADA)
```

## Help pages

All TADA R package functions have their own individual help pages, listed on the [Function reference](https://usepa.github.io/TADA/reference/index.html) page on the GitHub site. Users can also access the help page for a given function in R or RStudio using the following format (example below): `?TADA::[name of TADA function]`

```{r}
?TADA::TADA_DataRetrieval
```

## Retrieve WQP data

WQP data is retrieved and processed for compatibility with TADA. This
function, **TADA_DataRetrieval**, builds on USGS's dataRetrieval R
package functions. It joins three WQP profiles: Site,
Sample Results (physical/chemical metadata),
and Project. In addition, it changes all data in the
Characteristic, Speciation, Fraction, and Unit fields to uppercase,
removes exact duplicates, and addresses result values that include
special characters.

The characteristics pulled
from [Water Quality Portal (WQP)](https://www.waterqualitydata.us/) are not restricted and can include: 

-   startDate

-   endDate

-   characteristicName

-   sampleMedia

-   siteType

-   statecode (review list of possible state and territory
    [abbreviations](https://www2.census.gov/geo/docs/reference/state.txt))

-   countycode

-   siteid

-   organization

-   project

-   huc

-   characteristicType

The default TADA_DataRetrieval function
automatically runs the **TADA_AutoClean** function. In this example, we will set **TADA_AutoClean = FALSE** and run it as a separate step in the work flow. 

Tips:

1.  All the query filters for the WQP work as an AND but within the
    fields there are ORs. For example:

    -   Characteristics: If you choose pH & DO - it's an OR. This means
        you will retrieve both pH OR DO data if available.

    -   States: Similarly, if you choose MI and IL, it's an OR. This
        means you will retrieve both MI OR IL data if available.

    -   Combinations of fields are ANDs, such as State/MI AND
        Characteristic/DO". This means you will receive all DO data
        available in MI.

    -   "Characteristic" and "Characteristic Type" also work as an AND.
        This means that the Characteristic must fall within the
        CharacteristicGroup if both filters are being used, if not you
        will get an error.

2.  The "siteid" is a general term WQP uses to describe both Site IDs
    from USGS databases and Monitoring Location Identifiers (from WQX).
    Each monitoring location in the Water Quality
    Portal (WQP) has a unique Monitoring Location Identifier, regardless
    of the database from which it derives. 
    
Additional resources:

-   Review function documentation by entering the following code into
    the console: ?TADA_DataRetrieval

-   [Water Quality Portal Web Services
    Guide](https://www.waterqualitydata.us/webservices_documentation/)

-   TADA Module 1 (ADD LINK)


This example includes monitoring data for six??? parameters collected for one month (May 2019) by Region 5 state organizations(???) (Illinois, Indiana, Michigan, Minnesota, Ohio, and Wisconsin). We will move forward with this example in the remainder of the vignette.

For demonstration purposes, the R5 example data set had already been downloaded and can be accessed by uncommenting and running the TADA_DataRetrieval function below. If you're following along you can run the code chunk below to access the pre-downloaded data set.

Downloads using TADA_DataRetrieval will have the same columns each time,
but be aware that data are uploaded to the Water Quality Portal by
individual organizations, which may or may not follow the same
conventions. Data and metadata quality are not guaranteed! Make sure to
carefully explore any data and make conservative quality assurance
decisions where information is limited.

Keep in mind that any columns with a "TADA" prefix were added during data retrieval.

Note: TADA_DataRetrieval  automatically
converts the date times to UTC and data
to dates, datetimes, and numerics based on a standard algorithm. 

**Note:** USGS and EPA are working together to create WQP 3.0 data profiles. Once released, one data profile will contain the columns critical to TADA, removing the need to combine profiles in this first step. TADA package users likely will not notice a difference in their usage of the `TADA_DataRetrieval` function, but it will simplify the steps needed to upload a custom or WQP GUI-downloaded dataset into the R package.


```{r TADA_DataRetrieval}
# Uncomment query below to download data set from WQP
# TADAProfile <- TADA_DataRetrieval(statecode = c("IL", "IN", "MI", "MN", "OH", "WI"), startDate = "2019-05-01", endDate = "2019-05-07", applyautoclean = FALSE)

# For demo purposes, import pre-downloaded R5 data set

R5Profile <- TADA::Data_R5_TADAPackageDemo
```

If you need to download a large amount of data from across a large area,
and the TADA_DataRetrieval function is not working due to WQP timeout
issues, then the **TADA_BigDataRetrieval** function may work better. See ?TADA_BigDataRetrieval for more details or the TADA Module 1 for more details. 

## Filter for Analysis 

Some TADA users are interested in using WQP data for surface water only or including some non-water data. The **TADA_AnalysisDataFilter** function can assist in identifying results of interest. Multiple columns are used to identify groundwater results as organizations may populate different combinations of fields in order to identify groundwater results.

This function identifies surface water, groundwater, and sediment results. Users can  specify whether all results should be returned with a new column, *TADA.UseForAnalysis.Flag*, providing information about the result's media type of and identifying if the result should be included in further analysis or if only results that should be included are returned. 

The defaults are to include surface water, exclude groundwater and sediment, and to return only the results that should be used for analysis (clean = TRUE). This is shown in the active example below. If you would like to see all results with the *TADA.UseForAnalysis.Flag* column, you can uncomment the example where clean = FALSE.

**Note:** When WQX 3.0 data profiles are released, this function will be modified to include fish tissue an option.

```{r AnalysisDataFilter}

# Filter to retain only results for use in analysis including only surface water results
R5Profile <- TADA_AnalysisDataFilter(R5Profile, 
                                     clean = TRUE,
                                     surfacewater = TRUE,
                                     groundwater = FALSE,
                                     sediment = FALSE)

# Add TADA.UseForAnalysis.Flag column to identify which results should be used for analysis including only surface water results
# R5Profile <- TADA_AnalysisDataFilter(R5Profile, 
                                     # clean = TRUE,
                                     # surfacewater = TRUE,
                                     # groundwater = FALSE,
                                     # sediment = FALSE))

```


## AutoClean

Now **TADA_AutoClean** can be run on a smaller dataset after unnecessary results have been removed. It performs the following functions on the data retrieved from the WQP:

-   **TADA_ConvertSpecialChars** - converts result value columns to numeric and flags non-numeric values that could not be converted.

-   **TADA_ConvertResultUnits** - unifies result units for easier quality control and review

-   **TADA_ConvertDepthUnits** - converts depth units to a consistent unit (meters).

-   **TADA_IDCensoredData** - categorizes detection limit data and identifies mismatches in result detection condition and result detection limit type. 

-   Other helpful actions - converts important text columns to all upper-case letters, removes exact duplicates, and uses WQX format rules to harmonize specific NWIS metadata conventions (e.g. move characteristic speciation from the TADA.ResultMeasure.MeasureUnitCode column to the TADA.MethodSpeciationName column)

As a general rule, TADA functions do not change any contents in the WQP-served
columns. Instead, they add new columns with the prefix "TADA." The following
columns are numeric versions of their WQP origins:

    -   *TADA.ResultMeasureValue*

    -   *TADA.DetectionQuantitationLimitMeasure.MeasureValue*

    -   *TADA.LatitudeMeasure*

    -   *TADA.LongitudeMeasure*

These functions also add the columns
*TADA.ResultMeasureValueDataTypes.Flag* and
*TADA.DetectionQuantitationLimitMeasure.MeasureValueDataTypes.Flag*, which
provide information about the result values that is needed to address
censored data later on (i.e., nondetections). Specifically, these new
columns flag if special characters are included in result values, and
specifies what the special characters are.

``` {r TADA_AutoClean}

# run TADA_AutoClean on filtered dataset to convert special characters, result units, and depth units and identify censored data.

R5Profile <- TADA_AutoClean(R5Profile)

```

Review all column names in the TADA Profile to familiarize yourself with the dataset after TADA_AutoClean has added additional TADA prefixed columns. **TADA_SummarizeColumn** summarizes the data set based on the user specified column and returns a dataframe displaying the number of sites and number of records for each unique value in the specified column. The example below uses TADA.CharacteristicName. 

```{r TADA_SummarizeColumn}

# View column names for TADAProfile
colnames(R5Profile)

# Review the number of sites and number of records for each CharacteristicName in TADAProfile
R5Profile_CharSummary <- TADA_SummarizeColumn(R5Profile, "TADA.CharacteristicName")

# View TADAProfile_CharSummary
R5Profile_CharSummary
```


## Invalid coordinates

Review station locations and summary information using the
**TADA_OverviewMap** function. **TADA_OverviewMap** counts the number of
unique results, characteristics, and organizations at each monitoring
location in the dataset and creates a tidy map for reviewing summary
stats spatially. Larger point sizes indicate more results collected at a
given site, while darker blue colors indicate more unique
characteristics collected at the site. Users may click on a site to view
a pop-up with this summary information. This map may inform a
user's decision to remove/correct sites that are outside the US.

```{r Map, fig.width=8, fig.height=6, fig.fullwidth=TRUE}
TADA_OverviewMap(R5Profile)
```

The TADA **TADA_FlagCoordinates** function identifies and flags
potentially invalid coordinate data. While its functionality is
showcased here, it is always important to review any invalid outputs
before cleaning to reduce the risk of leaving out usable data/sites.

Allowable values for clean_outsideUSA are "no", "remove", or "change
sign". The default is "no" which flags latitude and longitude
coordinates outside the USA. Assigning clean_ousideUSA = "remove" will
remove rows of data with coordinates outside the USA. And assigning
clean_outsideUSA = "change sign" will flip the sign of latitude or
longitude coordinates flagged as outside the USA. The "change sign"
option should only be used when it is known that coordinates were
entered with the wrong sign in WQX; additionally, the data owner should
fix these incorrect coordinates in the raw data through the WQX - for
assistance email the WQX help desk: WQX\@epa.gov

Allowable values for clean_imprecise are TRUE or FALSE. The default is
FALSE which flags rows of data with invalid or imprecise coordinates
without removing them. Assigning clean_imprecise = TRUE will remove rows
of data with invalid or imprecise coordinates.

Allowable values for flaggedonly are TRUE or FALSE. The default is FALSE
which keeps all rows of data regardless of flag status. Assigning
flaggedonly = TRUE filters the dataframe to show only rows of data which
are flagged.

When clean_outsideUSA = "no" and/or clean_imprecise = FALSE, a column
will be appended titled "TADA.InvalidCoordinates.Flag" with the
following flags (if relevant to dataframe):

-   If the latitude is less than zero, the row will be flagged with
    "LAT_OutsideUSA". (Exception for American Samoa)

-   If the longitude is greater than zero AND less than 145, the row
    will be flagged as "LONG_OutsideUSA". (Exceptions for Guam and the
    Northern Mariana Islands)

-   If the latitude or longitude contains the string, "999", the row
    will be flagged as invalid.

-   Finally, precision can be measured by the number of decimal places
    in the latitude and longitude provided. If either does not have any
    numbers to the right of the decimal point, the row will be flagged
    as "Imprecise".

```{r TADA_FlagCoordinates}
# flag and remove --> CHANGE THIS
R5ProfileClean1 <- TADA_FlagCoordinates(R5Profile, clean_outsideUSA = "no", clean_imprecise = FALSE, flaggedonly = FALSE)

# review unique flags in TADAProfileClean1
unique(TADAProfileClean1$TADA.InvalidCoordinates.Flag)

# review unique MonitoringLocationIdentifiers in your flag dataframe
unique(TADAProfileClean1$MonitoringLocationIdentifier)

Unique_InvalidCoordinateFlags <- TADAProfileClean1 %>%
  dplyr::select(
    "MonitoringLocationIdentifier",
    "MonitoringLocationName",
    "TADA.InvalidCoordinates.Flag",
    "OrganizationIdentifier",
    "TADA.LongitudeMeasure",
    "TADA.LatitudeMeasure",
    "MonitoringLocationTypeName",
    "CountryCode",
    "StateCode",
    "CountyCode",
    "HUCEightDigitCode",
    "MonitoringLocationDescriptionText",
    "ProjectName",
    "ProjectIdentifier",
    "OrganizationFormalName"
  ) %>%
  dplyr::distinct()

Unique_InvalidCoordinateFlags

# if needed, un-comment below to change the sign for all data for sites flagged as outside the USA. You can also change FALSE to TRUE if you want to remove sites outside of the US or sites with imprecise lat/longs

# TADAProfileClean1 <- TADA_FlagCoordinates(TADAProfile, clean_outsideUSA = "change sign", clean_imprecise = FALSE, flaggedonly = FALSE)


```

## Depth unit conversions

The **TADA_ConvertDepthUnits** function converts depth units to a
consistent unit. Depth values and units are most commonly associated
with lake data, and are populated in the *ActivityDepthHeightMeasure*,
*ActivityTopDepthHeightMeasure*, *ActivityBottomDepthHeightMeasure*, and
*ResultDepthHeightMeasure* Result Value/Unit columns.

Allowable values for 'unit' are either 'm' (meter), 'ft' (feet), or 'in'
(inch). 'unit' accepts only one allowable value as an input. Default is
unit = "m".

Note that upon download using **TADA_AutoClean**, all depth columns
are converted to meters by default. However, the user may choose to run
the **TADA_ConvertDepthUnits** function on their dataset to convert to
another unit. See function documentation for additional input options by
entering the following code in the console: ?TADA_ConvertDepthUnits

```{r TADA_ConvertDepthUnits}
# converts all depth profile data to feet
TADAProfileClean1 <- TADA_ConvertDepthUnits(TADAProfileClean1,
  unit = "ft",
  transform = TRUE
)
```

## Statistically aggregated data

The **TADA_FindContinuousData** function checks for and removes
statistically aggregated high frequency (i.e., continuous) data, if
present.

The Water Quality Portal (WQP) is not currently designed to store
high-frequency sensor data (more than 1 value per day). However,
sometimes data providers choose to aggregate their continuous data to avg, max, or min value over daily or other intervals, and then submit that aggregated data to
the WQP through WQX. This
type of high frequency data may (or may not) be usable for your analyses. Therefore, this
function uses metadata submitted by data providers to flag rows with
aggregated continuous data. This is done by flagging results where the
ResultDetectionConditionText = "Reported in Raw Data (attached)".

-   When clean = FALSE, a column titled "TADA.AggregatedContinuousData"
    is added to the dataframe to indicate if the row includes aggregated
    continuous data, "Y", or not, "N".

-   When clean = TRUE, rows with aggregated continuous data are removed
    from the dataframe and no column will be appended. The default is
    clean = TRUE.

An additional input called flaggedonly will allow the user to filter data
to show only rows of aggregated continuous data. Allowable values for
flaggedonly are TRUE or FALSE. The default is FALSE which keeps all rows
of data regardless of flag status. Assigning flaggedonly = TRUE filters
the dataframe to show only rows of data which are flagged "Y".

See function documentation for additional function options by entering
the following code in the console: ?TADA_FindContinuousData

```{r AggregatedContinuousData}
TADAProfileClean1 <- TADA_FindContinuousData(TADAProfileClean1,
  clean = FALSE
)

# uncomment below to create a dataframe of only the aggregated continuous data

# TADAProfile_aggcont <- TADA_FindContinuousData(TADAProfileClean3, clean = FALSE, flaggedonly = TRUE)
```

## WQX Quality Assurance and Quality Control (QAQC) Service Result Flags

Run the following result functions to address invalid method, fraction,
speciation, and unit metadata by characteristic. The default is clean =
TRUE, which will remove invalid results. You can change this to clean =
FALSE to flag results, but not remove them.

See documentation for more details:

-   ?**TADA_FlagMethod**

    -   When clean = FALSE, this function adds the following column to
        your dataframe: TADA.AnalyticalMethod.Flag. This column flags
        invalid TADA.CharacteristicName,
        ResultAnalyticalMethod/MethodIdentifier, and
        ResultAnalyticalMethod/MethodIdentifierContext combinations in
        your dataframe either "NonStandardized", "Invalid", or "Valid".

    -   When clean = TRUE, "Invalid" rows are removed from the dataframe
        and no column will be appended.

    -   When flaggedonly = TRUE, the dataframe is filtered to only the
        rows flagged as "Invalid"; default is flaggedonly = FALSE.

-   ?**TADA_FlagSpeciation**

    -   When clean = "none", this function adds the following column to
        your dataframe: TADA.MethodSpeciation.Flag. This column flags
        each TADA.CharacteristicName and MethodSpeciationName
        combination in your dataframe as either "NonStandardized",

        "Invalid", or "Valid".

    -   When clean = "invalid_only", only "Invalid" rows are removed
        from the dataframe. Default is clean = "invalid_only".

    -   When clean = "nonstandardized_only", only "NonStandardized" rows
        are removed from the dataframe.

    -   When clean = "both", "Invalid" and "NonStandardized" rows are
        removed from the dataframe.

    -   When clean = "none", no rows are removed from the dataframe.

    -   When flaggedonly = TRUE, the dataframe is filtered to only the
        rows flagged as "Invalid" or "NonStandardized"; default is
        flaggedonly = FALSE.

-   ?**TADA_FlagResultUnit**

    -   When clean = FALSE, the following column will be added to your
        dataframe: TADA.ResultUnit.Flag. This column flags each
        TADA.CharacteristicName, TADA.ActivityMediaName, and
        TADA.ResultMeasure.MeasureUnitCode combination in your dataframe
        as either "NonStandardized", "Invalid", or "Valid".

    -   When clean = TRUE, "Invalid" rows are removed from the dataframe
        and no column will be appended.

    -   When flaggedonly = TRUE, the dataframe is filtered to only the
        rows flagged as "Invalid"; default is flaggedonly = FALSE.

-   ?**TADA_FlagFraction**

    -   When clean = FALSE, this function adds the following column to
        your dataframe: TADA.SampleFraction.Flag. This column flags each
        TADA.CharacteristicName and TADA.ResultSampleFractionText
        combination in your dataframe as either "NonStandardized",
        "Invalid", or "Valid".
    -   When clean = TRUE, "Invalid" rows are removed from the dataframe
        and no column will be appended.
    -   When flaggedonly = TRUE, the dataframe is filtered to only the
        rows flagged as "Invalid"; default is flaggedonly = FALSE.

```{r Invalid_Method_Fraction_Speciation_ResultUnit}
TADAProfileClean2 <- TADA_FlagMethod(TADAProfileClean1, clean = TRUE)

TADAProfileClean2 <- TADA_FlagFraction(TADAProfileClean2, clean = TRUE)

TADAProfileClean2 <- TADA_FlagSpeciation(TADAProfileClean2, clean = "invalid_only")

TADAProfileClean2 <- TADA_FlagResultUnit(TADAProfileClean2, clean = "invalid_only")
```

## WQX national upper and lower thresholds

Run the following code to flag or remove results that are above or below
the national upper and lower bound for each characteristic and unit
combination. See documentation for more details:

-   ?**TADA_FlagAboveThreshold**

    -   When clean = FALSE, the following column is added to your
        dataframe: TADA.ResultValueAboveUpperThreshold.Flag. This column
        flags rows with data that are above the upper WQX threshold.
        The default is clean = FALSE.

    -   When clean = TRUE, data that is above the upper WQX threshold is
        removed from the dataframe. 

    -   When flaggedonly = TRUE, the dataframe is filtered to only the
        rows flagged as above the upper WQX threshold; default is
        flaggedonly = FALSE.

-   ?**TADA_FlagBelowThreshold**

    -   When clean = FALSE, the following column is added to your
        dataframe: TADA.ResultValueBelowLowerThreshold.Flag. This column
        flags rows with data that are below the lower WQX threshold.
        The default is clean = FALSE.

    -   When clean = TRUE, data that is below the lower WQX threshold is
        removed from the dataframe. 

    -   When flaggedonly = TRUE, the dataframe is filtered to only the
        rows flagged as below the lower WQX threshold; default is
        flaggedonly = FALSE.

```{r WQX_Thresholds}
TADAProfileClean3 <- TADA_FlagAboveThreshold(TADAProfileClean2, clean = TRUE)

TADAProfileClean3 <- TADA_FlagBelowThreshold(TADAProfileClean3, clean = TRUE)
```

## Potential duplicates

Sometimes multiple organizations submit the exact same data to Water
Quality Portal (WQP), which can affect water quality analyses and
assessments. Similarly, organizations occasionally submit the same data multiple times to the Portal. The following functions check for and identify data that may be duplicates based on date, time, characteristic, result value, and a distance buffer. Each pair or group of potential duplicate rows is flagged with a
unique ID. For more information, review the documentation by entering
the following into the console:

-   ?**TADA_FindPotentialDuplicatesMultipleOrgs**
-   ?**TADA_FindPotentialDuplicatesSingleOrg**


```{r FindPotentialDuplicates}
TADAProfileClean3 <- TADA_FindPotentialDuplicatesMultipleOrgs(TADAProfileClean3,
  dist_buffer = 100,
  org_hierarchy = "none"
)

TADAProfileClean3 <- TADA_FindPotentialDuplicatesSingleOrg(TADAProfileClean3)
```

## Review QAPP information

The **TADA_FindQAPPApproval** function checks data for an approved QAPP.

This function checks to see if there is any information in the column
"QAPPApprovedIndicator". Some organizations submit data for this field
to indicate if the data produced has an approved Quality Assurance
Project Plan (QAPP) or not. In this field, Y indicates yes, N indicates
no.

This function has three default inputs: clean = TRUE, cleanNA = FALSE,
and flaggedonly = FALSE. These defaults remove rows of data where the
QAPPApprovedIndicator equals "N".

Users could alternatively remove both N's and NA's using the inputs
clean = TRUE, cleanNA = TRUE, and flaggedonly = FALSE.

Additionally, users could filter to show only N's and NA's by using the
inputs clean = FALSE, cleanNA = FALSE, and flaggedonly = TRUE.

If clean = FALSE, cleanNA = FALSE, and flaggedonly = FALSE, the function
will not do anything.

```{r TADA_FindQAPPApproval}
TADAProfileClean3 <- TADA_FindQAPPApproval(TADAProfileClean3, clean = FALSE, cleanNA = FALSE)
```

The **TADA_FindQAPPDoc** function checks to see if a QAPP Doc is
Available

This function checks data submitted under the "ProjectFileUrl" column to
determine if a QAPP document is available to review. When clean = FALSE,
a column will be appended to flag results that do have an associated
QAPP document URL provided. When clean = TRUE, rows that do not have an
associated QAPP document are removed from the dataframe and no column
will be appended. When flaggedonly = TRUE, the dataframe is filtered to
show only rows that do not have an associated QAPP document. The
defaults are clean = FALSE and flaggedonly = FALSE. This function should
only be used to remove data if an accompanying QAPP document is required
to use data in assessments.

```{r TADA_FindQAPPDoc}
TADAProfileClean3 <- TADA_FindQAPPDoc(TADAProfileClean3,
  clean = FALSE
)
```

## Full Dataframe Filtering

In this section a TADA user will want to review the unique values in
specific fields and may choose to remove data with particular values.

To start, review the list of common fields used for filtering, and the
number of unique values in each field using the **TADA_FieldCounts**
function.

This function returns counts for you entire data frame for each of the
following fields (if populated, columns that are populated only with
NA's are not included in the output):

-   *ActivityTypeCode*

-   *TADA.ActivityMediaName*

-   *ActivityMediaSubdivisionName*

-   *ActivityCommentText*

-   *MonitoringLocationTypeName*

-   *StateCode*

-   *OrganizationFormalName*

-   *TADA.CharacteristicName*

-   *HydrologicCondition*

-   *HydrologicEvent*

-   *BiologicalIntentName*

-   *MeasureQualifierCode*

-   *ActivityGroup*

-   *AssemblageSampledName*

-   *ProjectName*

-   *CharacteristicNameUserSupplied*

-   *DetectionQuantitationLimitTypeName*

-   *SampleTissueAnatomyName*

-   *LaboratoryName*

```{r TADA_FieldCounts_all}
# multiple options

# print table to console
TADA_FieldCounts(TADAProfileClean3)

# create object of table
fieldCounts_Table <- TADA_FieldCounts(TADAProfileClean3)
```


The *ActivityTypeCode* field has multiple unique values. Before we remove the 
QC samples/measurements from this dataset to prepare for analyses, lets review 
flagged Quality Control (QC) values using the
**TADA_FindQCActivities** function, which adds a new TADA *TADA.ActivityType.Flag*
column.

For example, the new *QC_replicate* flag in *TADA.ActivityType.Flag* column 
indicates that the flagged rows include any of the following replicate values:
-   *Quality Control Field Replicate Habitat Assessment*
-   *Quality Control Field Replicate Msr/Obs*
-   *Quality Control Field Replicate Portable Data Logger*
-   *Quality Control Field Replicate Sample-Composite*
-   *Quality Control Sample-Field Replicate*

See WQX domain file to review all the **ActivityTypeCode** allowable values:
https://cdx.epa.gov/wqx/download/DomainValues/ActivityType.CSV

```{r Run TADA_FindQCActivities to review replicates}
# Review flagged QC samples using the TADA_FindQCActivities function:
# enter ?TADA_FindQCActivities into the console for more information
TADAProfileClean3a <- TADA_FindQCActivities(TADAProfileClean3,
  clean = FALSE,
  flaggedonly = TRUE
)

# Filter to review only data where the TADA.ActivityType.Flag = "QC_replicate"
TADAProfileClean3a <- dplyr::filter(TADAProfileClean3a, TADA.ActivityType.Flag == "QC_replicate")
```

Now, let's run **TADA_PairReplicates** to see if any replicates in this 
dataframe can be paired with their original (parent) samples/measurements.

We found over CHECK IN NEW DATA SET FOR VALUE replicates in this dataframe that have a paired parent sample/measurement (based on a 10-minute time window, which can be adjusted if desired). Enter ?TADA_PairReplicates into the console for more details.

Users of TADA have noted that it would be useful to incorporate replicate field samples into water quality data analysis by (a) flagging routine field sample measurements whose associated replicate field sample measurements are outside of a user-defined window of precision (relative percent difference or absolute difference) and/or (b) averaging or randomly replacing routine field sample measurements with their associated replicate field sample measurements. 

For now, users can perform these subsequent analyses outside of TADA. See TADA Module 1 for more information about replicate field samples and additional analyses you may want to perform outside of TADA.

MODIFY CODE JUST TO REMOVE REPLICATES

```{r Run TADA_PairReplicates}
# Run TADA_PairReplicates to add new TADA.ReplicateSampleID column
TADAProfileClean3b <- TADA_PairReplicates(TADAProfileClean3)

# Review unique values in TADA.ReplicateSampleID
unique(TADAProfileClean3b$TADA.ReplicateSampleID)

# Filter df to include only unique values that are paired replicate samples (parent-result and child-replicate).

# Exclude NA's
TADAProfileClean3b <- TADAProfileClean3b[!is.na(TADAProfileClean3b$TADA.ReplicateSampleID), ]
# Exclude orphans
TADAProfileClean3b <- dplyr::filter(TADAProfileClean3b, TADA.ReplicateSampleID != "Orphan")

# Review unique values in TADA.ReplicateSampleID
unique(TADAProfileClean3b$TADA.ReplicateSampleID)
```

Now, let's remove QC samples/measurements from the dataframe.

```{r TADA_FindQCActivities, fig.width=6, fig.height=6, fig.fullwidth=TRUE}
# Remove flagged QC samples using the TADA_FindQCActivities function:
TADAProfileClean4 <- TADA_FindQCActivities(TADAProfileClean3,
  clean = TRUE
)

# regenerate table and pie chart
TADA_FieldValuesTable(TADAProfileClean4, "ActivityTypeCode")
TADA_FieldValuesPie(TADAProfileClean4, "ActivityTypeCode")
```

We've completed our review of the ActivityTypeCode.

Now, let's move on to a different field and see if there are any values
that we want to remove.

In this next example, there are multiple MeasureQualifierCode values to
review.

```{r MeasureQualifierCodeReview, fig.width=8, fig.height=6, fig.fullwidth=TRUE}
TADA_FieldValuesPie(TADAProfileClean4, "MeasureQualifierCode")
```

MeasureQualifierCode definitions are available
[here](https://cdx.epa.gov/wqx/download/DomainValues/ResultMeasureQualifier.CSV){style="font-size: 12pt;"}.

In this example, we show how to use the function **TADA_FlagMeasureQualifierCode** to add MeasureQualifierCode definitions and flag and/or remove rows with specific codes under MeasureQualifierCode that are categorized as "SUSPECT". 

See ?TADA_FlagMeasureQualifierCode for more information. 

```{r FilterMeasureQualifierCodes}
# flag only
Review_TADAProfileClean4 <- TADA_FlagMeasureQualifierCode(TADAProfileClean4,
  clean = FALSE,
  flaggedonly = TRUE,
  define = TRUE
)
# Review_TADAProfileClean4 is empty because we did not find any Suspect samples

TADAProfileClean4 <- TADA_FlagMeasureQualifierCode(TADAProfileClean4,
  clean = TRUE
)

# regenerate table and pie chart
TADA_FieldValuesPie(TADAProfileClean4, field = "MeasureQualifierCode")
```

## Censored data

Censored data are measurements for which the true value is not known,
but we can estimate the value based on lower or upper detection
conditions and limit types. TADA fills missing *TADA.ResultMeasureValue*
and *TADA.ResultMeasure.MeasureUnitCode* values with values and units
from *TADA.DetectionQuantitationLimitMeasure.MeasureValue* and
*TADA.DetectionQuantitationLimitMeasure.MeasureUnitCode*, respectively,
using the TADA_AutoClean function. In other words, detection limit
information is copied and pasted into the result value column when the
original value is NA and detection limit information is available. The
two columns TADA focuses on to define and flag censored data are
*ResultDetectionConditionText* and *DetectionQuantitationLimitTypeName*.

The TADA package currently has functions that summarize censored data
incidence in the dataset and perform simple substitutions of censored
data values, including x times the detection limit and random selection
of a value between 0 and the detection limit. The user may specify the
methods used for non-detects and over-detects separately in the input to
the **TADA_SimpleCensoredMethods** function.

All censored data functions depend first on the **TADA_IDCensoredData**
utility function, which assigns a *TADA.CensoredData.Flag* to all data
records and identifies over-detects from non-detects using the
*ResultDetectionConditionText* and *DetectionQuantitationLimitTypeName*.
This utility function is automatically run within the TADA_DataRetrieval
function and produces the *TADA.CensoredData.Flag* column. All records
receive one of the following classifications: - Uncensored - Not filled
with detection limit value; a detection. - Non-Detect - Left-censored -
Over-Detect - Right-censored - Other Condition/Limit Populated -
detection condition or limit type are ambiguous or not associated with a
lower/upper detection limit. - Conflict between Condition and Limit -
detection condition and limit type for a single record do not agree,
e.g. one suggests over-detect and the other suggests non-detect. -
Detection condition or detection limit is not documented in TADA
reference tables. - detection condition or limit type is not
characterized in the TADA reference tables, which are based on WQX
domain tables. - Detection condition is missing and required for
censored data ID. - Result needs more information before being
categorized.

The **TADA_SimpleCensoredMethods** function also adds a *TADA.MeasureQualifierCode.Def* column which contains the *MeasureQualiferCode* concatenated with the WQX definition for each qualifier code. This provides additional information to the user which may assist in deciding which records to retain for analysis.

The next step we take in this example is to perform simple conversions
to the censored data in the dataset: we keep over-detects as is (no
conversion made) and convert non-detect values to 0.5 times the
detection limit (half the detection limit). Please review
**?TADA_Stats** and **?TADA_SimpleCensoredMethods** for more
information.

```{r SummarizeCensoredData}
TADAProfileClean4 <- TADA_SimpleCensoredMethods(TADAProfileClean4,
  nd_method = "multiplier",
  nd_multiplier = 0.5,
  od_method = "as-is",
  od_multiplier = "null"
)
```

Next, review unique values within the *TADA.CensoredData.Flag*,
*DetectionQuantitationLimitTypeName*, and *ResultDetectionConditionText*
columns.

```{r uniquevalues}
# review unique values
unique(TADAProfileClean4$TADA.CensoredData.Flag)
unique(TADAProfileClean4$DetectionQuantitationLimitTypeName)
unique(TADAProfileClean4$ResultDetectionConditionText)
```

Also, review the *TADA.ResultMeasureValueDataTypes.Flag* to see if any
NA's or ND's (non-detects) remain.

```{r ResultMeasureValueDataTypes.Flag_uniquevalues}
unique(TADAProfileClean4$TADA.ResultMeasureValueDataTypes.Flag)
```

Count how many NA's remain in the TADA.ResultMeasureValue.

```{r Review_NA_MeasureValues}
sum(is.na(TADAProfileClean4$TADA.ResultMeasureValue))
```

Filter down to only numeric data. Remove data where the
TADA.ResultMeasureValueDataTypes.Flag = "Text" or "NA - Not Available". You can also remove any columns not required for the TADA workflow that contain only NAs. The **TADA_AutoFilter()** function removes non-numeric data and optional columns containing only NAs.

```{r filter_out_NAs}
# Removes rows where the result value is not numeric. Specifically, removes rows with "Text" or "NA - Not Available" in the TADA.ResultMeasureValueDataTypes.Flag column, or NA in the TADA.ResultMeasureValue column. Removes optional columns containing only NAs.
TADAProfileClean5 <- TADA_AutoFilter(TADAProfileClean4)
```

Double check to make sure no NA's or ND's remain.

```{r check_for_NAs_again}
unique(TADAProfileClean5$TADA.ResultMeasureValueDataTypes.Flag)

sum(is.na(TADAProfileClean5$TADA.ResultMeasureValue))
```

## Convert synonymous characteristic, fraction, speciation, and unit values to a consistent convention based on user-defined/TADA standards

The **TADA_GetSynonymRef** function generates a synonym reference
table that is specific to the input dataframe. Users can review how
their input data relates to standard TADA values for the following
elements:

-   *TADA.CharacteristicName*

-   *TADA.ResultSampleFractionText*

-   *TADA.MethodSpeciationName*

-   *TADA.ResultMeasure.MeasureUnitCode*

Users can also edit the reference file to meet their needs if desired.
The download argument can be used to save the harmonization file to your
current working directory when download = TRUE, the default is download
= FALSE.

The **TADA_HarmonizeSynonyms** function then compares the input dataframe to the
TADA Synonym Reference Table and makes conversions where target
characteristics/fractions/speciations/units are provided. This function also
appends a column called TADA.Harmonized.Flag, indicating which results had
metadata changed/converted in this function. The purpose of this function is to
make similar data consistent and therefore easier to compare and analyze.

Here are some examples of how the TADA_HarmonizeSynonyms function can be used:

1.  *TADA.ResultSampleFractionText* specifies forms of constituents. In
    some cases, a single *TADA.CharacteristicName* will have both
    "Total" and "Dissolved" forms specified, which should not be
    combined. In these cases, each *TADA.CharacteristicName* and
    *TADA.ResultSampleFractionText* combination is given a different
    identifier. This identifier can be used later on to identify
    comparable data groups for calculating statistics and creating
    figures for each combination.

2.  Some variables have different names but represent the same
    constituent (e.g., "Total Kjeldahl nitrogen (Organic N & NH3)" and
    "Kjeldahl nitrogen"). The **TADA_HarmonizeSynonyms** function gives a consistent
    name (and identifier) to synonyms.

```{r TADA_HarmonizeSynonyms}
UniqueHarmonizationRef <- TADA_GetSynonymRef(TADAProfileClean5)

TADAProfileClean5 <- TADA_HarmonizeSynonyms(TADAProfileClean5,
  ref = UniqueHarmonizationRef
)
```

## Total Nitrogen and Total Phosphorus Calculations

This section covers summing nutrient subspecies to estimate total nitrogen and phosphorus. This can be a challenging endeavor because some subspecies/compounds overlap in total nutrient calculations. Thus, **TADA_CalculateTotalNP** uses the [Nutrient Aggregation logic](https://echo.epa.gov/trends/loading-tool/resources/nutrient-aggregation) to add together specific subspecies to obtain a total. TADA adds one more equation to the mix: total particulate nitrogen + total dissolved nitrogen. The function uses as many subspecies as possible to calculate a total for each given site, date, and depth group, but it will estimate total nitrogen with whatever subspecies are present. This function creates NEW total nutrient measurements (total nitrogen unfiltered as N and total phosphorus unfiltered as P) and adds them to the dataframe. 

Users can use the default summation worksheet (see **TADA_GetNutrientSummationRef**) or customize it to suit their needs. The function also requires a daily aggregation value, either minimum, maximum, or mean. The default is 'max', which means that if multiple measurements of the same subspecies-fraction-speciation-unit occur on the same day at the same site and depth, the function will pick the maximum value to use in summation calculations.

```{r, TADA_CalculateTotalNP}
TADAProfileClean6 <- TADA_CalculateTotalNP(TADAProfileClean5, daily_agg = "max")
```


## Parameter Level Filtering

In this section, you can select a single parameter, and review the
unique values in specified fields. You may then choose to remove
particular values by filtering.

To start, review the list of parameters in the dataframe using the
**TADA_FieldValuesTable** function.

Enter ?TADA_FieldValuesTable into the console for more information.

```{r TADA_FieldValuesTable_chars}
TADA_FieldValuesTable(TADAProfileClean6, field = "TADA.CharacteristicName")
```

Next, we can revisit the **TADA_FieldCounts** function at the characteristic
level to review how many unique allowable values are included within
each of the following fields:

-   *ActivityCommentText*

-   *ActivityTypeCode*

-   *TADA.ActivityMediaName*

-   *ActivityMediaSubdivisionName*

-   *MeasureQualifierCode*

-   *MonitoringLocationTypeName*

-   *HydrologicCondition*

-   *HydrologicEvent*

-   *ResultStatusIdentifier*

-   *MethodQualifierTypeName*

-   *ResultCommentText*

-   *ResultLaboratoryCommentText*

-   *TADA.ResultMeasure.MeasureUnitCode*

-   *TADA.ResultSampleFractionText*

-   *ResultTemperatureBasisText*

-   *ResultValueTypeName*

-   *ResultWeightBasisText*

-   *SampleCollectionEquipmentName*

-   *LaboratoryName*

-   *MethodDescriptionText*

-   *ResultParticleSizeBasisText*

-   *SampleCollectionMethod.MethodIdentifier*

-   *SampleCollectionMethod.MethodIdentifierContext*

-   *SampleCollectionMethod.MethodName*

-   *DataQuality.BiasValue*

-   *MethodSpeciationName*

-   *ResultAnalyticalMethod.MethodName*

-   *ResultAnalyticalMethod.MethodIdentifier*

-   *ResultAnalyticalMethod.MethodIdentifierContext*

-   *AssemblageSampledName*

-   *DetectionQuantitationLimitTypeName*

```{r TADA_FieldCounts_char}
TADA_FieldCounts(TADAProfileClean6, display = "most", characteristicName = "TOTAL PHOSPHORUS, MIXED FORMS")
```

Selecting a parameter generates the list above, which is subset by the
selected parameter. The list includes fields you may want to review, and
the number of unique values in each field.

Next, choose a field from the list.

Review the WQX domain files for definitions:
<https://www.epa.gov/waterdata/storage-and-retrieval-and-water-quality-exchange-domain-services-and-downloads>

Now, we'll use **TADA_FieldValuesTable** and **TADA_FieldValuesPie** at the
characteristic-level to review a column of interest.

```{r TADA_FieldValuesTable_Pie_char, fig.width=8, fig.height=6, fig.fullwidth=TRUE}
# In this example we review values from the SampleCollectionMethod.MethodName field
TADA_FieldValuesTable(TADAProfileClean6, field = "SampleCollectionMethod.MethodName", characteristicName = "TOTAL PHOSPHORUS, MIXED FORMS")
TADA_FieldValuesPie(TADAProfileClean6, field = "SampleCollectionMethod.MethodName", characteristicName = "TOTAL PHOSPHORUS, MIXED FORMS")
```

Generate a scatterplot with two 
```{r TADA_TwoCharacteristicScatterplot, fig.width=8, fig.height=6, fig.fullwidth=TRUE}
# review unique identifiers
unique(TADAProfileClean6$TADA.ComparableDataIdentifier)

# choose two and generate scatterplot
TADA_TwoCharacteristicScatterplot(TADAProfileClean6, id_cols = "TADA.ComparableDataIdentifier", groups = c("TOTAL NITROGEN, MIXED FORMS_UNFILTERED_AS N_MG/L", "TOTAL PHOSPHORUS, MIXED FORMS_UNFILTERED_AS P_UG/L"))
```


Now we will summarize results for a single comparable data group using the
TADA.ComparableDataIdentifier (i.e., comparable characteristic, unit,
speciation, and fraction combination) using **TADA_Histogram** and **TADA_Boxplot**. Note that users may generate a list output of multiple plots if their input dataset has more than one unique comparable data group.

```{r ComparableDataIdentifier_stats_and_histogram, fig.width=8, fig.height=6, fig.fullwidth=TRUE}
# review TADA.ComparableDataIdentifier
unique(TADAProfileClean5$TADA.ComparableDataIdentifier)

# filter dataframe to only "TOTAL PHOSPHORUS, MIXED FORMS"
TADAProfileCleanTP <- dplyr::filter(TADAProfileClean6, TADA.ComparableDataIdentifier == "TOTAL PHOSPHORUS, MIXED FORMS_UNFILTERED_AS P_UG/L")

# generate stats table
TADAProfileCleanTP_stats <- TADA::TADA_Stats(TADAProfileCleanTP)

TADAProfileCleanTP_stats

# generate a histogram
TP_Histogram <- TADA_Histogram(TADAProfileCleanTP, id_cols = "TADA.ComparableDataIdentifier")

# view histogram
TP_Histogram
```

Generate interactive box plot.

```{r boxplot, fig.width=8, fig.height=6, fig.fullwidth=TRUE}
TP_Boxplot <- TADA::TADA_Boxplot(TADAProfileCleanTP, id_cols = "TADA.ComparableDataIdentifier")

TP_Boxplot
```

Generate interactive scatterplot.

```{r scatterplot, fig.width=8, fig.height=6, fig.fullwidth=TRUE}
TADAProfileCleanTP_dailymax <- TADA_AggregateMeasurements(TADAProfileCleanTP,
  agg_fun = c("max"),
  clean = TRUE
)

TP_Scatterplot <- TADA::TADA_Scatterplot(TADAProfileCleanTP_dailymax, id_cols = "TADA.ComparableDataIdentifier")

TP_Scatterplot
```

## Retain TADA Required Columns
Now we can review the "TADA" prefixed columns we have added to the data set. If we are satisfied with the conversions, filtering, flagging, etc. and the resulting "TADA" columns, we can use the **TADA_RetainRequired** function to remove any columns that are not required or used as filters in the TADA workflow. This reduces the size of the data frame.

```{r retainrequired}
TADAProfileClean7 <- TADA_RetainRequired(TADAProfileClean6)
```

## TADA Shiny Application

Finally, take a look at an alternative workflow, TADA Shiny Module 1:
Data Discovery and Cleaning. This is a Shiny application that runs many
of the TADA functions covered in this document behind a graphical user
interface. The shiny application queries the WQP, contains maps and data
visualizations, flags suspect data results, handles censored data, and
more. You can launch it using the code below.

DRAFT [Module 1](https://owshiny-dev.app.cloud.gov/tada-dev/) is also
currently hosted on the web with minimal server memory/storage
allocated.

```{r, eval = F}
# download TADA Shiny repository
remotes::install_github("USEPA/TADAShiny",
  ref = "develop",
  dependencies = TRUE
)

# launch the app locally.
TADAShiny::run_app()
```

## Download this Article from GitHub

Go to:
<https://github.com/USEPA/TADA/blob/develop/vignettes/TADAModule1.Rmd>

[![Click the highlighted icon to download TADAR5.Rmd from GitHub.
Open this file in R Studio to follow along. Alternatively, you can copy
and paste desired lines of code from here into your own
script. Note: You must have a GitHub account to download TADAModule1.Rmd from GitHub ](images/DownloadModule1.jpg)](https://github.com/USEPA/TADA/blob/develop/vignettes/TADAModule1.Rmd)
