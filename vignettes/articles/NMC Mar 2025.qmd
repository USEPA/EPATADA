---
title: "Creating Efficient and Reproducible Water Quality Workflows Using R"
format:  
  revealjs:
    theme: serif
  html:
    fig-width: 8
    fig-height: 6
  pdf:
    fig-width: 7
    fig-height: 5
editor: visual
editor_options: 
    wrap: 72
execute:
  echo: true
  eval: true
  output: true
  warning: false
  error: false
  include: true
author:
  - name: "Cristina Mullin"
    orcid: 0000-0002-0615-6087
    email: mullin.cristina@epa.gov
    affiliation: 
      - name: Office of Water, Water Data Integration Branch, Environmental Protection Agency
        city: Washington, D.C., United States
        url: https://www.epa.gov/waterdata/TADA
footer: "EPATADA, dataRetrieval, nhdplusTools, StreamCatTools, hydroloom"
---

# Introduction (10 mins)

## Quarto

Quarto enables you to weave together content and executable code into a finished presentation. To learn more about Quarto presentations see <https://quarto.org/docs/presentations/>.

## Introduction

This workshop showcases how to integrate several R Packages developed by the U.S. Environmental Protection Agency (EPA) and the United States Geological Survey (USGS), and other fundamental packages to create efficient and reproducible workflows that support water quality programs and research – for example performing watershed or waterbody level analyses such as Clean Water Act Assessments. We will also touch briefly on packages that can assist with building statistical models.

## Intended audience

Water Quality eXchange (WQX) and Water Quality Portal (WQP) community, Clean Water Act (CWA) Assessment community (EPA, States and Tribal Nations), water quality and geospatial data analysts, researchers, EPA/USGS and other federal agencies.

## Agenda

This workshop demonstrates potential uses (beyond their original collection purpose) for publicly available water quality data from Water Quality Portal (WQP). To start, participants will learn how to use EPA’s Tools for Automated Data Analysis (TADA) R Package to retrieve, wrangle, harmonize, quality check, visualize and analyze WQP data from multiple organizations.

## Agenda

Then we will showcase how to bring in other web services and libraries for easy integration of additional hydrologic (e.g. USGS continuous sensor data), climatic and remote sensing data. While not the focus of this workshop, we plan to briefly touch on packages that can assist with building statistical models. Finally, we will demonstrate as example workflow for performing Assessment Unit (a type of hydrology and watershed level analysis) level analysis and visualization.

## Packages

-   EPA: EPATADA, StreamCatTools

-   USGS: dataRetrieval, nhdplusTools, hydroloom

-   Fundamental geospatial packages such as sf, terra, leaflet and tmap

# Preparing Water Quality Portal (WQP) data for analysis using EPATADA

Let's dive into Green Bay, WI!

## Install and load

Install and load the remotes package.

```{r}
if(!"remotes"%in%installed.packages()){
install.packages("remotes")
}

library(remotes)
```

## Load

Install and load the [EPATADA R Package](https://github.com/USEPA/EPATADA) from GitHub.

```{r}
remotes::install_github("USEPA/EPATADA", 
                        ref = "develop", 
                        dependencies = TRUE, 
                        force = TRUE)

library(EPATADA)
```

## It's go time!

Let's time our process.

```{r}
# Record start time
start.time <- Sys.time()
```

## Retrieve data from WQP

In this example, we will use EPA's How's My Waterway (HMW) application to find an applicable Hydrologic Unit Code (HUC) for our area of interest - the [Fox River, Green Bay, WI](https://mywaterway.epa.gov/community/040302040405/monitoring). Next, query the WQP using the identified HUC, state abbreviation, and a date range. In this example, we'll start by pulling all data available in the WQP for this area for the last 5 years.

WATERSHED: City of Green Bay-Fox River (040302040405)

```{r}
GreenBay_FoxRiver <- EPATADA::TADA_DataRetrieval(
  statecode = "WI",
  startDate = "2015-01-01",
  endDate = "2024-12-30",
  huc = c("040302040405"),
  applyautoclean = TRUE
)
```

## Wrangle

Now, let's use EPATADA functions to whittle the data down to what is applicable to our analysis.

![](images/Funnel.png)

## Refine area of interest and filter

Visualize
```{r}
ATTAINS_data <- TADA_GetATTAINS(GreenBay_FoxRiver)
ATTAINS_map <- TADA_ViewATTAINS(ATTAINS_data)
ATTAINS_map
```

Filter
```{r}
# Filter data for specified assessment unit

AUID_data <- ATTAINS_data$TADA_with_ATTAINS %>%
  dplyr::filter(ATTAINS.assessmentunitidentifier == "IL_I-84")

Analysis_data <- ATTAINS_data$TADA_with_ATTAINS %>%
  dplyr::filter(ATTAINS.assessmentunitidentifier == "IL_I-84") %>%
  dplyr::select(-contains("ATTAINS.")) %>%
  sf::st_drop_geometry() %>%
  TADA_RetainRequired()

# Create table of monitoring location identifiers

MonitoringLocations <- Analysis_data %>%
  dplyr::select(MonitoringLocationName, MonitoringLocationIdentifier, OrganizationFormalName) %>%
  dplyr::distinct()

DT::datatable(MonitoringLocations, fillContainer = TRUE)

# Create pie of results by organization
Orgs_pie <- TADA_FieldValuesPie(Analysis_data, field = "OrganizationFormalName")

Orgs_pie

# Filter data for specified assessment unit

AUID_data <- ATTAINS_data$TADA_with_ATTAINS %>%
  dplyr::filter(ATTAINS.assessmentunitidentifier == "IL_I-84")

Analysis_data <- ATTAINS_data$TADA_with_ATTAINS %>%
  dplyr::filter(ATTAINS.assessmentunitidentifier == "IL_I-84") %>%
  dplyr::select(-contains("ATTAINS.")) %>%
  sf::st_drop_geometry() %>%
  TADA_RetainRequired()
```

## Quality check

```{r}
# Flag and remove results

Analysis_data <- Analysis_data %>%
  TADA_FlagMethod(clean = TRUE) %>%
  TADA_FlagSpeciation(clean = "both") %>%
  TADA_FlagResultUnit(clean = "both") %>%
  TADA_FlagFraction(clean = TRUE) %>%
  TADA_FlagAboveThreshold(clean = TRUE) %>%
  TADA_FlagBelowThreshold(clean = TRUE) %>%
  TADA_FindPotentialDuplicatesSingleOrg() %>%
  dplyr::filter(TADA.SingleOrgDup.Flag == "Unique") %>%
  TADA_FindPotentialDuplicatesMultipleOrgs(
    dist_buffer = 100,
    org_hierarchy = "none"
  ) %>%
  dplyr::filter(TADA.ResultSelectedMultipleOrgs == "Y") %>%
  TADA_FindQCActivities(clean = TRUE) %>%
  TADA_FlagMeasureQualifierCode(clean = TRUE)
```

## Harmonize

```{r}
Analysis_data <- TADA_SimpleCensoredMethods(Analysis_data,
  nd_method = "multiplier",
  nd_multiplier = 0.5,
  od_method = "as-is",
  od_multiplier = "null"
) %>%
  dplyr::filter(!is.na(TADA.ResultMeasureValue))

UniqueHarmonizationRef <- TADA_GetSynonymRef(Analysis_data)

UniqueHarmonizationRef_edit <- UniqueHarmonizationRef %>%
  dplyr::mutate(
    Target.TADA.CharacteristicName = ifelse(TADA.CharacteristicName == "TEMPERATURE, WATER", "TEMPERATURE", TADA.CharacteristicName),
    Target.TADA.ResultSampleFractionText = ifelse(TADA.CharacteristicName == "PH", NA, Target.TADA.ResultSampleFractionText),
    HarmonizationGroup = ifelse(TADA.CharacteristicName == "PH", "PH", HarmonizationGroup),
    HarmonizationGroup = ifelse(Target.TADA.CharacteristicName == "TEMPERATURE", "TEMPERATURE",
      HarmonizationGroup
    )
  )

Harmonized_data <- TADA_HarmonizeSynonyms(Analysis_data,
  ref = UniqueHarmonizationRef_edit
)
```

## Analyze

```{r}
Harmonized_data <- TADA_CalculateTotalNP(Harmonized_data, daily_agg = "max")
```

## Filter
```{r}
# review unique identifiers
unique(Harmonized_data$TADA.ComparableDataIdentifier)

# filter for three comparable data identifiers of interest
Filtered_data <- Harmonized_data %>%
  dplyr::filter(TADA.ComparableDataIdentifier %in% c("TEMPERATURE_NA_NA_DEG C", "PH_NA_NA_NA", "TOTAL NITROGEN, MIXED FORMS_UNFILTERED_AS N_MG/L"))

# generate stats table
Filtered_data_stats <- TADA_Stats(Filtered_data)

DT::datatable(Filtered_data_stats, fillContainer = TRUE)
```

## Visualize

```{r}
# choose two and generate scatterplot
TADA_TwoCharacteristicScatterplot(Harmonized_data, id_cols = "TADA.ComparableDataIdentifier", groups = c("TEMPERATURE_NA_NA_DEG C", "PH_NA_NA_NA"))
```

# Ingestion of additional hydrologic, climatic and remote sensing data

## Combine hydrologic, climatic and remote sensing data with WQP data

1.  USGS continuous sensor data
2.  PRISM climate

# Example Use Case 1: Building Statistical Models

placeholder

# Example Use Case 2: Clean Water Act (CWA) Section 303(d) Assessments

## CWA Assessment Process

We do not have time to cover the full process today. Let's focus on geospatial aspects!

[Integrated Reporting Memoranda under CWA Sections 303(d), 305(b) and 314](https://www.epa.gov/tmdl/Integrated%20Reporting%20Guidance%20under%20CWA%20Sections%20303%28d%29%2C%20305%28b%29%20and%20314).

## What are Assessment Units?

Geospatial areas for analysis. Let's assign data to those units!

CWA assessment determinations are made by assessment unit, meaning the entire assessment unit is assessed as either meeting or not meeting water quality standards (i.e., thresholds or criteria) for all designated uses.

## How are assessment units delineated?

Assessment units are typically delineated by using watershed-oriented collections of stream reaches, often broken down by physical features like waterfalls, bridge crossings, or changes in land use, to analyze water quality impairments within a specific area, ensuring data homogeneity and spatial clarity within the assessment unit.

-   Existing Assessment Units are available from ATTAINS geospatial services

## Associating ATTAINS Assessment Units with WQP Monitoring Locations

One of the first steps in the CWA assessment process is to define Assessment Units and associate data with them. A major source for water quality data is the WQP.

## Associating ATTAINS Assessment Units with WQP Monitoring Locations

-   Assessment Units: state or tribal waterbody geospatial features
    -   These may be lines, areas or points
-   Water Quality Portal Monitoring Locations
    -   points

## TADA_GetATTAINS()

-   Automated matching of WQP monitoring locations with ATTAINS assessment units that fall within (intersect) the same NHDPlus catchment ([details](https://usepa.github.io/EPATADA/articles/TADAModule2.html))
-   The function uses high resolution NHDPlus catchments by default because 80% of state submitted assessment units in ATTAINS were developed based on high res NHD; users can select med-res if applicable to their use case

## Challenges with Automated Approach

-   Certain NHDPlus high res catchments overlap multiple ATTAINS assessment units (state submitted hydrography) which means the sites are assigned to both AUs in the current functions. Another challenge is that the WQP sites are not always accurate (imprecise coordinates). Ideally, each site could be matched with a single assessment unit and not multiple.

## Challenges with Automated Approach

-   Placeholder: Are there tools to help with these challenges (i.e., QAQC'ing draft TADA site/AU associations)?
    -   Can more sophisticated logic (e.g., maybe flow/rain drop logic or even simply closest AU) be added for areas where multiple assessment units overlap the same high-res catchment (for example at tributaries)?

## Challenges with Automated Approach

-   Use EPA WATERS or nhdplusTools?
    -   Note: WQP location metadata may also be helpful for matching/QAQC'ing waterbody names with ATTAINS waterbody names instead of relying solely on the lat/long and geospatial/mapping information.

## Using all available data

Finally, some waterbodies have data available in the WQP or from other sources, but there are no existing Assessment Units in ATTAINS for them. In the next section, we will share a way to create create AU's using NHDPlus high resolution catchments.

## Creating new AUs to assess additional areas

TADA has included a way to do this using TADA_GetATTAINS() fill_catchments function input. This is included for exploratory purposes only. In theory the high res catchments could be created as new assessment unit polygons, but that process is outside of TADA.

## Creating new AUs to assess additional areas with TADA::fetchNHD()

For WQP monitoring sites that DO NOT overlap an existing ATTAINS feature (neither ATTAINS NHDPlus high res catchment snap shot or state submitted points/lines/polys), there is nothing to use from ATTAINS because these are areas where there is WQP data but no ATTAINS AU yet.

## Creating new AUs to assess additional areas with TADA::fetchNHD()

For these, we implemented a solution using NHDPlusTools to pull in either NHDPlus high res or med res catchments (user can choose, but high res is the default) and match those with the WQP sites & create new IDs (essentially creating new AUs that are the catchments that intersect these WQP sites).

## Creating new AUs to assess additional areas with TADA::fetchNHD()

-   Do we want to include anything else from StreamCatTools or other packages here to help with new AU delineation?

# Conclusion

```{r}
end.time <- Sys.time()

end.time - start.time
```

placeholder

Thank you for your attention!

## Thank you to our workshop contributors!

-   EPA: Cristina Mullin (mullin.cristina\@epa.gov), Hillary Marler, Kenny Wong, Shelly Thawley, Marc Weber, Ryan Hill, Michael Dumelle

-   USGS: Dave Blodgett
